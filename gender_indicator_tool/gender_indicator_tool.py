# -*- coding: utf-8 -*-
"""
/***************************************************************************
 GenderIndicatorTool
                                 A QGIS plugin
 Gender Indicator Tool
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2023-07-15
        git sha              : $Format:%H$
        copyright            : (C) 2023 by Pegasys
        email                : andre@pegasys.co.za
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""
# QGIS and PyQt libraries and modules
from qgis.PyQt.QtCore import QSettings, QTranslator, QCoreApplication, QVariant
from qgis.PyQt.QtGui import *
from qgis.PyQt.QtWidgets import QAction, QMessageBox
from PyQt5.QtWidgets import QFileDialog, QApplication, QComboBox
from qgis.core import *
from qgis.core import QgsVectorLayer, QgsProject, QgsCoordinateReferenceSystem, QgsCoordinateTransformContext, \
    QgsCoordinateTransform, QgsMessageLog, Qgis, QgsWkbTypes
from PyQt5.QtCore import QVariant

# package installs


# Auxiliary libraries
import os
import sys
import geopandas as gpd
import pandas as pd
import rasterio
from rasterio.crs import CRS
import numpy as np
import math
import shutil
import time
import logging
import ast
from rasterio.mask import mask
from rasterio.features import geometry_mask
import csv
import subprocess

# Prepare processing framework
# sys.path.append(r'C:\Program Files\QGIS 3.32.0\apps\qgis\python\plugins') # Folder where Processing is located
from processing.core.Processing import Processing

Processing.initialize()
import processing
import sys
from qgis.PyQt import QtWidgets

# also import pyqtRemoveInputHook
from qgis.PyQt.QtCore import pyqtRemoveInputHook
from qgis.core import QgsMessageLog

# Initialize Qt resources from file resources.py
from .resources import *

# Import the code for the dialog
from .gender_indicator_tool_dialog import GenderIndicatorToolDialog


# test
class GenderIndicatorTool:
    """QGIS Plugin Implementation."""

    def __init__(self, iface):
        """Constructor.

        :param iface: An interface instance that will be passed to this class
            which provides the hook by which you can manipulate the QGIS
            application at run time.
        :type iface: QgsInterface
        """
        # Save reference to the QGIS interface
        self.iface = iface
        # initialize plugin directory
        self.plugin_dir = os.path.dirname(__file__)

        # Show commands button only shown in debug mode
        # Fetch the value of GEEST_DEBUG from an environment variable
        debug_mode = int(os.getenv("GEEST_DEBUG", 0))
        if debug_mode:
            import multiprocessing  # pylint: disable=import-outside-toplevel

            if multiprocessing.current_process().pid > 1:
                import debugpy  # pylint: disable=import-outside-toplevel

                debugpy.listen(("0.0.0.0", 9000))
                debugpy.wait_for_client()
                # self.display_information_message_bar(
                #     title="Animation Workbench",
                #     message="Visual Studio Code debugger is now attached on port 9000",
                # )

        # initialize locale
        locale = QSettings().value("locale/userLocale")[0:2]
        locale_path = os.path.join(
            self.plugin_dir, "i18n", "GenderIndicatorTool_{}.qm".format(locale)
        )

        if os.path.exists(locale_path):
            self.translator = QTranslator()
            self.translator.load(locale_path)
            QCoreApplication.installTranslator(self.translator)

        # Declare instance attributes
        self.actions = []
        self.menu = self.tr("&Gender Enabling Environments Spatial Tool (GEEST)")

        # Check if plugin was started the first time in current QGIS session
        # Must be set in initGui() to survive plugin reloads
        self.first_start = None

        # Add a global buffer distance constant
        # This value used to be 2000
        self.BUFFER_DISTANCE = 0

    # noinspection PyMethodMayBeStatic
    def tr(self, message):
        """Get the translation for a string using Qt translation API.

        We implement this ourselves since we do not inherit QObject.

        :param message: String for translation.
        :type message: str, QString

        :returns: Translated version of message.
        :rtype: QString
        """
        # noinspection PyTypeChecker,PyArgumentList,PyCallByClass
        return QCoreApplication.translate("GenderIndicatorTool", message)

    def add_action(
            self,
            icon_path,
            text,
            callback,
            enabled_flag=True,
            add_to_menu=True,
            add_to_toolbar=True,
            status_tip=None,
            whats_this=None,
            parent=None,
    ):
        """Add a toolbar icon to the toolbar.

        :param icon_path: Path to the icon for this action. Can be a resource
            path (e.g. ':/plugins/foo/bar.png') or a normal file system path.
        :type icon_path: str

        :param text: Text that should be shown in menu items for this action.
        :type text: str

        :param callback: Function to be called when the action is triggered.
        :type callback: function

        :param enabled_flag: A flag indicating if the action should be enabled
            by default. Defaults to True.
        :type enabled_flag: bool

        :param add_to_menu: Flag indicating whether the action should also
            be added to the menu. Defaults to True.
        :type add_to_menu: bool

        :param add_to_toolbar: Flag indicating whether the action should also
            be added to the toolbar. Defaults to True.
        :type add_to_toolbar: bool

        :param status_tip: Optional text to show in a popup when mouse pointer
            hovers over the action.
        :type status_tip: str

        :param parent: Parent widget for the new action. Defaults None.
        :type parent: QWidget

        :param whats_this: Optional text to show in the status bar when the
            mouse pointer hovers over the action.

        :returns: The action that was created. Note that the action is also
            added to self.actions list.
        :rtype: QAction
        """

        icon = QIcon(icon_path)
        action = QAction(icon, text, parent)
        action.triggered.connect(callback)
        action.setEnabled(enabled_flag)

        if status_tip is not None:
            action.setStatusTip(status_tip)

        if whats_this is not None:
            action.setWhatsThis(whats_this)

        if add_to_toolbar:
            # Adds plugin icon to Plugins toolbar
            self.iface.addToolBarIcon(action)

        if add_to_menu:
            self.iface.addPluginToMenu(self.menu, action)

        self.actions.append(action)

        return action

    def initGui(self):
        """Create the menu entries and toolbar icons inside the QGIS GUI."""

        icon_path = ":/plugins/gender_indicator_tool/icon.png"
        self.add_action(
            icon_path,
            text=self.tr("GEEST"),
            callback=self.run,
            parent=self.iface.mainWindow(),
        )

        # will be set False in run()
        self.first_start = True

    def unload(self):
        """Removes the plugin menu item and icon from QGIS GUI."""
        for action in self.actions:
            self.iface.removePluginMenu(
                self.tr("&World Bank Gender Indicator Tool"), action
            )
            self.iface.removeToolBarIcon(action)

    def run(self):
        """Run method that performs all the real work"""

        # Create the dialog with elements (after translation) and keep reference
        # Only create GUI ONCE in callback, so that it will only load when the plugin is started
        if self.first_start == True:
            self.first_start = False
            self.dlg = GenderIndicatorToolDialog()

        # show the dialog
        self.dlg.show()

        ## TAB 1 - Analysis Setup ***********************************************************************
        self.dlg.workingDir_Button.clicked.connect(lambda: self.getFolder(0))

        ## TAB 2 - Contextual ***************************************************************************

        ###### TAB 2.1 - Workplace Discrimination
        self.dlg.WD_Execute_PB.clicked.connect(lambda: self.Rasterize(1))

        ###### TAB 2.2 - Regulatory Frameworks
        self.dlg.RF_Execute_PB.clicked.connect(lambda: self.Rasterize(2))

        ###### TAB 2.3 - Financial Inclusion
        self.dlg.FIN_Execute_PB.clicked.connect(lambda: self.Rasterize(3))

        ###### TAB 2.2 - Aggregate
        self.dlg.WD_Aggregate_TB.clicked.connect(lambda: self.getFile(1))
        self.dlg.RF_Aggregate_TB.clicked.connect(lambda: self.getFile(3))
        self.dlg.FIN_Aggregate_TB.clicked.connect(lambda: self.getFile(4))

        self.dlg.Contextual_AggregateExecute_PB.clicked.connect(
            self.contextual_aggregation
        )

        ## TAB 3 - Accessibility ************************************************************************
        Modes = ["Walking", "Driving"]
        Measurement = ["Distance", "Time"]

        ###### TAB 3.1 - Women's Travel Patterns
        self.dlg.WTP_mode_CB.clear()
        self.dlg.WTP_mode_CB.addItems(Modes)
        self.dlg.WTP_measurement_CB.clear()
        self.dlg.WTP_measurement_CB.addItems(Measurement)
        self.dlg.WTP_Execute_PB.clicked.connect(lambda: self.ServiceArea(5))

        self.dlg.WTP_Aggregate_PB.clicked.connect(self.wtp_aggregate)

        ###### TAB 3.2 - Public Transport
        self.dlg.PBT_mode_CB.clear()
        self.dlg.PBT_mode_CB.addItems(Modes)
        self.dlg.PBT_measurement_CB.clear()
        self.dlg.PBT_measurement_CB.addItems(Measurement)
        self.dlg.PBT_Execute_PB.clicked.connect(lambda: self.ServiceArea(0))

        ###### TAB 3.3 - Education & Training
        self.dlg.ETF_mode_CB.clear()
        self.dlg.ETF_mode_CB.addItems(Modes)
        self.dlg.ETF_measurement_CB.clear()
        self.dlg.ETF_measurement_CB.addItems(Measurement)
        self.dlg.ETF_Execute_PB.clicked.connect(lambda: self.ServiceArea(1))

        ###### TAB 3.4 - Health Facilities
        self.dlg.HEA_mode_CB.clear()
        self.dlg.HEA_mode_CB.addItems(Modes)
        self.dlg.HEA_measurement_CB.clear()
        self.dlg.HEA_measurement_CB.addItems(Measurement)
        self.dlg.HEA_Execute_PB.clicked.connect(lambda: self.ServiceArea(3))

        ###### TAB 3.5 - Financial Facilities
        self.dlg.FIF_mode_CB.clear()
        self.dlg.FIF_mode_CB.addItems(Modes)
        self.dlg.FIF_measurement_CB.clear()
        self.dlg.FIF_measurement_CB.addItems(Measurement)
        self.dlg.FIF_Execute_PB.clicked.connect(lambda: self.ServiceArea(4))

        ###### TAB 3.6 - Aggregate
        self.dlg.WTP_Aggregate_TB.clicked.connect(lambda: self.getFile(5))
        self.dlg.PBT_Aggregate_TB.clicked.connect(lambda: self.getFile(6))
        self.dlg.ETF_Aggregate_TB.clicked.connect(lambda: self.getFile(7))
        self.dlg.HEA_Aggregate_TB.clicked.connect(lambda: self.getFile(9))
        self.dlg.FIF_Aggregate_TB.clicked.connect(lambda: self.getFile(10))
        self.dlg.Accessibility_AggregateExecute_PB.clicked.connect(
            self.accessibilty_aggregation
        )

        ## TAB 4 - Place Charqacterization **************************************************************
        ###### TAB 4.1 - Walkability / Active Transport
        #self.dlg.WLK_Set_PB.clicked.connect(lambda: self.TypeSet(1))
        #self.dlg.WLK_unique_PB.clicked.connect(lambda: self.uniqueValues(1))
        self.dlg.WLK_Execute_PB_2.clicked.connect(self.walkability)
        self.dlg.AT_Aggregate_PB.clicked.connect(self.walkabilityAggregate)

        ###### TAB 4.2 - Safe Urban Design
        self.dlg.SAF_Input_Field.fileChanged.connect(self.populateCBFieldsFromPolygonLayer_PC_SAF)
        self.dlg.SAF_rasField_CB.textActivated.connect(self.populateTextFieldWithUniqueValues_PC_SAF)
        self.dlg.SAF_Execute_PB.clicked.connect(self.SAFRasterizerDelegator)

        ###### TAB 4.3 - Digital Inclusion
        self.dlg.DIG_Set_PB.clicked.connect(lambda: self.RasterizeSet(4))
        self.dlg.DIG_Execute_PB.clicked.connect(lambda: self.Rasterize(5))

        ###### TAB 4.4 - Natural Environment
        #self.dlg.ENV_Set_PB.clicked.connect(lambda: self.TypeSet(3))
        #self.dlg.ENV_Input_Field.fileChanged.connect(self.populateCBFieldsFromPolygonLayer_PC_ENV)
        #self.dlg.ENV_unique_PB.clicked.connect(lambda: self.uniqueValues(3))
        #self.dlg.ENV_riskLevelField_CB.textActivated.connect(self.populateTextFieldWithUniqueValues_PC_ENV)
        self.dlg.ENV_Execute_PB.clicked.connect(self.natEnvironment)
        self.dlg.ENV_Aggregate_PB.clicked.connect(self.env_aggregate)

        ###### TAB 4.5- Education
        #self.dlg.EDU_Set_PB.clicked.connect(lambda: self.RasterizeSet(0))
        self.dlg.EDU_Input_Field.fileChanged.connect(self.populateCBFieldsFromPolygonLayer_PC_EDU)
        self.dlg.EDU_Execute_PB.clicked.connect(self.EDURasterizerDelegator)

        ###### TAB 4.6 - Facility, conflict, and violence
        #self.dlg.FCV_Set_PB.clicked.connect(lambda: self.RasterizeSet(5))
        self.dlg.FCV_Execute_PB.clicked.connect(lambda: self.Rasterize(6))

        ###### TAB 4.7 - Water and Sanitation
        #self.dlg.WAS_Execute_PB.clicked.connect(lambda: self.Rasterize(7))
        self.dlg.WAS_Execute_PB.clicked.connect(self.WAS_rasterizer_v2)

        ###### TAB 4.7 - Aggregate
        self.dlg.WLK_Aggregate_TB.clicked.connect(lambda: self.getFile(11))
        self.dlg.SAF_Aggregate_TB.clicked.connect(lambda: self.getFile(14))
        self.dlg.DIG_Aggregate_TB.clicked.connect(lambda: self.getFile(20))
        self.dlg.ENV_Aggregate_TB.clicked.connect(lambda: self.getFile(21))
        self.dlg.EDU_Aggregate_TB.clicked.connect(lambda: self.getFile(0))
        self.dlg.FCV_Aggregate_TB.clicked.connect(lambda: self.getFile(26))
        self.dlg.WAS_Aggregate_TB.clicked.connect(lambda: self.getFile(27))
        self.dlg.PlaceCharacterization_AggregateExecute_PB.clicked.connect(
            self.place_characterization_aggregation
        )

        ## TAB 5 - Dimension Aggregation ************************************************************************
        #self.dlg.ID_Aggregate_TB.clicked.connect(lambda: self.getFile(22))
        self.dlg.CD_Aggregate_TB.clicked.connect(lambda: self.getFile(23))
        self.dlg.AD_Aggregate_TB.clicked.connect(lambda: self.getFile(24))
        self.dlg.PD_Aggregate_TB.clicked.connect(lambda: self.getFile(25))
        self.dlg.Dimensions_AggregateExecute_PB.clicked.connect(
            self.dimensions_aggregation
        )

        ## TAB 6 - Insights ************************************************************************
        ###### TAB 6.1 - Enablement
        self.dlg.Score_reclassify.clicked.connect(self.scoreReclassInsights)
        self.dlg.Pop_reclassify.clicked.connect(self.populationReclassInsights)
        self.dlg.Combine_reclassify.clicked.connect(self.combineReclassInsights)
        self.dlg.Aggregation_Execute_PB.clicked.connect(self.Aggregationinsights)

        ###### TAB 6.2 - Raster Locations
        self.dlg.RE_Execute_PB.clicked.connect(self.reZones)

        ###### TAB 6.3 - Point Locations
        self.dlg.Buffer_Execute_PB.clicked.connect(self.Bufferinsights)

        # ******************************************************************************************* Weights Auto-calc #
        # weights auto-calc button
        self.dlg.PB_PC_aggregate_auto.clicked.connect(lambda: self.calculate_aggregate_weights(self.PC_aggregate_field_pairs))
        self.dlg.PB_CTX_aggregate_auto.clicked.connect(lambda: self.calculate_aggregate_weights(self.CTX_aggregate_field_pairs))
        self.dlg.PB_ACC_aggregate_auto.clicked.connect(lambda: self.calculate_aggregate_weights(self.ACC_aggregate_field_pairs))
        self.dlg.PB_AGG_aggregate_auto.clicked.connect(lambda: self.calculate_aggregate_weights(self.AGG_aggregate_field_pairs))

        # Place Characterization field pairs
        self.PC_aggregate_field_pairs = [
            (self.dlg.AT_Aggregate_Field, self.dlg.WLK_Aggregate_SB),
            (self.dlg.SAF_Aggregate_Field, self.dlg.SAF_Aggregate_SB),
            (self.dlg.EDU_Aggregate_Field, self.dlg.EDU_Aggregate_SB),
            (self.dlg.DIG_Aggregate_Field, self.dlg.DIG_Aggregate_SB),
            (self.dlg.ENV_Aggregate_Field, self.dlg.ENV_Aggregate_SB),
            (self.dlg.FCV_Aggregate_Field, self.dlg.FCV_Aggregate_SB),
            (self.dlg.WAS_Aggregate_Field, self.dlg.WAS_Aggregate_SB),
        ]

        self.CTX_aggregate_field_pairs = [
            (self.dlg.WD_Aggregate_Field, self.dlg.WD_Aggregate_SB),
            (self.dlg.RF_Aggregate_Field, self.dlg.RF_Aggregate_SB),
            (self.dlg.FIN_Aggregate_Field, self.dlg.FIN_Aggregate_SB)
        ]

        self.ACC_aggregate_field_pairs = [
            (self.dlg.WTP_Aggregate_Field, self.dlg.WTP_Aggregate_SB),
            (self.dlg.PBT_Aggregate_Field, self.dlg.PBT_Aggregate_SB),
            (self.dlg.ETF_Aggregate_Field, self.dlg.ETF_Aggregate_SB),
            (self.dlg.HEA_Aggregate_Field, self.dlg.HEA_Aggregate_SB),
            (self.dlg.FIF_Aggregate_Field, self.dlg.FIF_Aggregate_SB)
        ]

        self.AGG_aggregate_field_pairs = [
            (self.dlg.CD_Aggregate_Field, self.dlg.CD_Aggregate_SB),
            (self.dlg.AD_Aggregate_Field, self.dlg.AD_Aggregate_SB),
            (self.dlg.PD_Aggregate_Field, self.dlg.PD_Aggregate_SB)
        ]

    # ================================================================================================================ #

    def calculate_aggregate_weights(self, field_pairs):
        non_empty_fields = [pair for pair in field_pairs if pair[0].text()]
        num_non_empty = len(non_empty_fields)

        if num_non_empty == 0:
            return  # No fields with text, nothing to do

        weight_per_field = 100 / num_non_empty

        for line_edit, spin_box in field_pairs:
            if line_edit.text():
                spin_box.setValue(weight_per_field)
            else:
                spin_box.setValue(0)

        # Ensure total is exactly 100
        total = sum(pair[1].value() for pair in field_pairs)
        if total != 100:
            # Adjust the last non-empty field to make the total exactly 100
            last_non_empty = next((pair[1] for pair in reversed(field_pairs) if pair[0].text()), None)
            if last_non_empty:
                last_non_empty.setValue(last_non_empty.value() + (100 - total))


    def getFile(self, button_num):
        """
        Function used for all factor tabs to browse files and retrieve filepaths required to be used as input to other functions.

        Factors it is applied:
        - All
        """
        response = QFileDialog.getOpenFileName(
            parent=self.dlg, caption="Select a file", directory=os.getcwd()
        )

        if button_num == 0:
            self.dlg.EDU_Aggregate_Field.setText(response[0])

        elif button_num == 1:
            self.dlg.WD_Aggregate_Field.setText(response[0])

        elif button_num == 3:
            self.dlg.RF_Aggregate_Field.setText(response[0])

        elif button_num == 4:
            self.dlg.FIN_Aggregate_Field.setText(response[0])

        elif button_num == 5:
            self.dlg.WTP_Aggregate_Field.setText(response[0])

        elif button_num == 6:
            self.dlg.PBT_Aggregate_Field.setText(response[0])

        elif button_num == 7:
            self.dlg.ETF_Aggregate_Field.setText(response[0])

        elif button_num == 9:
            self.dlg.HEA_Aggregate_Field.setText(response[0])

        elif button_num == 10:
            self.dlg.FIF_Aggregate_Field.setText(response[0])

        elif button_num == 11:
            self.dlg.AT_Aggregate_Field.setText(response[0])

        elif button_num == 12:
            self.dlg.CYC_Aggregate_Field.setText(response[0])

        elif button_num == 14:
            self.dlg.SAF_Aggregate_Field.setText(response[0])

        elif button_num == 20:
            self.dlg.DIG_Aggregate_Field.setText(response[0])

        elif button_num == 21:
            self.dlg.ENV_Aggregate_Field.setText(response[0])

        elif button_num == 22:
            self.dlg.ID_Aggregate_Field.setText(response[0])

        elif button_num == 23:
            self.dlg.CD_Aggregate_Field.setText(response[0])

        elif button_num == 24:
            self.dlg.AD_Aggregate_Field.setText(response[0])

        elif button_num == 25:
            self.dlg.PD_Aggregate_Field.setText(response[0])

        elif button_num == 26:
            self.dlg.FCV_Aggregate_Field.setText(response[0])

        elif button_num == 27:
            self.dlg.WAS_Aggregate_Field.setText(response[0])

    def getFolder(self, button_num):
        """
        Function used to browse and retrieve filepath for project working directory selected in the setup tab
        """
        response = QFileDialog.getExistingDirectory(
            parent=self.dlg, caption="Select a folder/directory", directory=os.getcwd()
        )

        if button_num == 0:
            # Clear the field before setting its text
            self.dlg.workingDir_Field.clear()
            self.dlg.workingDir_Field.setText(str(response + "/"))

    def RasterizeSet(self, factor_no):
        """
        Used in combination with tabs that use the "Rasterization" function. This function is used to extract all the attribute table's field headings
        from the input vector layers. The extracted values are then populated in the drop-down menu allowing the user to select which fields values are to be used when
        executing the "Rasterization" function.

        Factors it is applied:
            Contextual Dimension
                - Workplace Discrimination
                - Regulatory Frameworks(RF)
                - Financial Inclusion
            Place Characterization Dimension
                - Education
                - Safety
                - Income Level
                - Digital Inclusion
                - Fragility, conflict, and violence(FCV)
        """
        if factor_no == 0:
            """polygonlayer = self.dlg.EDU_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            self.dlg.EDU_rasField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.EDU_rasField_CB.addItems(fields)"""

        elif factor_no == 1:
            polygonlayer = self.dlg.WD_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            self.dlg.WD_rasField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.WD_rasField_CB.addItems(fields)

        elif factor_no == 2:
            polygonlayer = self.dlg.RF_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            self.dlg.RF_rasField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.RF_rasField_CB.addItems(fields)

        elif factor_no == 3:
            polygonlayer = self.dlg.FIN_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            self.dlg.FIN_rasField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.FIN_rasField_CB.addItems(fields)

        elif factor_no == 4:
            polygonlayer = self.dlg.DIG_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            self.dlg.DIG_rasField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.DIG_rasField_CB.addItems(fields)

        elif factor_no == 5:
            polygonlayer = self.dlg.FCV_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            #self.dlg.FCV_rasField_CB.clear()
            #fields = [field.name() for field in layer.fields()]
            #self.dlg.FCV_rasField_CB.addItems(fields)

    def TypeSet(self, factor_no):
        """
        Similar to the "RasterizeSet" function this function is used to extract all the attribute table's field headings from the input vector layers. However,
        the extracted values are then populated in the drop-down menu where the user is to select which field from which they want extract the unique values. (See uniqueValues function)

        Factors it is applied:
            Place Characterization Dimension
                - Active Transport
                - Natural Environment and Climatic Factors
        """
        if factor_no == 1:
            roadlayer = self.dlg.WLK_Input_Field.filePath()
            layer = QgsVectorLayer(roadlayer, "polygonlayer", "ogr")
            self.dlg.WLK_roadTypeField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.WLK_roadTypeField_CB.addItems(fields)

        elif factor_no == 2:
            roadlayer = self.dlg.CYC_Input_Field.filePath()
            layer = QgsVectorLayer(roadlayer, "polygonlayer", "ogr")
            self.dlg.CYC_roadTypeField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.CYC_roadTypeField_CB.addItems(fields)

        elif factor_no == 3:
            polygonlayer = self.dlg.ENV_Input_Field.filePath()
            layer = QgsVectorLayer(polygonlayer, "polygonlayer", "ogr")
            self.dlg.ENV_riskLevelField_CB.clear()
            fields = [field.name() for field in layer.fields()]
            self.dlg.ENV_riskLevelField_CB.addItems(fields)

    def uniqueValues(self, factor_no):
        """
        This function is used in combination with the "TypeSet" function. Once the field of interest in the polygon layer has been selected this function
        extracts all the unique values in the selected field and populates the empty field with a list of the unique value in the following format:

        [["low", 0], ["medium", 0], ["high", 0]]

        The user than assigns scores according to the standardized scaling system to each unique value as seen below:

        [["low", 4], ["medium", 2], ["high", 1]]

        Factors it is applied:
            Place Characterization Dimension
                - Active Transport
                - Natural Environment and Climatic Factors
        """
        if factor_no == 1:
            gdf = gpd.read_file(self.dlg.WLK_Input_Field.filePath())
            roadTypeField = self.dlg.WLK_roadTypeField_CB.currentText()
            uniqueValues = gdf[roadTypeField].unique().tolist()
            scoreList = []

            for val in uniqueValues:
                scoreList.append([val, 0])

            self.dlg.WLK_typeScore_Field.setText(str(scoreList))

        elif factor_no == 2:
            gdf = gpd.read_file(self.dlg.CYC_Input_Field.filePath())
            roadTypeField = self.dlg.CYC_roadTypeField_CB.currentText()
            self.dlg.CYC_roadType_CB.clear()
            uniqueValues = gdf[roadTypeField].unique().tolist()
            self.dlg.CYC_roadType_CB.addItems(uniqueValues)

        if factor_no == 3:
            gdf = gpd.read_file(self.dlg.ENV_Input_Field.filePath())
            riskTypeField = self.dlg.ENV_riskLevelField_CB.currentText()
            uniqueValues = gdf[riskTypeField].unique().tolist()
            scoreList = []

            for val in uniqueValues:
                scoreList.append([val, 0])

            self.dlg.ENV_typeScore_Field.setText(str(scoreList))

    def convertCRS(self, vector, UTM_crs):
        """
        This function is used whenever a vector file's co-ordinate reference system needs to be reprojected so that it can be used as input into an algorithm.

        Factors it is applied:
        - All
        """
        global shp_utm

        shp = gpd.read_file(vector)
        shp_wgs84 = shp.to_crs("EPSG:4326")
        shp_utm = shp_wgs84.to_crs(UTM_crs)

    # *************************** Factor Functions ********************************** #
    def Rasterize(self, factor_no):
        """
        Numerous functions use this function to convert vector file type into the standardized raster file types required for aggregation.

        Factors it is applied:
            Contextual Dimension
                - Workplace Discrimination
                - Regulatory Frameworks(RF)
                - Financial Inclusion
            Place Characterization Dimension
                - Education
                - Fragility, conflict, and violence(FCV)
                - Digital Inclusion
                - Water and Sanitation (WAS)
        """
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)

        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(":")[-1][:-1]

        # INPUT
        if factor_no == 0:
            """polygonlayer = self.dlg.EDU_Input_Field.filePath()
            rasField = self.dlg.EDU_rasField_CB.currentText()
            self.dlg.EDU_status.setText("Variables Set")
            self.dlg.EDU_status.repaint()
            time.sleep(0.5)
            self.dlg.EDU_status.setText("Processing...")
            self.dlg.EDU_status.repaint()"""

        elif factor_no == 1:
            # polygonlayer = self.dlg.WD_Input_Field.filePath()
            rasField = "rasField"
            WD_Value_SB = self.dlg.WD_User_Value_Input.value()
            self.dlg.WD_status.setText("Variables Set")
            self.dlg.WD_status.repaint()
            time.sleep(0.5)
            self.dlg.WD_status.setText("Processing...")
            self.dlg.WD_status.repaint()

        elif factor_no == 2:
            # polygonlayer = self.dlg.RF_Input_Field.filePath()
            rasField = "rasField"
            RF_Value_SB = self.dlg.RF_User_Value_Input.value()
            RF_Value_SB_2 = self.dlg.RF_User_Value_Input_2.value()
            RF_Value_Average = (RF_Value_SB + RF_Value_SB_2) / 2
            self.dlg.RF_status.setText("Variables Set")
            self.dlg.RF_status.repaint()
            time.sleep(0.5)
            self.dlg.RF_status.setText("Processing...")
            self.dlg.RF_status.repaint()

        elif factor_no == 3:
            # polygonlayer = self.dlg.FIN_Input_Field.filePath()
            rasField = "rasField"
            FIN_Value_SB = self.dlg.FIN_User_Value_Input.value()
            self.dlg.FIN_status.setText("Variables Set")
            self.dlg.FIN_status.repaint()
            time.sleep(0.5)
            self.dlg.FIN_status.setText("Processing...")
            self.dlg.FIN_status.repaint()

        elif factor_no == 4:
            polygonlayer = self.dlg.SEC_Input_Field.filePath()
            rasField = self.dlg.SEC_rasField_CB.currentText()
            self.dlg.SEC_status.setText("Variables Set")
            self.dlg.SEC_status.repaint()
            time.sleep(0.5)
            self.dlg.SEC_status.setText("Processing...")
            self.dlg.SEC_status.repaint()

        elif factor_no == 5:
            polygonlayer = self.dlg.DIG_Input_Field.filePath()
            rasField = self.dlg.DIG_rasField_CB.currentText()
            if len(polygonlayer) < 1:
                rasField = "rasField"
                DIG_Value_SB = self.dlg.DIG_User_Value_Input.value()
            self.dlg.DIG_status.setText("Variables Set")
            self.dlg.DIG_status.repaint()
            time.sleep(0.5)
            self.dlg.DIG_status.setText("Processing...")
            self.dlg.DIG_status.repaint()

        elif factor_no == 6:
            csvFile = self.dlg.FCV_Input_Field.filePath()
            csvFile = f"file:///{csvFile.replace(os.sep, '/')}?type=csv&maxFields=10000&detectTypes=yes&xField=longitude&yField=latitude&crs=EPSG:4326&spatialIndex=no&subsetIndex=no&watchFile=no"
            rasField = "rasField"
            self.dlg.FCV_status.setText("Variables Set")
            self.dlg.FCV_status.repaint()
            time.sleep(0.5)
            self.dlg.FCV_status.setText("Processing...")
            self.dlg.FCV_status.repaint()

        elif factor_no == 7:
            pointlayer = self.dlg.WAS_Input_Field.filePath()
            #rasField = self.dlg.WAS_rasField_CB.currentText()
            rasField = "rasField"
            self.dlg.WAS_status.setText("Variables Set")
            self.dlg.WAS_status.repaint()
            time.sleep(0.5)
            self.dlg.WAS_status.setText("Processing...")
            self.dlg.WAS_status.repaint()

        # Convert countryLayer data to UTM CRS
        self.convertCRS(countryLayer, UTM_crs)
        shp_utm[rasField] = [0]
        countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

        #outputPathCountry = f"{workingDir}temp/countryBuff.shp"
        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": "memory:",
            },
        )

        countryUTMLayerBuf = buffer["OUTPUT"]

        # Convert spatial data to UTM CRS
        if factor_no in [1, 2, 3, 6]:
            pass
        elif factor_no in [5]:
            if len(polygonlayer) > 1:
                self.convertCRS(polygonlayer, UTM_crs)
            else:
                pass
        elif factor_no in [7]:
            self.convertCRS(pointlayer, UTM_crs)
        else:
            self.convertCRS(polygonlayer, UTM_crs)

        if rasField not in shp_utm.columns:
            shp_utm[rasField] = [0] * len(shp_utm)

        shp_utm[rasField] = shp_utm[rasField].astype(float)

        # Set variables required to conduct standardization of values
        Rmax = 100
        Rmin = 0
        m_max = 5
        m_min = 0
        if factor_no == 0:
            # Standardization formula
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            polygonUTM = QgsVectorLayer(shp_utm.to_json(), "polygonUTM", "ogr")

            clipPolygonUTM = processing.run(
                "native:clip",
                {
                    "INPUT": polygonUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            polygonUTM = clipPolygonUTM["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": polygonUTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [polygonUTM, difference],
                 "CRS": None,
                 "OUTPUT": "memory:"},
            )

            mergeOutput = Merge["OUTPUT"]

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Place Characterization"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.EDU_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.EDU_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.EDU_status.setText("Processing has been completed!")
            self.dlg.EDU_status.repaint()

        elif factor_no == 1:
            shp_utm[rasField] = WD_Value_SB
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            polygonUTM = QgsVectorLayer(shp_utm.to_json(), "polygonUTM", "ogr")

            clipPolygonUTM = processing.run(
                "native:clip",
                {
                    "INPUT": polygonUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            polygonUTM = clipPolygonUTM["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": polygonUTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [polygonUTM, difference], "CRS": None, "OUTPUT": "memory:"},
            )

            mergeOutput = Merge["OUTPUT"]

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Contextual"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.WD_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.WD_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.WD_status.setText("Processing has been completed!")
            self.dlg.WD_status.repaint()

        elif factor_no == 2:
            shp_utm[rasField] = RF_Value_Average
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            polygonUTM = QgsVectorLayer(shp_utm.to_json(), "polygonUTM", "ogr")

            clipPolygonUTM = processing.run(
                "native:clip",
                {
                    "INPUT": polygonUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            polygonUTM = clipPolygonUTM["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": polygonUTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [polygonUTM, difference], "CRS": None, "OUTPUT": "memory:"},
            )

            mergeOutput = Merge["OUTPUT"]

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Contextual"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.RF_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.RF_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.RF_status.setText("Processing has been completed!")
            self.dlg.RF_status.repaint()

        elif factor_no == 3:
            shp_utm[rasField] = FIN_Value_SB
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            polygonUTM = QgsVectorLayer(shp_utm.to_json(), "polygonUTM", "ogr")

            clipPolygonUTM = processing.run(
                "native:clip",
                {
                    "INPUT": polygonUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            polygonUTM = clipPolygonUTM["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": polygonUTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [polygonUTM, difference], "CRS": None, "OUTPUT": "memory:"},
            )

            mergeOutput = Merge["OUTPUT"]

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Contextual"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.FIN_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.FIN_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.FIN_status.setText("Processing has been completed!")
            self.dlg.FIN_status.repaint()

        elif factor_no == 4:
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            polygonUTM = QgsVectorLayer(shp_utm.to_json(), "polygonUTM", "ogr")

            clipPolygonUTM = processing.run(
                "native:clip",
                {
                    "INPUT": polygonUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            polygonUTM = clipPolygonUTM["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": polygonUTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [polygonUTM, difference], "CRS": None, "OUTPUT": "memory:"},
            )

            mergeOutput = Merge["OUTPUT"]

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Place Characterization"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.INC_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.INC_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.INC_status.setText("Processing has been completed!")
            self.dlg.INC_status.repaint()


        elif factor_no == 5:
            if len(polygonlayer) < 1:
                shp_utm[rasField] = DIG_Value_SB
            else:
                shp_utm[rasField] = shp_utm[rasField]
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            polygonUTM = QgsVectorLayer(shp_utm.to_json(), "polygonUTM", "ogr")

            clipPolygonUTM = processing.run(
                "native:clip",
                {
                    "INPUT": polygonUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            polygonUTM = clipPolygonUTM["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": polygonUTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [polygonUTM, difference], "CRS": None, "OUTPUT": "memory:"},
            )

            mergeOutput = Merge["OUTPUT"]

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Place Characterization"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.DIG_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.DIG_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.DIG_status.setText("Processing has been completed!")
            self.dlg.DIG_status.repaint()

        elif factor_no == 6:
            shp_utm[rasField] = 100
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max

            # csv conversion to shapefile

            temp = "temp"
            if os.path.exists(temp):
                pass
            else:
                os.mkdir(temp)

            outputPath = f"{workingDir}{temp}/acled.shp"
            crs = QgsCoordinateReferenceSystem('EPSG:4326')

            layer = QgsVectorLayer(csvFile, 'acled', 'delimitedtext')
            layer.setCrs(crs)
            save_options = QgsVectorFileWriter.SaveVectorOptions()

            save_options.driverName = "ESRI Shapefile"

            save_options.fileEncoding = "UTF-8"

            transform_context = QgsProject.instance().transformContext()
            error = QgsVectorFileWriter.writeAsVectorFormatV3(
                layer,
                outputPath,
                transform_context,
                save_options
            )

            if error[0] == QgsVectorFileWriter.NoError:
                print('Shapefile successfully created!')
            else:
                print('Error occurred:', error)

            csvFileLayer = outputPath
            self.convertCRS(csvFileLayer, UTM_crs)
            csvFileLayerUTM = QgsVectorLayer(shp_utm.to_json(), "csvFileLayerUTM", "ogr")

            clipCsvFileUTM = processing.run(
                "native:clip",
                {
                    "INPUT": csvFileLayerUTM,
                    "OVERLAY": countryUTMLayerBuf,
                    "OUTPUT": "memory:",
                }
            )

            csvFileLayerUTM = clipCsvFileUTM["OUTPUT"]

            gridExtent = countryUTMLayerBuf.extent()
            grid_params = {
                'TYPE': 2,  # Rectangle (polygon)
                'EXTENT': gridExtent,
                'HSPACING': 100,  # Horizontal spacing
                'VSPACING': 100,  # Vertical spacing
                'CRS': UTM_crs,
                'OUTPUT': "memory:"
            }

            grid_result = processing.run('native:creategrid', grid_params)
            grid_layer = grid_result['OUTPUT']

            field_name = 'reclass_va'
            if not grid_layer.fields().indexFromName(field_name) >= 0:
                grid_layer.dataProvider().addAttributes([QgsField(field_name, QVariant.Int)])
                grid_layer.updateFields()

            radius = self.dlg.FCV_Input_Radius.value() or 5000


            buffer_result = processing.run(
                "native:buffer",
                {
                    "INPUT": csvFileLayerUTM,
                    "DISTANCE": radius,
                    "SEGMENTS": 5,
                    "END_CAP_STYLE": 0,
                    "JOIN_STYLE": 0,
                    "MITER_LIMIT": 2,
                    "DISSOLVE": False,
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": "memory:",
                },
            )

            buffer_layer = buffer_result["OUTPUT"]

            event_type_scores = {
                'Battle': 0,
                'Explosions': 0,
                'Remote violence': 1,
                'Violence against civilians': 2,
                'Protests': 4,
                'Riots': 4,
                'no_event': 5
            }

            buffer_layer_provider = buffer_layer.dataProvider()
            buffer_layer_provider.addAttributes([QgsField("score", QVariant.Int)])
            buffer_layer.updateFields()

            buffer_layer.startEditing()
            for feature in buffer_layer.getFeatures():
                event_type = feature['event_type']
                score = event_type_scores.get(event_type, event_type_scores['no_event'])
                feature.setAttribute("score", score)
                buffer_layer.updateFeature(feature)

            buffer_layer.commitChanges()

            grid_layer_provider = grid_layer.dataProvider()
            grid_layer_provider.addAttributes([QgsField("score", QVariant.Int)])
            grid_layer.updateFields()


            # Create a spatial index for the buffer layer
            spatial_index = QgsSpatialIndex(buffer_layer.getFeatures())

            # Start editing the grid layer
            grid_layer.startEditing()

            for grid_feature in grid_layer.getFeatures():
                grid_geom = grid_feature.geometry()
                intersecting_ids = spatial_index.intersects(grid_geom.boundingBox())

                min_score = event_type_scores['no_event']

                # Check intersections and find the minimum score (most serious event)
                for buffer_id in intersecting_ids:
                    buffer_feature = buffer_layer.getFeature(buffer_id)
                    buffer_geom = buffer_feature.geometry()

                    if grid_geom.intersects(buffer_geom):
                        buffer_score = buffer_feature['score']
                        if buffer_score < min_score:
                            min_score = buffer_score

                # Set the minimum score (most serious event) to the grid cell
                grid_feature.setAttribute('score', min_score)
                grid_layer.updateFeature(grid_feature)
            grid_layer.commitChanges()

            outputPath1 = f"{workingDir}{temp}/clipBuff.shp"

            clipBuffer = processing.run(
                "native:clip",
                {
                    "INPUT": grid_layer,
                    "OVERLAY": countryUTMLayer,
                    "OUTPUT": "memory:",
                }
            )

            grid_layer = clipBuffer["OUTPUT"]

            outputPath2 = f"{workingDir}{temp}/difference.shp"
            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": grid_layer,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]
            outputPath3 = f"{workingDir}{temp}/merge.shp"
            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [difference, grid_layer], "CRS": None, "OUTPUT": "memory:"},
            )

            grid_layer = Merge["OUTPUT"]

            mergeOutput = grid_layer

            # Get the width and height of the extent
            extent = mergeOutput.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Place Characterization"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.FCV_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": "score",
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.FCV_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.FCV_status.setText("Processing has been completed!")
            self.dlg.FCV_status.repaint()

        elif factor_no == 7:
            shp_utm[rasField] = 99
            shp_utm[rasField] = (shp_utm[rasField] - Rmin) / (Rmax - Rmin) * m_max
            pointUTM = QgsVectorLayer(shp_utm.to_json(), "pointUTM", "ogr")
            #
            #shp_utm[rasField] = [0]

            #for i in roadType_Score:
            #    shp_utm.loc[shp_utm[roadTypeField] == i[0], "Score"] = i[1]

            #shp_utm[rasField] = shp_utm[rasField].astype(int)
            gridExtent = countryUTMLayerBuf.extent()
            grid_params = {
                'TYPE': 2,  # Rectangle (polygon)
                'EXTENT': gridExtent,
                'HSPACING': 100,  # Horizontal spacing
                'VSPACING': 100,  # Vertical spacing
                'CRS': UTM_crs,
                'OUTPUT': "memory:"
            }

            grid_result = processing.run('native:creategrid', grid_params)
            grid_layer = grid_result['OUTPUT']

            field_name = 'reclass_va'
            if not grid_layer.fields().indexFromName(field_name) >= 0:
                grid_layer.dataProvider().addAttributes([QgsField(field_name, QVariant.Int)])
                grid_layer.updateFields()

            self.dlg.WAS_status.setText("Processing...")
            self.dlg.WAS_status.repaint()

            #dif_out = f"{workingDir}/temp/tempBuf.shp"

            #Buffer = processing.run(
            #    "native:buffer",
            #{
            #    "INPUT": pointUTM,
            #    "DISTANCE": 250,
            #    "SEGMENTS": 5,
            #    "END_CAP_STYLE": 0,
            #    "JOIN_STYLE": 0,
            #    "MITER_LIMIT": 2,
            #    "DISSOLVE": False,
            #    "SEPARATE_DISJOINT": False,
            #    "OUTPUT": "memory:",
            #},
            #)

            # Count the number of buffers within each grid cell
            #buffer_layer = Buffer['OUTPUT']
            index = QgsSpatialIndex(pointUTM.getFeatures())
            reclass_vals = {}

            for grid_feat in grid_layer.getFeatures():
                intersecting_ids = index.intersects(grid_feat.geometry().boundingBox())
                num_waterpoints = len(intersecting_ids)

                if num_waterpoints >= 2:
                    reclass_val = 5
                elif num_waterpoints == 1:
                    reclass_val = 3
                else:
                    reclass_val = 0

                reclass_vals[grid_feat.id()] = reclass_val

            grid_layer.startEditing()
            for grid_feat in grid_layer.getFeatures():
                grid_layer.changeAttributeValue(grid_feat.id(), grid_layer.fields().indexFromName(field_name),
                                                reclass_vals[grid_feat.id()])
            grid_layer.commitChanges()

            #dif_out = f"{workingDir}/{tempDir}/Dif.shp"

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": countryUTMLayerBuf,
                    "OVERLAY": grid_layer,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [grid_layer, difference], "CRS": UTM_crs, "OUTPUT": "memory:"},
            )

            merge = Merge["OUTPUT"]

            dif_out = f"{workingDir}/temp/Dif.shp"
            mergeClip = processing.run(
                "native:clip",
                {
                    "INPUT": merge,
                    "OVERLAY": countryUTMLayer,
                    "OUTPUT": "memory:",
                }
            )

            mergeOutput = mergeClip["OUTPUT"]

            # Get the width and height of the extent

            extent = countryUTMLayerBuf.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            Dimension = "Place Characterization"
            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            rasOutput = self.dlg.WAS_Output_Field.text()

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": field_name,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            self.dlg.WAS_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.WAS_status.setText("Processing Complete!")
            self.dlg.WAS_status.repaint()

    def ServiceArea(self, factor_no):
        """
        This function is used to conduct a service area network analysis facilitated using Openrouteservices' (ORS) isochrones service. Isochrones are derived from the OpenStreetMap (OSM) road network
        with the use of travel distances or times as input to estimate ease of access to the input locations at five incrementally increasing measurement intervals. The largest interval being the
        maximum distance or time taken to reach these locations. The algorithm produces five catchment areas based on the road network. A scoring system ranging from 5 to 1 is assigned to the catchment area
        polygons, reflecting the decreasing order of accessibility. Areas outside these catchment areas receive a score of zero.

        Service Area Analysis is undertaken using the openrouteservice API and OpenStreetMap data.  openrouteservice.org by HeiGIT | Road network data  OpenStreetMap contributors

        Factors it is applied:
            Accessibility Dimension
                - Women's Travel Patterns
                - Access to Public Transport
                - Access to Education and Training Facilities
                - Access to Health Facilities
                - Access to Finance Facilities
        """
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        tempDir = f"{workingDir}temp"
        Dimension = "Accessibility"

        if os.path.exists(Dimension):
            pass
        else:
            os.mkdir(Dimension)

        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(1)
        os.mkdir(tempDir)

        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()

        # INPUT
        if factor_no == 0:
            self.dlg.PBT_status.setText("")
            self.dlg.PBT_status.repaint()
            FaciltyPointlayer = self.dlg.PBT_Input_Field.filePath()
            ranges = self.dlg.PBT_Ranges_Field.text()
            rasOutput = f"{self.dlg.PBT_Output_Field.text()}"
            mergeOutput = (
                f"{workingDir}{Dimension}/SA_SHP/{rasOutput[:-4]}_Service_Area.shp"
            )

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            self.dlg.PBT_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            if self.dlg.PBT_mode_CB.currentText() == "Driving":
                mode = 0
            elif self.dlg.PBT_mode_CB.currentText() == "Walking":
                mode = 6

            if self.dlg.PBT_measurement_CB.currentText() == "Time":
                measurement = 0
                ranges_field = "AA_MINS"
            elif self.dlg.PBT_measurement_CB.currentText() == "Distance":
                measurement = 1
                ranges_field = "AA_METERS"

            self.dlg.PBT_status.setText("Variables Set")
            self.dlg.PBT_status.repaint()
            time.sleep(0.5)
            self.dlg.PBT_status.setText("Processing...")
            self.dlg.PBT_status.repaint()

        elif factor_no == 1:
            self.dlg.ETF_status.setText("")
            self.dlg.ETF_status.repaint()
            FaciltyPointlayer = self.dlg.ETF_Input_Field.filePath()
            ranges = self.dlg.ETF_Ranges_Field.text()
            rasOutput = f"{self.dlg.ETF_Output_Field.text()}"
            mergeOutput = (
                f"{workingDir}{Dimension}/SA_SHP/{rasOutput[:-4]}_Service_Area.shp"
            )

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            self.dlg.ETF_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            if self.dlg.ETF_mode_CB.currentText() == "Driving":
                mode = 0
            elif self.dlg.ETF_mode_CB.currentText() == "Walking":
                mode = 6

            if self.dlg.ETF_measurement_CB.currentText() == "Time":
                measurement = 0
                ranges_field = "AA_MINS"
            elif self.dlg.ETF_measurement_CB.currentText() == "Distance":
                measurement = 1
                ranges_field = "AA_METERS"

            self.dlg.ETF_status.setText("Variables Set")
            self.dlg.ETF_status.repaint()
            time.sleep(0.5)
            self.dlg.ETF_status.setText("Processing...")
            self.dlg.ETF_status.repaint()

        elif factor_no == 3:
            self.dlg.HEA_status.setText("")
            self.dlg.HEA_status.repaint()
            FaciltyPointlayer = self.dlg.HEA_Input_Field.filePath()
            ranges = self.dlg.HEA_Ranges_Field.text()
            rasOutput = f"{self.dlg.HEA_Output_Field.text()}"
            mergeOutput = (
                f"{workingDir}{Dimension}/SA_SHP/{rasOutput[:-4]}_Service_Area.shp"
            )

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            self.dlg.HEA_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            if self.dlg.HEA_mode_CB.currentText() == "Driving":
                mode = 0
            elif self.dlg.HEA_mode_CB.currentText() == "Walking":
                mode = 6

            if self.dlg.HEA_measurement_CB.currentText() == "Time":
                measurement = 0
                ranges_field = "AA_MINS"
            elif self.dlg.HEA_measurement_CB.currentText() == "Distance":
                measurement = 1
                ranges_field = "AA_METERS"

            self.dlg.HEA_status.setText("Variables Set")
            self.dlg.HEA_status.repaint()
            time.sleep(0.5)
            self.dlg.HEA_status.setText("Processing...")
            self.dlg.HEA_status.repaint()

        elif factor_no == 4:
            self.dlg.FIF_status.setText("")
            self.dlg.FIF_status.repaint()
            FaciltyPointlayer = self.dlg.FIF_Input_Field.filePath()
            ranges = self.dlg.FIF_Ranges_Field.text()
            rasOutput = f"{self.dlg.FIF_Output_Field.text()}"
            mergeOutput = (
                f"{workingDir}{Dimension}/SA_SHP/{rasOutput[:-4]}_Service_Area.shp"
            )

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            self.dlg.FIF_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

            if self.dlg.FIF_mode_CB.currentText() == "Driving":
                mode = 0
            elif self.dlg.FIF_mode_CB.currentText() == "Walking":
                mode = 6

            if self.dlg.FIF_measurement_CB.currentText() == "Time":
                measurement = 0
                ranges_field = "AA_MINS"
            elif self.dlg.FIF_measurement_CB.currentText() == "Distance":
                measurement = 1
                ranges_field = "AA_METERS"

            self.dlg.FIF_status.setText("Variables Set")
            self.dlg.FIF_status.repaint()
            time.sleep(0.5)
            self.dlg.FIF_status.setText("Processing...")
            self.dlg.FIF_status.repaint()

        elif factor_no == 5:
            self.dlg.WTP_status.setText("")
            self.dlg.WTP_status.repaint()
            input_fields = [
                self.dlg.WTP_Input_Field,
                self.dlg.WTP_Input_Field_2,
                self.dlg.WTP_Input_Field_3,
                self.dlg.WTP_Input_Field_4
            ]

            FaciltyPointlayerList = []

            for input_field in input_fields:
                file_path = input_field.filePath()
                if file_path:
                    FaciltyPointlayerList.append(file_path)

            ranges = self.dlg.WTP_Ranges_Field.text()
            rasOutput = f"{self.dlg.WTP_FacilityOutput_Field.text()}"
            #mergeOutput = (
            #    f"{workingDir}{Dimension}/SA_SHP/{rasOutput[:-4]}_{shapefile_name}_Service_Area.shp"
            #)

            if self.dlg.WTP_mode_CB.currentText() == "Driving":
                mode = 0
            elif self.dlg.WTP_mode_CB.currentText() == "Walking":
                mode = 6

            if self.dlg.WTP_measurement_CB.currentText() == "Time":
                measurement = 0
                ranges_field = "AA_MINS"
            elif self.dlg.WTP_measurement_CB.currentText() == "Distance":
                measurement = 1
                ranges_field = "AA_METERS"

            self.dlg.WTP_status.setText("Variables Set")
            self.dlg.WTP_status.repaint()
            time.sleep(0.5)
            self.dlg.WTP_status.setText("Processing...")
            self.dlg.WTP_status.repaint()

        # OUTPUT
        SAOutput_utm = f"{tempDir}/SA_OUTPUT_UTM.shp"
        temp_merge = f"{tempDir}/temp_merge.shp"

        if factor_no == 5:
            # Do stuff
            facility_data = 0
            for FaciltyPointlayer in FaciltyPointlayerList:
                os.chdir(workingDir)
                rasOutput = ""
                rasOutput = f"{self.dlg.WTP_FacilityOutput_Field.text()}"
                base_name = os.path.basename(FaciltyPointlayer)
                shapefile_name, _ = os.path.splitext(base_name)
                mergeOutput = (
                f"{workingDir}{Dimension}/SA_SHP/{rasOutput[:-4]}_{shapefile_name}_Service_Area.shp"
                )
                gdf = gpd.read_file(FaciltyPointlayer)

                subset_size = 5
                subsets = []

                for i in range(0, len(gdf), subset_size):
                    subset = gdf.iloc[i: i + subset_size]
                    subset = QgsVectorLayer(subset.to_json(), "mygeojson", "ogr")
                    subset_outfile = (
                        f"{tempDir}/SA_subset_{i + subset_size}_{rasOutput[:-4]}_{shapefile_name}.shp"
                    )

                    Service_Area = processing.run(
                        "ORS Tools:isochrones_from_layer",
                        {
                            "INPUT_PROVIDER": 0,
                            "INPUT_PROFILE": mode,
                            "INPUT_POINT_LAYER": subset,
                            "INPUT_FIELD": "",
                            "INPUT_METRIC": measurement,
                            "INPUT_RANGES": ranges,
                            "INPUT_SMOOTHING": None,
                            "LOCATION_TYPE": 0,
                            "INPUT_AVOID_FEATURES": [],
                            "INPUT_AVOID_BORDERS": None,
                            "INPUT_AVOID_COUNTRIES": "",
                            "INPUT_AVOID_POLYGONS": None,
                            "OUTPUT": subset_outfile,
                        },
                    )

                    subsets.append(subset_outfile)

                    batch = i + subset_size

                    if batch > len(gdf):
                        batch = len(gdf)

                    if factor_no == 0:
                        self.dlg.PBT_status.setText(f"Processing... {batch} of {len(gdf)}")
                        self.dlg.PBT_status.repaint()
                    elif factor_no == 1:
                        self.dlg.ETF_status.setText(f"Processing... {batch} of {len(gdf)}")
                        self.dlg.ETF_status.repaint()
                    elif factor_no == 3:
                        self.dlg.HEA_status.setText(f"Processing... {batch} of {len(gdf)}")
                        self.dlg.HEA_status.repaint()
                    elif factor_no == 4:
                        self.dlg.FIF_status.setText(f"Processing... {batch} of {len(gdf)}")
                        self.dlg.FIF_status.repaint()
                    elif factor_no == 5:
                        self.dlg.WTP_status.setText(f"Processing... {batch} of {len(gdf)} for {shapefile_name}")
                        self.dlg.WTP_status.repaint()

                Merge = processing.run(
                    "native:mergevectorlayers",
                    {
                        "LAYERS": subsets,
                        "CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "OUTPUT": SAOutput_utm,
                    },
                )

                time.sleep(0.5)

                # self.convertCRS(SAOutput_utm, UTM_crs)
                # SA_df = shp_utm
                SA_df = gpd.read_file(SAOutput_utm)
                no_spaces_string = "".join(ranges.split())
                ranges_list = no_spaces_string.split(",")
                int_ranges_list = [int(x) for x in ranges_list]
                int_ranges_list.sort()

                range_subsets = []

                for i in int_ranges_list:
                    range_subset = SA_df[SA_df[ranges_field] == i]
                    range_subset = QgsVectorLayer(range_subset.to_json(), f"range_{i}", "ogr")
                    temp_out = f"{tempDir}/{rasOutput[:-4]}Range_dis_{i}.shp"

                    dissolve = processing.run(
                        "native:dissolve",
                        {
                            "INPUT": range_subset,
                            "FIELD": [],
                            "SEPARATE_DISJOINT": False,
                            "OUTPUT": temp_out,
                        },
                    )

                    Range_output = dissolve["OUTPUT"]

                    range_subsets.append(range_subset)

                Merge_list = []

                for i in range(-1, -len(range_subsets), -1):
                    output = (
                        f"{tempDir}/band_dif_{int_ranges_list[i]}_-_{int_ranges_list[i - 1]}.shp"
                    )
                    # Merge_list.append(output)
                    difference = processing.run(
                        "native:difference",
                        {
                            "INPUT": range_subsets[i],
                            "OVERLAY": range_subsets[i - 1],
                            "OUTPUT": "memory:",
                            "GRID_SIZE": None,
                        },
                    )
                    diff_output = difference["OUTPUT"]

                    dissolve = processing.run(
                        "native:dissolve",
                        {
                            "INPUT": diff_output,
                            "FIELD": [],
                            "SEPARATE_DISJOINT": False,
                            "OUTPUT": "memory:",
                        },
                    )

                    dis_output = dissolve["OUTPUT"]
                    Merge_list.append(dis_output)

                dissolve = processing.run(
                    "native:dissolve",
                    {
                        "INPUT": range_subsets[0],
                        "FIELD": [],
                        "SEPARATE_DISJOINT": False,
                        "OUTPUT": "memory:",
                    },
                )

                dis_output = dissolve["OUTPUT"]
                Merge_list.append(dis_output)

                print(f"Path: {os.getcwd()}")

                if os.path.exists(f"{Dimension}/SA_SHP"):
                    pass
                else:
                    os.mkdir(f"{Dimension}/SA_SHP")

                feedback = QgsProcessingFeedback()

                Merge = processing.run(
                    "native:mergevectorlayers",
                    {"LAYERS": Merge_list, "CRS": None, "OUTPUT": f"{mergeOutput}"},
                )

                if Merge is not None and "OUTPUT" in Merge:
                    print(f"Processing completed successfully")

                    # Do something

                    merge_df = gpd.read_file(f"{mergeOutput}")
                    merge_df["rasField"] = [1, 2, 3, 4, 5]
                    merge_SA_UTM = QgsVectorLayer(merge_df.to_json(), "merge_SA_utm", "ogr")

                    # Convert countryLayer data to UTM CRS
                    self.convertCRS(countryLayer, UTM_crs)
                    shp_utm["rasField"] = [0]
                    shp_utm_ = QgsVectorLayer(shp_utm.to_json(), "shp_utm", "ogr")
                    # shp_utm.to_file(countryUTMLayer)

                    buffer = processing.run(
                        "native:buffer",
                        {
                            "INPUT": shp_utm_,
                            "DISTANCE": self.BUFFER_DISTANCE,
                            "SEGMENTS": 5,
                            "END_CAP_STYLE": 0,
                            "JOIN_STYLE": 0,
                            "MITER_LIMIT": 2,
                            "DISSOLVE": True,
                            "SEPARATE_DISJOINT": False,
                            "OUTPUT": "memory:",
                        },
                    )

                    buffer_output = buffer["OUTPUT"]

                    clipAOI = processing.run(
                        "native:clip",
                        {
                            "INPUT": merge_SA_UTM,
                            "OVERLAY": buffer_output,
                            "OUTPUT": "memory:",
                        }
                    )

                    merge_SA_UTM = clipAOI["OUTPUT"]

                    Difference = processing.run(
                        "native:difference",
                        {
                            "INPUT": buffer_output,
                            "OVERLAY": merge_SA_UTM,
                            "OUTPUT": "memory:",
                            "GRID_SIZE": None,
                        },
                    )

                    diff_output = Difference["OUTPUT"]

                    Merge = processing.run(
                        "native:mergevectorlayers",
                        {"LAYERS": [merge_SA_UTM, diff_output], "CRS": None, "OUTPUT": "memory:"},
                    )

                    merge_output = Merge["OUTPUT"]

                    extent = merge_output.extent()
                    raster_width = int(extent.width() / pixelSize)
                    raster_height = int(extent.height() / pixelSize)

                    rasOutput = f"{self.dlg.WTP_FacilityOutput_Field.text()[:-4]}{shapefile_name}.tif"

                    if os.path.exists(Dimension):
                        os.chdir(Dimension)
                    else:
                        os.mkdir(Dimension)
                        os.chdir(Dimension)

                    if factor_no == 5:
                        Output_Folder = "WTP"
                        if os.path.exists(Output_Folder):
                            os.chdir(Output_Folder)
                        else:
                            os.mkdir(Output_Folder)
                            os.chdir(Output_Folder)

                        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
                        styleFileDestination = f"{workingDir}{Dimension}/{Output_Folder}"
                        styleFile = f"{rasOutput.split('.')[0]}.qml"
                    else:
                        pass

                    rasterize = processing.run(
                        "gdal:rasterize",
                        {
                            "INPUT": merge_output,
                            "FIELD": "rasField",
                            "BURN": 0,
                            "USE_Z": False,
                            "UNITS": 0,
                            "WIDTH": raster_width,
                            "HEIGHT": raster_height,
                            "EXTENT": None,
                            "NODATA": -9999,
                            "OPTIONS": "",
                            "DATA_TYPE": 5,
                            "INIT": None,
                            "INVERT": False,
                            "EXTRA": "",
                            "OUTPUT": rasOutput,
                        },
                    )

                    facility_data = facility_data + 1

                    shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                    if factor_no == 0:
                        self.dlg.PBT_status.setText("Processing Complete!")
                        self.dlg.PBT_status.repaint()

                    elif factor_no == 1:
                        self.dlg.ETF_status.setText("Processing Complete!")
                        self.dlg.ETF_status.repaint()

                    elif factor_no == 3:
                        self.dlg.HEA_status.setText("Processing Complete!")
                        self.dlg.HEA_status.repaint()

                    elif factor_no == 4:
                        self.dlg.FIF_status.setText("Processing Complete!")
                        self.dlg.FIF_status.repaint()

                    elif factor_no == 5:
                        self.dlg.WTP_status.setText(f"Processing Complete for {shapefile_name}!")
                        self.dlg.WTP_status.repaint()
                else:
                    print(f"Processing failed")
        else:
            # Do more stuff

            gdf = gpd.read_file(FaciltyPointlayer)

            subset_size = 5
            subsets = []

            for i in range(0, len(gdf), subset_size):
                subset = gdf.iloc[i: i + subset_size]
                print(f"subset:{subset}")
                subset = QgsVectorLayer(subset.to_json(), "mygeojson", "ogr")
                subset_outfile = (
                    f"{tempDir}/SA_subset_{i + subset_size}_{rasOutput[:-4]}.shp"
                )

                Service_Area = processing.run(
                    "ORS Tools:isochrones_from_layer",
                    {
                        "INPUT_PROVIDER": 0,
                        "INPUT_PROFILE": mode,
                        "INPUT_POINT_LAYER": subset,
                        "INPUT_FIELD": "",
                        "INPUT_METRIC": measurement,
                        "INPUT_RANGES": ranges,
                        "INPUT_SMOOTHING": None,
                        "LOCATION_TYPE": 0,
                        "INPUT_AVOID_FEATURES": [],
                        "INPUT_AVOID_BORDERS": None,
                        "INPUT_AVOID_COUNTRIES": "",
                        "INPUT_AVOID_POLYGONS": None,
                        "OUTPUT": subset_outfile,
                    },
                )

                subsets.append(subset_outfile)

                batch = i + subset_size

                if batch > len(gdf):
                    batch = len(gdf)

                if factor_no == 0:
                    self.dlg.PBT_status.setText(f"Processing... {batch} of {len(gdf)}")
                    self.dlg.PBT_status.repaint()
                elif factor_no == 1:
                    self.dlg.ETF_status.setText(f"Processing... {batch} of {len(gdf)}")
                    self.dlg.ETF_status.repaint()
                elif factor_no == 3:
                    self.dlg.HEA_status.setText(f"Processing... {batch} of {len(gdf)}")
                    self.dlg.HEA_status.repaint()
                elif factor_no == 4:
                    self.dlg.FIF_status.setText(f"Processing... {batch} of {len(gdf)}")
                    self.dlg.FIF_status.repaint()
                elif factor_no == 5:
                    self.dlg.WTP_status.setText(f"Processing... {batch} of {len(gdf)}")
                    self.dlg.WTP_status.repaint()

            Merge = processing.run(
                "native:mergevectorlayers",
                {
                    "LAYERS": subsets,
                    "CRS": QgsCoordinateReferenceSystem(UTM_crs),
                    "OUTPUT": SAOutput_utm,
                },
            )

            time.sleep(0.5)

            # self.convertCRS(SAOutput_utm, UTM_crs)
            # SA_df = shp_utm
            SA_df = gpd.read_file(SAOutput_utm)
            no_spaces_string = "".join(ranges.split())
            ranges_list = no_spaces_string.split(",")
            int_ranges_list = [int(x) for x in ranges_list]
            int_ranges_list.sort()

            range_subsets = []

            for i in int_ranges_list:
                range_subset = SA_df[SA_df[ranges_field] == i]
                range_subset = QgsVectorLayer(range_subset.to_json(), f"range_{i}", "ogr")
                temp_out = f"{tempDir}/{rasOutput[:-4]}Range_dis_{i}.shp"

                dissolve = processing.run(
                    "native:dissolve",
                    {
                        "INPUT": range_subset,
                        "FIELD": [],
                        "SEPARATE_DISJOINT": False,
                        "OUTPUT": temp_out,
                    },
                )

                Range_output = dissolve["OUTPUT"]

                range_subsets.append(range_subset)

            Merge_list = []

            for i in range(-1, -len(range_subsets), -1):
                output = (
                    f"{tempDir}/band_dif_{int_ranges_list[i]}_-_{int_ranges_list[i - 1]}.shp"
                )
                # Merge_list.append(output)
                difference = processing.run(
                    "native:difference",
                    {
                        "INPUT": range_subsets[i],
                        "OVERLAY": range_subsets[i - 1],
                        "OUTPUT": "memory:",
                        "GRID_SIZE": None,
                    },
                )
                diff_output = difference["OUTPUT"]

                dissolve = processing.run(
                    "native:dissolve",
                    {
                        "INPUT": diff_output,
                        "FIELD": [],
                        "SEPARATE_DISJOINT": False,
                        "OUTPUT": "memory:",
                    },
                )

                dis_output = dissolve["OUTPUT"]
                Merge_list.append(dis_output)

            dissolve = processing.run(
                "native:dissolve",
                {
                    "INPUT": range_subsets[0],
                    "FIELD": [],
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": "memory:",
                },
            )

            dis_output = dissolve["OUTPUT"]
            Merge_list.append(dis_output)

            if os.path.exists(f"{Dimension}/SA_SHP"):
                pass
            else:
                os.mkdir(f"{Dimension}/SA_SHP")

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": Merge_list, "CRS": None, "OUTPUT": f"{mergeOutput}"},
            )

            time.sleep(0.5)

            merge_df = gpd.read_file(f"{mergeOutput}")
            merge_df["rasField"] = [1, 2, 3, 4, 5]
            merge_SA_UTM = QgsVectorLayer(merge_df.to_json(), "merge_SA_utm", "ogr")

            # Convert countryLayer data to UTM CRS
            self.convertCRS(countryLayer, UTM_crs)
            shp_utm["rasField"] = [0]
            shp_utm_ = QgsVectorLayer(shp_utm.to_json(), "shp_utm", "ogr")
            # shp_utm.to_file(countryUTMLayer)

            buffer = processing.run(
                "native:buffer",
                {
                    "INPUT": shp_utm_,
                    "DISTANCE": self.BUFFER_DISTANCE,
                    "SEGMENTS": 5,
                    "END_CAP_STYLE": 0,
                    "JOIN_STYLE": 0,
                    "MITER_LIMIT": 2,
                    "DISSOLVE": True,
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": "memory:",
                },
            )

            buffer_output = buffer["OUTPUT"]

            clipAOI = processing.run(
                "native:clip",
                {
                    "INPUT": merge_SA_UTM,
                    "OVERLAY": buffer_output,
                    "OUTPUT": "memory:",
                }
            )

            merge_SA_UTM = clipAOI["OUTPUT"]

            Difference = processing.run(
                "native:difference",
                {
                    "INPUT": buffer_output,
                    "OVERLAY": merge_SA_UTM,
                    "OUTPUT": "memory:",
                    "GRID_SIZE": None,
                },
            )

            diff_output = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [merge_SA_UTM, diff_output], "CRS": None, "OUTPUT": "memory:"},
            )

            merge_output = Merge["OUTPUT"]

            extent = merge_output.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            if os.path.exists(Dimension):
                os.chdir(Dimension)
            else:
                os.mkdir(Dimension)
                os.chdir(Dimension)

            if factor_no == 5:
                Output_Folder = "WTP"
                if os.path.exists(Output_Folder):
                    os.chdir(Output_Folder)
                else:
                    os.mkdir(Output_Folder)
                    os.chdir(Output_Folder)

                styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
                styleFileDestination = f"{workingDir}{Dimension}/{Output_Folder}"
                styleFile = f"{rasOutput.split('.')[0]}.qml"
            else:
                pass

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": merge_output,
                    "FIELD": "rasField",
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            if factor_no == 0:
                self.dlg.PBT_status.setText("Processing Complete!")
                self.dlg.PBT_status.repaint()

            elif factor_no == 1:
                self.dlg.ETF_status.setText("Processing Complete!")
                self.dlg.ETF_status.repaint()

            elif factor_no == 3:
                self.dlg.HEA_status.setText("Processing Complete!")
                self.dlg.HEA_status.repaint()

            elif factor_no == 4:
                self.dlg.FIF_status.setText("Processing Complete!")
                self.dlg.FIF_status.repaint()

            elif factor_no == 5:
                self.dlg.WTP_status.setText("Processing Complete!")
                self.dlg.WTP_status.repaint()

    def wtp_aggregate(self):
        """
        This function is used in combination with the "ServiceArea" function. Due to women's travel patterns involving numerous locations and/or facilities a service area network analysis
        has to be conducted numerous times. This function aggregates each of the service area analysis relating to women's travel patterns into a single standardized raster file.

        Factors it is applied:
            Accessibility Dimension
                - Women's Travel Patterns
        """
        self.dlg.WTPAGG_status.setText("")
        self.dlg.WTPAGG_status.repaint()
        # OUTPUT
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        Dimension = "Accessibility"
        WTP_Folder = f"{Dimension}/WTP"

        if os.path.exists(WTP_Folder):
            os.chdir(WTP_Folder)
        else:
            pass

        rasOutput = self.dlg.WTP_AGGOutput_Field.text()

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        tif_list = [f for f in os.listdir(os.getcwd()) if f.endswith(".tif")]
        raster_list = []
        nodata_masks = []

        for ras in tif_list:
            with rasterio.open(ras) as src:
                raster_data = src.read(1)
                raster_list.append(raster_data)
                nodata_masks.append(raster_data == src.nodata)
                meta1 = src.meta

        len_raster_list = len(raster_list)
        cumulative_sum = np.zeros_like(raster_list[0], dtype=np.float32)
        valid_count = np.zeros_like(raster_list[0], dtype=np.float32)

        for i in range(len_raster_list):
            value = raster_list[i]
            mask = ~nodata_masks[i]  # Invert the nodata mask
            cumulative_sum += np.where(mask, value, 0)
            valid_count += mask.astype(np.float32)

        # Avoid division by zero and set nodata value to -9999
        aggregation = np.where(valid_count > 0, cumulative_sum / valid_count, -9999)
        os.chdir("..")

        meta1.update(dtype=rasterio.float32, nodata=-9999)

        with rasterio.open(rasOutput, "w", **meta1) as dst:
            dst.write(aggregation.astype(rasterio.float32), 1)

        self.dlg.WTP_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.WTPAGG_status.setText("Processing Complete!")
        self.dlg.WTPAGG_status.repaint()

        os.chdir(workingDir)

    def sec_aggregate(self):
        """
        This function is used in combination with the "Rasterization" function. Due to security, or lack thereof, involving numerous incident types, rasterization of each type
        has to be conducted. This function aggregates each of the rasterized incident types relating to security into a single standardized raster file.

        Factors it is applied:
            Place Characterization Dimension
                - Security
        """
        self.dlg.SECAGG_status.setText("")
        self.dlg.SECAGG_status.repaint()
        # OUTPUT
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        Dimension = "Place Characterization"
        SEC_Folder = f"{Dimension}/SEC"

        if os.path.exists(SEC_Folder):
            os.chdir(SEC_Folder)
        else:
            pass

        rasOutput = self.dlg.SEC_AGGOutput_Field.text()

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        tif_list = [f for f in os.listdir(os.getcwd()) if f.endswith(".tif")]
        raster_list = []
        nodata_masks = []

        for ras in tif_list:
            with rasterio.open(ras) as src:
                raster_data = src.read(1)
                raster_list.append(raster_data)
                nodata_masks.append(raster_data == src.nodata)
                meta1 = src.meta

        len_raster_list = len(raster_list)
        cumulative_sum = np.zeros_like(raster_list[0], dtype=np.float32)
        valid_count = np.zeros_like(raster_list[0], dtype=np.float32)

        for i in range(len_raster_list):
            value = raster_list[i]
            mask = ~nodata_masks[i]  # Invert the nodata mask
            cumulative_sum += np.where(mask, value, 0)
            valid_count += mask.astype(np.float32)

        # Avoid division by zero and set nodata value to -9999
        aggregation = np.where(valid_count > 0, cumulative_sum / valid_count, -9999)
        os.chdir("..")

        meta1.update(dtype=rasterio.float32, nodata=-9999)

        with rasterio.open(rasOutput, "w", **meta1) as dst:
            dst.write(aggregation.astype(rasterio.float32), 1)

        self.dlg.SEC_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.SECAGG_status.setText("Processing Complete!")
        self.dlg.SECAGG_status.repaint()

        os.chdir(workingDir)

    def walkability(self):
        """
        This function is used in combination with the "TypeSet" and "uniqueValue" functions to execute the Active Transports rasterization algorithm.
        It buffers the road network by 250m and rasterizes the buffer polygons according to the scoring assigned to the unique values.

        Factors it is applied:
            Place Characterization Dimension
                - Active Transport
        """
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        tempDir = "temp"
        Dimension = "Place Characterization"

        if os.path.exists(Dimension):
            pass
        else:
            os.mkdir(Dimension)

        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        streetCrossingLayer = self.dlg.WLK_Input_Field.filePath()
        blockLayer = self.dlg.WLK_Input_Field_4.filePath()
        input_fields = [
            self.dlg.WLK_Input_Field_2,
            self.dlg.WLK_Input_Field_3
        ]

        lineLayerList = []

        for input_field in input_fields:
            file_path = input_field.filePath()
            if file_path:
                lineLayerList.append(file_path)
        #roadTypeField = self.dlg.WLK_roadTypeField_CB.currentText()
        #roadType_Score = ast.literal_eval(self.dlg.WLK_typeScore_Field.text())
        rasField = "Score"

        self.dlg.WLK_status_2.setText("Variables Set")
        self.dlg.WLK_status_2.repaint()
        time.sleep(0.5)
        self.dlg.WLK_status_2.setText("Processing...")
        self.dlg.WLK_status_2.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        shp_utm[rasField] = [0]
        countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

        if lineLayerList is not None:
            for lineLayer in lineLayerList:
                os.chdir(workingDir)

                base_name = os.path.basename(lineLayer)
                shapefile_name, _ = os.path.splitext(base_name)
                scoredRoads = f"{workingDir}/{tempDir}/Scored_roads_{shapefile_name}.shp"

                buffer = processing.run(
                    "native:buffer",
                    {
                        "INPUT": countryUTMLayer,
                        "DISTANCE": self.BUFFER_DISTANCE,
                        "SEGMENTS": 5,
                        "END_CAP_STYLE": 0,
                        "JOIN_STYLE": 0,
                        "MITER_LIMIT": 2,
                        "DISSOLVE": True,
                        "SEPARATE_DISJOINT": False,
                        "OUTPUT": "memory:",
                    },
                )

                countryUTMLayerBuf = buffer["OUTPUT"]

                self.convertCRS(lineLayer, UTM_crs)
                #shp_utm[rasField] = [0]

                #for i in roadType_Score:
                #    shp_utm.loc[shp_utm[roadTypeField] == i[0], "Score"] = i[1]

                #shp_utm[rasField] = shp_utm[rasField].astype(int)
                shp_utm.to_file(scoredRoads)

                gridOutput = f"{workingDir}{tempDir}/grid.shp"
                gridExtent = countryUTMLayer.extent()
                grid_params = {
                    'TYPE': 2,  # Rectangle (polygon)
                    'EXTENT': gridExtent,
                    'HSPACING': 100,  # Horizontal spacing
                    'VSPACING': 100,  # Vertical spacing
                    'CRS': UTM_crs,
                    'OUTPUT': "memory:"
                }

                grid_result = processing.run('native:creategrid', grid_params)
                grid_layer = grid_result['OUTPUT']

                field_name = 'reclass_va'
                if not grid_layer.fields().indexFromName(field_name) >= 0:
                    grid_layer.dataProvider().addAttributes([QgsField(field_name, QVariant.Int)])
                    grid_layer.updateFields()

                # scoredRoadsUTM = QgsVectorLayer(shp_utm.to_json(), "linebufUTM", "ogr")
                roadBuf_out = f"{workingDir}/{tempDir}/roadBuf.shp"

                self.dlg.WLK_status_2.setText(f"Processing... {shapefile_name}")
                self.dlg.WLK_status_2.repaint()

                Buffer = processing.run(
                    "gdal:buffervectors",
                    {
                        "INPUT": scoredRoads,
                        "GEOMETRY": "geometry",
                        "DISTANCE": 50,
                        "FIELD": "",
                        "DISSOLVE": False,
                        "EXPLODE_COLLECTIONS": False,
                        "OPTIONS": "",
                        "OUTPUT": roadBuf_out,
                    },
                )

                # Count the number of buffers within each grid cell
                line_layer = QgsVectorLayer(scoredRoads, 'buffer', 'ogr')
                index = QgsSpatialIndex(line_layer.getFeatures())
                reclass_vals = {}

                for grid_feat in grid_layer.getFeatures():
                    intersecting_ids = index.intersects(grid_feat.geometry().boundingBox())
                    # Initialize a set to store unique intersecting line feature IDs
                    unique_intersections = set()

                    # Check each potentially intersecting line feature
                    for line_id in intersecting_ids:
                        line_feat = line_layer.getFeature(line_id)
                        line_geom = line_feat.geometry()

                        # Perform a detailed intersection check
                        if grid_feat.geometry().intersects(line_geom):
                            unique_intersections.add(line_id)  # Add the line feature ID to the set

                    # Count the number of unique intersecting line features
                    num_footpaths = len(unique_intersections)

                    if num_footpaths >= 2:
                        reclass_val = 5
                    elif num_footpaths == 1:
                        reclass_val = 3
                    else:
                        reclass_val = 0

                    reclass_vals[grid_feat.id()] = reclass_val

                grid_layer.startEditing()
                for grid_feat in grid_layer.getFeatures():
                    grid_layer.changeAttributeValue(grid_feat.id(), grid_layer.fields().indexFromName(field_name),
                                                    reclass_vals[grid_feat.id()])
                grid_layer.commitChanges()

                dif_out = f"{workingDir}/{tempDir}/Dif.shp"

                #Difference = processing.run(
                #    "native:difference",
                #    {
                #        "INPUT": countryUTMLayerBuf,
                #        "OVERLAY": grid_layer,
                #        "OUTPUT": dif_out,
                #        "GRID_SIZE": None,
                #    },
                #)

                # difference = Difference["OUTPUT"]

                Merge = processing.run(
                    "native:mergevectorlayers",
                    {"LAYERS": [grid_layer], "CRS": None, "OUTPUT": "memory:"},
                )

                merge = Merge["OUTPUT"]

                mergeClip = processing.run(
                    "native:clip",
                    {
                        "INPUT": merge,
                        "OVERLAY": countryUTMLayer,
                        "OUTPUT": "memory:",
                    }
                )

                mergeOutput = mergeClip["OUTPUT"]

                # Get the width and height of the extent
                extent = countryUTMLayerBuf.extent()
                raster_width = int(extent.width() / pixelSize)
                raster_height = int(extent.height() / pixelSize)

                os.chdir(Dimension)
                Output_Folder = "AT"
                if os.path.exists(Output_Folder):
                    os.chdir(Output_Folder)
                else:
                    os.mkdir(Output_Folder)
                    os.chdir(Output_Folder)
                rasOutput = f"{self.dlg.WLK_Output_Field_2.text()[:-4]}{shapefile_name}.tif"

                rasterize = processing.run(
                    "gdal:rasterize",
                    {
                        "INPUT": mergeOutput,
                        "FIELD": field_name,
                        "BURN": 0,
                        "USE_Z": False,
                        "UNITS": 0,
                        "WIDTH": raster_width,
                        "HEIGHT": raster_height,
                        "EXTENT": None,
                        "NODATA": -9999,
                        "OPTIONS": "",
                        "DATA_TYPE": 5,
                        "INIT": None,
                        "INVERT": False,
                        "EXTRA": "",
                        "OUTPUT": rasOutput,
                    },
                )

                #self.dlg.WLK_Output_Field_2.setText(f"{workingDir}{Dimension}/{rasOutput}")

                styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
                styleFileDestination = f"{workingDir}{Dimension}/{Output_Folder}"
                styleFile = f"{rasOutput.split('.')[0]}.qml"

                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                self.dlg.WLK_status_2.setText(f"Processing Complete for {shapefile_name}!")
                self.dlg.WLK_status_2.repaint()
        else:
            pass
        if streetCrossingLayer:
            os.chdir(workingDir)

            base_name = os.path.basename(streetCrossingLayer)
            shapefile_name, _ = os.path.splitext(base_name)
            scoredRoads = f"{workingDir}/{tempDir}/Scored_{shapefile_name}.shp"

            buffer = processing.run(
                "native:buffer",
                {
                    "INPUT": countryUTMLayer,
                    "DISTANCE": self.BUFFER_DISTANCE,
                    "SEGMENTS": 5,
                    "END_CAP_STYLE": 0,
                    "JOIN_STYLE": 0,
                    "MITER_LIMIT": 2,
                    "DISSOLVE": True,
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": "memory:",
                },
            )

            countryUTMLayerBuf = buffer["OUTPUT"]

            self.convertCRS(streetCrossingLayer, UTM_crs)
            #shp_utm[rasField] = [0]

            #for i in roadType_Score:
            #    shp_utm.loc[shp_utm[roadTypeField] == i[0], "Score"] = i[1]

            #shp_utm[rasField] = shp_utm[rasField].astype(int)
            shp_utm.to_file(scoredRoads)

            gridOutput = f"{workingDir}{tempDir}/grid.shp"
            gridExtent = countryUTMLayer.extent()
            grid_params = {
                'TYPE': 2,  # Rectangle (polygon)
                'EXTENT': gridExtent,
                'HSPACING': 100,  # Horizontal spacing
                'VSPACING': 100,  # Vertical spacing
                'CRS': UTM_crs,
                'OUTPUT': "memory:"
            }

            grid_result = processing.run('native:creategrid', grid_params)
            grid_layer = grid_result['OUTPUT']

            field_name = 'reclass_va'
            if not grid_layer.fields().indexFromName(field_name) >= 0:
                grid_layer.dataProvider().addAttributes([QgsField(field_name, QVariant.Int)])
                grid_layer.updateFields()

            # scoredRoadsUTM = QgsVectorLayer(shp_utm.to_json(), "linebufUTM", "ogr")
            #roadBuf_out = f"{workingDir}/{tempDir}/roadBuf.shp"

            self.dlg.WLK_status_2.setText(f"Processing... {shapefile_name}")
            self.dlg.WLK_status_2.repaint()

            #Buffer = processing.run(
            #    "gdal:buffervectors",
            #    {
            #        "INPUT": scoredRoads,
            #        "GEOMETRY": "geometry",
            #        "DISTANCE": 50,
            #        "FIELD": "",
            #        "DISSOLVE": False,
            #        "EXPLODE_COLLECTIONS": False,
            #        "OPTIONS": "",
            #        "OUTPUT": roadBuf_out,
            #    },
            #)

            # Count the number of buffers within each grid cell
            point_layer = QgsVectorLayer(scoredRoads, 'buffer', 'ogr')
            index = QgsSpatialIndex(point_layer.getFeatures())
            reclass_vals = {}

            for grid_feat in grid_layer.getFeatures():
                intersecting_ids = index.intersects(grid_feat.geometry().boundingBox())
                num_footpaths = len(intersecting_ids)

                if num_footpaths >= 2:
                    reclass_val = 5
                elif num_footpaths == 1:
                    reclass_val = 3
                else:
                    reclass_val = 0

                reclass_vals[grid_feat.id()] = reclass_val

            grid_layer.startEditing()
            for grid_feat in grid_layer.getFeatures():
                grid_layer.changeAttributeValue(grid_feat.id(), grid_layer.fields().indexFromName(field_name),
                                                reclass_vals[grid_feat.id()])
            grid_layer.commitChanges()

            dif_out = f"{workingDir}/{tempDir}/Dif.shp"

            #Difference = processing.run(
            #    "native:difference",
            #    {
            #        "INPUT": countryUTMLayerBuf,
            #        "OVERLAY": grid_layer,
            #        "OUTPUT": dif_out,
            #        "GRID_SIZE": None,
            #    },
            #)

            # difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [grid_layer], "CRS": None, "OUTPUT": "memory:"},
            )

            merge = Merge["OUTPUT"]

            mergeClip = processing.run(
                "native:clip",
                {
                    "INPUT": merge,
                    "OVERLAY": countryUTMLayer,
                    "OUTPUT": "memory:",
                }
            )

            mergeOutput = mergeClip["OUTPUT"]

            # Get the width and height of the extent
            extent = countryUTMLayerBuf.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            os.chdir(Dimension)
            Output_Folder = "AT"
            if os.path.exists(Output_Folder):
                os.chdir(Output_Folder)
            else:
                os.mkdir(Output_Folder)
                os.chdir(Output_Folder)
            rasOutput = f"{self.dlg.WLK_Output_Field_2.text()[:-4]}{shapefile_name}.tif"

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": field_name,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            #self.dlg.WLK_Output_Field_2.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/{Output_Folder}"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.WLK_status_2.setText(f"Processing Complete for {shapefile_name}!")
            self.dlg.WLK_status_2.repaint()
        else:
            pass
        if blockLayer:
            os.chdir(workingDir)

            base_name = os.path.basename(blockLayer)
            shapefile_name, _ = os.path.splitext(base_name)
            scoredBlocks = f"{workingDir}/{tempDir}/Scored_blocks_{shapefile_name}.shp"

            buffer = processing.run(
                "native:buffer",
                {
                    "INPUT": countryUTMLayer,
                    "DISTANCE": self.BUFFER_DISTANCE,
                    "SEGMENTS": 5,
                    "END_CAP_STYLE": 0,
                    "JOIN_STYLE": 0,
                    "MITER_LIMIT": 2,
                    "DISSOLVE": True,
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": "memory:",
                },
            )

            countryUTMLayerBuf = buffer["OUTPUT"]

            self.convertCRS(blockLayer, UTM_crs)
            #shp_utm[rasField] = [0]

            #for i in roadType_Score:
            #    shp_utm.loc[shp_utm[roadTypeField] == i[0], "Score"] = i[1]

            #shp_utm[rasField] = shp_utm[rasField].astype(int)
            shp_utm.to_file(scoredBlocks)

            gridOutput = f"{workingDir}{tempDir}/grid.shp"
            gridExtent = countryUTMLayer.extent()
            grid_params = {
                'TYPE': 2,  # Rectangle (polygon)
                'EXTENT': gridExtent,
                'HSPACING': 100,  # Horizontal spacing
                'VSPACING': 100,  # Vertical spacing
                'CRS': UTM_crs,
                'OUTPUT': "memory:"
            }

            grid_result = processing.run('native:creategrid', grid_params)
            grid_layer = grid_result['OUTPUT']

            field_name = 'reclass_va'
            if not grid_layer.fields().indexFromName(field_name) >= 0:
                grid_layer.dataProvider().addAttributes([QgsField(field_name, QVariant.Int)])
                grid_layer.updateFields()

            # scoredRoadsUTM = QgsVectorLayer(shp_utm.to_json(), "linebufUTM", "ogr")
            roadBuf_out = f"{workingDir}/{tempDir}/roadBuf.shp"

            self.dlg.WLK_status_2.setText(f"Processing... {shapefile_name}")
            self.dlg.WLK_status_2.repaint()

            Buffer = processing.run(
                "gdal:buffervectors",
                {
                    "INPUT": scoredBlocks,
                    "GEOMETRY": "geometry",
                    "DISTANCE": 50,
                    "FIELD": "",
                    "DISSOLVE": False,
                    "EXPLODE_COLLECTIONS": False,
                    "OPTIONS": "",
                    "OUTPUT": roadBuf_out,
                },
            )

            # Count the number of buffers within each grid cell
            block_layer = QgsVectorLayer(scoredBlocks, 'buffer', 'ogr')
            index = QgsSpatialIndex(block_layer.getFeatures())
            reclass_vals = {}

            for grid_feat in grid_layer.getFeatures():
                intersecting_ids = index.intersects(grid_feat.geometry().boundingBox())
                unique_intersections = set()

                # Initialize variable to keep track of the maximum perimeter
                max_perimeter = 0

                for poly_id in intersecting_ids:
                    poly_feat = block_layer.getFeature(poly_id)
                    poly_geom = poly_feat.geometry()

                    if grid_feat.geometry().intersects(poly_geom):
                        unique_intersections.add(poly_id)
                        perimeter = poly_geom.length()

                        # Update max_perimeter if this perimeter is larger
                        if perimeter > max_perimeter:
                            max_perimeter = perimeter

                # Assign reclassification value based on the maximum perimeter
                if max_perimeter > 1000:  # Very large blocks
                    reclass_val = 1
                elif 751 <= max_perimeter <= 1000:  # Large blocks
                    reclass_val = 2
                elif 501 <= max_perimeter <= 750:  # Moderate blocks
                    reclass_val = 3
                elif 251 <= max_perimeter <= 500:  # Small blocks
                    reclass_val = 4
                elif 0 < max_perimeter <= 250:  # Very small blocks
                    reclass_val = 5
                else:
                    reclass_val = 0  # No intersection

                reclass_vals[grid_feat.id()] = reclass_val

            grid_layer.startEditing()
            for grid_feat in grid_layer.getFeatures():
                grid_layer.changeAttributeValue(grid_feat.id(), grid_layer.fields().indexFromName(field_name),
                                                reclass_vals[grid_feat.id()])
            grid_layer.commitChanges()

            dif_out = f"{workingDir}/{tempDir}/Dif.shp"

            #Difference = processing.run(
            #    "native:difference",
            #    {
            #        "INPUT": countryUTMLayerBuf,
            #        "OVERLAY": grid_layer,
            #        "OUTPUT": dif_out,
            #        "GRID_SIZE": None,
            #    },
            #)

            # difference = Difference["OUTPUT"]

            Merge = processing.run(
                "native:mergevectorlayers",
                {"LAYERS": [grid_layer], "CRS": None, "OUTPUT": "memory:"},
            )

            merge = Merge["OUTPUT"]

            mergeClip = processing.run(
                "native:clip",
                {
                    "INPUT": merge,
                    "OVERLAY": countryUTMLayer,
                    "OUTPUT": "memory:",
                }
            )

            mergeOutput = mergeClip["OUTPUT"]

            # Get the width and height of the extent
            extent = countryUTMLayerBuf.extent()
            raster_width = int(extent.width() / pixelSize)
            raster_height = int(extent.height() / pixelSize)

            os.chdir(Dimension)
            Output_Folder = "AT"
            if os.path.exists(Output_Folder):
                os.chdir(Output_Folder)
            else:
                os.mkdir(Output_Folder)
                os.chdir(Output_Folder)
            rasOutput = f"{self.dlg.WLK_Output_Field_2.text()[:-4]}{shapefile_name}.tif"

            rasterize = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": mergeOutput,
                    "FIELD": field_name,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": raster_width,
                    "HEIGHT": raster_height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput,
                },
            )

            #self.dlg.WLK_Output_Field_2.setText(f"{workingDir}{Dimension}/{rasOutput}")

            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/{Output_Folder}"
            styleFile = f"{rasOutput.split('.')[0]}.qml"

            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            self.dlg.WLK_status_2.setText(f"Processing Complete for {shapefile_name}!")
            self.dlg.WLK_status_2.repaint()

    def SAFRasterizerDelegator(self):
        """
        This function delegates the rendering task to one of four rasterizing functions based on input type and subtype:
        - In case of raster input --> SAFnightTimeLights
        - In case of points (vector) input --> SAFstreetLightsRasterizer
        - In case of polygons (vector) with numeric field as metric --> SAFPerceivedSafetyFromNumericFieldRasterizer
        - In case of polygons (vector) with text field as metric --> SAFPerceivedSafetyFromTextFieldRasterizer
        - If no input layer is given, uses a user-provided value to rasterize --> SAFPerceivedSafetyFromUserValueRasterizer
        """

        # Announce the start of the process
        self.dlg.SAF_status.setText("Starting...")
        self.dlg.SAF_status.repaint()

        input_file = self.dlg.SAF_Input_Field.filePath()

        # Check if the input file is empty or not provided
        if not input_file:
            # Get the user-provided value from the spinner
            user_value = self.dlg.SAF_User_Value_Input.value()
            self.SAFPerceivedSafetyFromUserValueRasterizer(user_value)
            return

        input_layer = QgsRasterLayer(input_file, "input")

        if input_layer.isValid():
            self.SAFnightTimeLights_v2()
        else:
            input_layer = QgsVectorLayer(input_file, "input", "ogr")
            if not input_layer.isValid():
                self.dlg.SAF_status.setText("The input file is not a valid raster or vector layer.")
                self.dlg.SAF_status.repaint()
                return

            # Check the geometry type of the vector layer
            if input_layer.geometryType() == QgsWkbTypes.PointGeometry:
                self.SAFstreetLightsRasterizer()
            elif input_layer.geometryType() == QgsWkbTypes.PolygonGeometry:
                selected_field = self.dlg.SAF_rasField_CB.currentText()
                if selected_field.endswith(" (text)"):
                    self.SAFPerceivedSafetyFromTextFieldRasterizer(input_layer)
                else:
                    self.SAFPerceivedSafetyFromNumericFieldRasterizer(input_layer)
            else:
                self.dlg.SAF_status.setText(
                    "Unsupported vector layer type. Only point and polygon geometries are supported.")
                self.dlg.SAF_status.repaint()

    def populateCBFieldsFromPolygonLayer_PC_SAF(self, file_path):
        if file_path == '':
            # enable the user value field if no file is selected
            self.dlg.SAF_User_Value_Input.setEnabled(True)
        else:
            # disable the user value field
            self.dlg.SAF_User_Value_Input.setEnabled(False)

        # Clear and disable the SAF_typeScore_Field by default
        self.dlg.SAF_typeScore_Field.clear()
        self.dlg.SAF_typeScore_Field.setEnabled(False)
        layer = QgsVectorLayer(file_path, "input", "ogr")
        # Check if the layer is a polygon
        if layer.geometryType() == QgsWkbTypes.PolygonGeometry:
            # if it is, populate the combo box fields
            self.dlg.SAF_rasField_CB.setEnabled(True)
            self.dlg.SAF_rasField_CB.clear()
            for field in layer.fields():
                field_name = field.name()
                # Check if the field is of type text
                if field.type() == QVariant.String:
                    # distinguish text fields
                    field_name = f"{field_name} (text)"
                self.dlg.SAF_rasField_CB.addItem(field_name)
        else:
            # ensure the CB is not displaying stale information
            self.dlg.SAF_rasField_CB.clear()
            self.dlg.SAF_rasField_CB.setEnabled(False)
            # Clear and disable the SAF_typeScore_Field by default
            self.dlg.SAF_typeScore_Field.clear()
            self.dlg.SAF_typeScore_Field.setEnabled(False)

    def populateCBFieldsFromPolygonLayer_PC_EDU(self, file_path):
        layer = QgsVectorLayer(file_path, "input", "ogr")
        # Check if the layer is a polygon
        if layer.geometryType() == QgsWkbTypes.PolygonGeometry:
            # if it is, populate the combo box fields
            self.dlg.EDU_rasField_CB.setEnabled(True)
            self.dlg.EDU_rasField_CB.clear()
            for field in layer.fields():
                field_name = field.name()
                # Check if the field is of type text
                if field.type() != QVariant.String:
                    # remove text fields
                    self.dlg.EDU_rasField_CB.addItem(field_name)
        else:
            # ensure the CB is not displaying stale information
            self.dlg.EDU_rasField_CB.clear()
            self.dlg.EDU_rasField_CB.setEnabled(False)

    def populateCBFieldsFromPolygonLayer_PC_ENV(self, file_path):
        # Clear and disable the SAF_typeScore_Field by default
        self.dlg.ENV_typeScore_Field.clear()
        self.dlg.ENV_typeScore_Field.setEnabled(False)
        layer = QgsVectorLayer(file_path, "input", "ogr")
        # Check if the layer is a polygon
        if layer.geometryType() == QgsWkbTypes.PolygonGeometry:
            # if it is, populate the combo box fields
            self.dlg.ENV_riskLevelField_CB.setEnabled(True)
            self.dlg.ENV_riskLevelField_CB.clear()
            for field in layer.fields():
                field_name = field.name()
                # Check if the field is of type text
                if field.type() == QVariant.String:
                    # distinguish text fields
                    field_name = f"{field_name} (text)"
                self.dlg.ENV_riskLevelField_CB.addItem(field_name)
        else:
            # ensure the CB is not displaying stale information
            self.dlg.ENV_riskLevelField_CB.clear()
            self.dlg.ENV_riskLevelField_CB.setEnabled(False)
            # Clear and disable the ENV_typeScore_Field by default
            self.dlg.ENV_typeScore_Field.clear()
            self.dlg.ENV_typeScore_Field.setEnabled(False)

    def populateTextFieldWithUniqueValues_PC_SAF(self, layer):
        # Get the file path from the QgsFileWidget
        file_path = self.dlg.SAF_Input_Field.filePath()
        # Get the selected field name from the QComboBox
        field_name = self.dlg.SAF_rasField_CB.currentText()

        # Clear and disable the SAF_typeScore_Field by default
        self.dlg.SAF_typeScore_Field.clear()
        self.dlg.SAF_typeScore_Field.setEnabled(False)

        if file_path and field_name:
            if field_name.endswith(" (text)"):
                # Remove " (text)" suffix
                field_name = field_name.replace(" (text)", "")
                try:
                    # Read the file using geopandas
                    gdf = gpd.read_file(file_path)
                    # Get unique values from the selected field
                    unique_values = gdf[field_name].unique().tolist()
                    # Create the score list
                    score_list = [[str(val), 0] for val in unique_values if pd.notna(val)]
                    # Set the text in the QFilterLineEdit and enable it
                    self.dlg.SAF_typeScore_Field.setText(str(score_list))
                    self.dlg.SAF_typeScore_Field.setEnabled(True)
                except Exception as e:
                    # Handle any errors (e.g., file not found, invalid field name)
                    self.dlg.SAF_typeScore_Field.setText(f"Error: {str(e)}")
                    self.dlg.SAF_typeScore_Field.setEnabled(False)
            else:
                # Field name doesn't end with " (text)", so we keep the field cleared and disabled
                pass
        else:
            # Handle the case where no file or field is selected
            self.dlg.SAF_typeScore_Field.setText("Please select a file and field first.")
            self.dlg.SAF_typeScore_Field.setEnabled(False)

    def populateTextFieldWithUniqueValues_PC_ENV(self, layer):
        # Get the file path from the QgsFileWidget
        file_path = self.dlg.ENV_Input_Field.filePath()
        # Get the selected field name from the QComboBox
        field_name = self.dlg.ENV_riskLevelField_CB.currentText()

        # Clear and disable the ENV_typeScore_Field by default
        self.dlg.ENV_typeScore_Field.clear()
        self.dlg.ENV_typeScore_Field.setEnabled(False)

        if file_path and field_name:
            if field_name.endswith(" (text)"):
                # Remove " (text)" suffix
                field_name = field_name.replace(" (text)", "")
                try:
                    # Read the file using geopandas
                    gdf = gpd.read_file(file_path)
                    # Get unique values from the selected field
                    unique_values = gdf[field_name].unique().tolist()
                    # Create the score list
                    score_list = [[str(val), 0] for val in unique_values if pd.notna(val)]
                    # Set the text in the QFilterLineEdit and enable it
                    self.dlg.ENV_typeScore_Field.setText(str(score_list))
                    self.dlg.ENV_typeScore_Field.setEnabled(True)
                except Exception as e:
                    # Handle any errors (e.g., file not found, invalid field name)
                    self.dlg.ENV_typeScore_Field.setText(f"Error: {str(e)}")
                    self.dlg.ENV_typeScore_Field.setEnabled(False)
            else:
                # Field name doesn't end with " (text)", so we keep the field cleared and disabled
                pass
        else:
            # Handle the case where no file or field is selected
            self.dlg.ENV_typeScore_Field.setText("Please select a file and field first.")
            self.dlg.ENV_typeScore_Field.setEnabled(False)


    # ------------------------------------ SAFETY factor rasterization section
    def SAFnightTimeLights(self):
        """
        This function processes night-time lights data for safety assessment.
        It handles only raster inputs. How brightly lit an area is used as a proxy for safety or safe urban design.
        """

        # Set up directories
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        tempDir = "temp"
        Dimension = "Place Characterization"

        # Create necessary directories
        if not os.path.exists(Dimension):
            os.mkdir(Dimension)

        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        time.sleep(0.5)
        os.mkdir(tempDir)

        # Set CRS and input/output paths
        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        input_file = self.dlg.SAF_Input_Field.filePath()
        rasOutput = self.dlg.SAF_Output_Field.text()

        # Detect input file type, assuming it's raster
        input_layer = QgsRasterLayer(input_file, "input")

        # Handle raster input layer
        if input_layer.isValid():
            # Raster input detected - proceed with existing functionality
            NTL_input = input_file

            # Define temporary file paths
            tempCalc = f"{tempDir}/tempCalc.tif"
            tempResample = f"{tempDir}/tempResample.tif"
            countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"

            # Copy style file
            styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
            styleFileDestination = f"{workingDir}{Dimension}/"
            styleFile = f"{rasOutput.split('.')[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            # Update UI status
            self.dlg.SAF_status.setText("Variables Set")
            self.dlg.SAF_status.repaint()
            time.sleep(0.5)
            self.dlg.SAF_status.setText("Processing...")
            self.dlg.SAF_status.repaint()

            # Convert CRS of country layer
            self.convertCRS(countryLayer, UTM_crs)
            countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

            # Buffer the country layer
            buffer = processing.run(
                "native:buffer",
                {
                    "INPUT": countryUTMLayer,
                    "DISTANCE": self.BUFFER_DISTANCE,
                    "SEGMENTS": 5,
                    "END_CAP_STYLE": 0,
                    "JOIN_STYLE": 0,
                    "MITER_LIMIT": 2,
                    "DISSOLVE": True,
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": countryUTMLayerBuf,
                },
            )

            # Get the extent of the buffered country layer
            CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
            country_extent = CountryBuf_df.total_bounds

            # Reproject and resample the night-time lights raster
            processing.run(
                "gdal:warpreproject",
                {
                    "INPUT": NTL_input,
                    "SOURCE_CRS": None,
                    "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                    "RESAMPLING": 0,
                    "NODATA": -9999,
                    "TARGET_RESOLUTION": pixelSize,
                    "OPTIONS": "",
                    "DATA_TYPE": 0,
                    "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                    "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                    "MULTITHREADING": False,
                    "EXTRA": "",
                    "OUTPUT": tempResample,
                },
            )

            # Perform raster calculation
            processing.run(
                "gdal:rastercalculator",
                {
                    "INPUT_A": tempResample,
                    "BAND_A": 1,
                    "FORMULA": "A*1000",
                    "NO_DATA": None,
                    "RTYPE": 4,
                    "OPTIONS": "",
                    "EXTRA": "",
                    "OUTPUT": tempCalc,
                },
            )

            # Normalize raster values
            with rasterio.open(tempCalc, "r+") as src:
                SAF_ras = src.read(1)
                meta1 = src.meta
                Rmax = SAF_ras.max()
                Rmin = SAF_ras.min()
                m_max = 5
                m_min = 0
                result = ((SAF_ras - Rmin) / (Rmax - Rmin)) * m_max
                meta1.update(dtype=rasterio.float32)

            try:
                # Create output directory if it does not exist
                if not os.path.exists(Dimension):
                    os.mkdir(Dimension)
                os.chdir(Dimension)

                # Write the final output raster
                with rasterio.open(rasOutput, "w", **meta1) as dst:
                    dst.write(result, 1)

                # Update UI with the output path
                self.dlg.SAF_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")
                self.dlg.SAF_status.setText("Processing Complete!")
                self.dlg.SAF_status.repaint()

                # Return to the original working directory
                os.chdir(workingDir)

            except Exception as e:
                # Something went awry, inform the user
                error_message = f"Processing failed: {str(e)}"
                self.dlg.SAF_status.setText(error_message)
                self.dlg.SAF_status.repaint()

                # Ensure we return to the original working directory even if an error occurs
                if os.getcwd() != workingDir:
                    os.chdir(workingDir)

        else:
            self.dlg.SAF_status.setText("The input file is not a valid raster layer.")
            self.dlg.SAF_status.repaint()

    def SAFnightTimeLights_v2(self):
        """
        This function processes night-time lights (NTL) data to assess urban safety, using luminosity as a proxy for safe urban design.
        The approach refines NTL classification by employing local statistics (e.g., median, 75th percentile) to adapt the analysis
        to specific contexts, such as small island nations, as suggested by Elvidge et al. (2013) and Levin & Zhang (2017).
        This method replaces fixed thresholds with a classification scheme grounded in local NTL characteristics,
        aligning with the principles outlined by Chen & Nordhaus (2011) for using luminosity as a socio-economic indicator.
        """

        try:
            # Set up directories
            current_script_path = os.path.dirname(os.path.abspath(__file__))
            workingDir = self.dlg.workingDir_Field.text()
            os.chdir(workingDir)
            tempDir = "temp"
            Dimension = "Place Characterization"

            # Helper function to create directories if they don't exist
            def create_directory(path):
                if not os.path.exists(path):
                    os.makedirs(path, exist_ok=True)

            # Create necessary directories
            create_directory(Dimension)
            dimension_dir = os.path.join(workingDir, Dimension)
            if os.path.exists(tempDir):
                shutil.rmtree(tempDir)
            create_directory(tempDir)

            # Set CRS and input/output paths
            pixelSize = self.dlg.pixelSize_SB.value()
            UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
            countryLayer = self.dlg.countryLayer_Field.filePath()
            input_file = self.dlg.SAF_Input_Field.filePath()
            rasOutput = os.path.join(workingDir, Dimension, self.dlg.SAF_Output_Field.text())
            
            # Load and reproject country layer if necessary
            countryLayer = QgsVectorLayer(countryLayer, "country_layer", "ogr")
            if not countryLayer.isValid():
                raise ValueError("Invalid country layer")
            if countryLayer.crs() != UTM_crs:
                countryLayer = processing.run("native:reprojectlayer", {
                    'INPUT': countryLayer,
                    'TARGET_CRS': UTM_crs,
                    'OUTPUT': 'memory:'
                })['OUTPUT']

            # Ensure spatial index exists
            _ = QgsSpatialIndex(countryLayer.getFeatures())

            # Open the raster in its native CRS and perform classification
            with rasterio.open(input_file) as src:
                ntl_data = src.read(1)
                out_meta = src.meta.copy()
                nodata_value = src.nodata

            # Handle case where nodata_value is None
            if nodata_value is None:
                nodata_value = 255  # or another appropriate value for your data

            # Ensure nodata_value is a number
            nodata_value = float(nodata_value)

            # Handle NODATA values
            valid_data = ntl_data[~np.isnan(ntl_data) & (ntl_data != nodata_value)]

            if valid_data.size > 0:
                max_value = np.max(valid_data)
                median = np.median(valid_data)
                percentile_75 = np.percentile(valid_data, 75)

                print(f"Max Value: {max_value:.6f}")
                print(f"Median: {median:.6f}")
                print(f"75th Percentile: {percentile_75:.6f}")

                # Determine classification scheme
                if max_value <= 0.05 or (max_value - percentile_75) <= 0.05 * max_value:
                    print("Using max_value classification scheme")
                    classification = np.full_like(ntl_data, 0, dtype=np.float32)
                    classification[(ntl_data > 0) & (ntl_data <= 0.2 * max_value)] = 1
                    classification[(ntl_data > 0.2 * max_value) & (ntl_data <= 0.4 * max_value)] = 2
                    classification[(ntl_data > 0.4 * max_value) & (ntl_data <= 0.6 * max_value)] = 3
                    classification[(ntl_data > 0.6 * max_value) & (ntl_data <= 0.8 * max_value)] = 4
                    classification[ntl_data > 0.8 * max_value] = 5
                else:
                    print("Using original classification scheme")
                    classification = np.full_like(ntl_data, 0, dtype=np.float32)
                    classification[(ntl_data > 0.05) & (ntl_data <= 0.25 * median)] = 1
                    classification[(ntl_data > 0.25 * median) & (ntl_data <= 0.5 * median)] = 2
                    classification[(ntl_data > 0.5 * median) & (ntl_data <= median)] = 3
                    classification[(ntl_data > median) & (ntl_data <= percentile_75)] = 4
                    classification[ntl_data > percentile_75] = 5

                # Ensure NODATA values are preserved
                classification[np.isnan(ntl_data) | (ntl_data == nodata_value)] = nodata_value

                # Update metadata for output
                out_meta.update(dtype=rasterio.float32, nodata=nodata_value)

                # Save the classified raster in native CRS
                tempClassified = os.path.join(tempDir, "tempClassified.tif")
                with rasterio.open(tempClassified, "w", **out_meta) as dst:
                    dst.write(classification, 1)

                print(f"Classified NTL raster saved to {tempClassified}")

                # Clip the classified raster to the country boundaries
                clippedClassified = os.path.join(tempDir, "clippedClassified.tif")
                processing.run(
                    "gdal:cliprasterbymasklayer",
                    {
                        "INPUT": tempClassified,
                        "MASK": countryLayer,
                        "CROP_TO_CUTLINE": True,
                        "NODATA": nodata_value,
                        "OUTPUT": clippedClassified
                    }
                )

                print(f"Clipped NTL raster saved to {clippedClassified}")

                # Get the CRS from the original raster
                src_crs = out_meta['crs'].to_string()

                # Reproject the clipped raster to the output CRS without resampling
                self.dlg.SAF_status.setText("Reprojecting to output CRS...")
                self.dlg.SAF_status.repaint()
                countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"
                # Buffer the country layer
                buffer = processing.run(
                    "native:buffer",
                    {
                        "INPUT": countryLayer,
                        "DISTANCE": self.BUFFER_DISTANCE,
                        "SEGMENTS": 5,
                        "END_CAP_STYLE": 0,
                        "JOIN_STYLE": 0,
                        "MITER_LIMIT": 2,
                        "DISSOLVE": True,
                        "SEPARATE_DISJOINT": False,
                        "OUTPUT": countryUTMLayerBuf,
                    },
                )
                countryUTMLayerBuf = buffer["OUTPUT"]

                CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
                country_extent = CountryBuf_df.total_bounds
                processing.run(
                    "gdal:warpreproject",
                    {
                        "INPUT": clippedClassified,
                        "SOURCE_CRS": None,
                        "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "RESAMPLING": 0,  # Nearest neighbor to preserve classification
                        "NODATA": nodata_value,
                        "TARGET_RESOLUTION": pixelSize,
                        "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                        "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "OUTPUT": rasOutput,
                    }
                )

                print(f"Reprojected and saved final NTL raster to {rasOutput}")
                
                # Copy style file
                styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
                styleFileDestination = os.path.join(dimension_dir)
                if not os.path.exists(styleFileDestination):
                    os.mkdir(styleFileDestination)
                styleFile = f"{os.path.splitext(rasOutput)[0]}.qml"
                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                # Update UI with the output path
                self.dlg.SAF_Aggregate_Field.setText(rasOutput)
                self.dlg.SAF_status.setText("Processing Complete!")
                self.dlg.SAF_status.repaint()

            else:
                print("No valid data found after handling NODATA values.")
                self.dlg.SAF_status.setText("No valid data found in the input raster.")
                self.dlg.SAF_status.repaint()

        except Exception as e:
            # Something went awry, inform the user
            error_message = f"Processing failed: {str(e)}"
            self.dlg.SAF_status.setText(error_message)
            self.dlg.SAF_status.repaint()
            print(f"Error details: {e}")  # Add this for more detailed error information

        finally:
            # Ensure we return to the original working directory
            os.chdir(workingDir)



    def CommonRasterizerSetup(self):
        """
        Common setup for SAF-related functions. Handles directory setup, CRS conversion,
        and loading/buffering the country layer.

        Returns:
            dict: A dictionary containing processed layers and paths.
        """
        # Setup directories
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        workingDir = os.path.normpath(workingDir)  # Normalize path
        Dimension = "Place Characterization"
        tempDir = os.path.join(workingDir, "temp")
        os.makedirs(os.path.join(workingDir, Dimension), exist_ok=True)
        os.makedirs(tempDir, exist_ok=True)
        os.chdir(workingDir)

        # Input parameters
        countryLayerPath = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        UTM_crs = self.dlg.mQgsProjectionSelectionWidget.crs()

        # Load and preprocess the country layer
        countryLayer = QgsVectorLayer(countryLayerPath, "country_layer", "ogr")
        if not countryLayer.isValid():
            raise ValueError("Invalid country layer")
        if countryLayer.crs() != UTM_crs:
            countryLayer = processing.run("native:reprojectlayer", {
                'INPUT': countryLayer,
                'TARGET_CRS': UTM_crs,
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

        # Buffer the country layer in memory
        buffer_result = processing.run(
            "native:buffer",
            {
                "INPUT": countryLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": 'memory:'
            },
            feedback=QgsProcessingFeedback()
        )

        buffered_country_layer = buffer_result['OUTPUT']
        if not buffered_country_layer.isValid():
            raise ValueError("Buffering failed. Invalid buffered layer.")

        # Get the extent of the buffered country layer
        country_extent = buffered_country_layer.extent()

        return {
            "current_script_path": current_script_path,
            "workingDir": workingDir,
            "Dimension": Dimension,
            "tempDir": tempDir,
            "countryLayer": countryLayer,
            "buffered_country_layer": buffered_country_layer,
            "country_extent": country_extent,
            "pixelSize": pixelSize,
            "UTM_crs": UTM_crs
        }

    def SAFstreetLightsRasterizer(self):
        """
        Process streetlight vector data for safety assessment.
        Count streetlight points within a grid, scale to 0-5 range, and rasterize using rasterio.
        """
        try:
            # Call the common setup function
            setup = self.CommonRasterizerSetup()

            # Input parameters
            input_file = self.dlg.SAF_Input_Field.filePath()

            self.dlg.SAF_status.setText("Variables Set")
            self.dlg.SAF_status.repaint()
            time.sleep(0.5)
            self.dlg.SAF_status.setText("Processing...")
            self.dlg.SAF_status.repaint()

            # Load and preprocess vector layer
            vector_layer = QgsVectorLayer(input_file, "streetlights", "ogr")
            if not vector_layer.isValid():
                raise ValueError("Invalid vector input. Please check the file.")
            if vector_layer.crs() != setup['UTM_crs']:
                vector_layer = processing.run("native:reprojectlayer", {
                    'INPUT': vector_layer,
                    'TARGET_CRS': setup['UTM_crs'],
                    'OUTPUT': 'memory:'
                }, feedback=QgsProcessingFeedback())['OUTPUT']

            # Generate grid and count points
            grid = processing.run("native:creategrid", {
                'TYPE': 2,
                'EXTENT': setup['country_extent'],
                'HSPACING': setup['pixelSize'],
                'VSPACING': setup['pixelSize'],
                'CRS': setup['UTM_crs'],
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

            clipped_grid = processing.run("native:clip", {
                'INPUT': grid,
                'OVERLAY': setup['buffered_country_layer'],
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

            overlap_count = processing.run("qgis:countpointsinpolygon", {
                'POLYGONS': clipped_grid,
                'POINTS': vector_layer,
                'FIELD': 'OVERLAP',
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

            # Prepare raster data
            xmin, ymin, xmax, ymax = setup['country_extent'].toRectF().getCoords()
            width = int(np.floor((xmax - xmin) / setup['pixelSize']))
            height = int(np.floor((ymax - ymin) / setup['pixelSize']))
            raster_data = np.full((height, width), -9999, dtype=np.float32)

            # Rasterize vector data
            for feature in overlap_count.getFeatures():
                geom = feature.geometry()
                if geom.type() == QgsWkbTypes.PolygonGeometry:
                    centroid = geom.centroid().asPoint()
                    col = int((centroid.x() - xmin) / setup['pixelSize'])
                    row = int((ymax - centroid.y()) / setup['pixelSize'])
                    if 0 <= row < height and 0 <= col < width:
                        raster_data[row, col] = feature['OVERLAP']

            # Normalize raster data
            valid_data = raster_data != -9999
            max_value = np.max(raster_data[valid_data])
            if max_value > 0:
                raster_data[valid_data] = (raster_data[valid_data] / max_value) * 5.0

            # Create output raster
            raster_output = os.path.join(setup['workingDir'], setup['Dimension'], self.dlg.SAF_Output_Field.text())
            transform = rasterio.transform.from_origin(xmin, ymax, setup['pixelSize'], setup['pixelSize'])

            with rasterio.open(
                    raster_output,
                    'w',
                    driver='GTiff',
                    height=height,
                    width=width,
                    count=1,
                    dtype=raster_data.dtype,
                    crs=setup['UTM_crs'].toWkt(),
                    transform=transform,
                    nodata=-9999
            ) as dst:
                dst.write(raster_data, 1)
                dst.write_mask(valid_data.astype(np.uint8))

            # Set output field and apply style
            self.dlg.SAF_Aggregate_Field.setText(raster_output)
            styleTemplate = os.path.join(setup['current_script_path'], "Style", f"{setup['Dimension']}.qml")
            styleFile = f"{os.path.splitext(os.path.basename(raster_output))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(setup['workingDir'], setup['Dimension'], styleFile))

            self.dlg.SAF_status.setText("Processing has been completed!")
            self.dlg.SAF_status.repaint()

        except Exception as e:
            self.dlg.SAF_status.setText(f"Error: {str(e)}")
            self.dlg.SAF_status.repaint()

    def SAFPerceivedSafetyFromUserValueRasterizer(self, user_value):
        """
        This function rasterizes the Perceived Safety factor for the Urban Safety Factor based on a user-provided value.
        It creates a raster with the user-provided value within the country bounds and fills pixels outside the country shape with zero.
        The value provided by the user is in the range 0-100, but the value to render the output at is 0-5,
        so it's user value divided by 20.0.
        """
        try:
            # Call the common setup function
            setup = self.CommonRasterizerSetup()

            # Convert the user-provided value to the 0-5 scale
            render_value = user_value / 20.0

            self.dlg.SAF_status.setText("Variables Set")
            self.dlg.SAF_status.repaint()
            time.sleep(0.5)
            self.dlg.SAF_status.setText("Processing...")
            self.dlg.SAF_status.repaint()

            # Get the extent of the buffered country layer
            xmin, ymin, xmax, ymax = setup['country_extent'].toRectF().getCoords()

            # Initialize raster data with zeros
            width = int(np.floor((xmax - xmin) / setup['pixelSize']))
            height = int(np.floor((ymax - ymin) / setup['pixelSize']))
            raster_data = np.zeros((height, width), dtype=np.float32)

            # Create the transform for the raster
            transform = rasterio.transform.from_origin(xmin, ymax, setup['pixelSize'], setup['pixelSize'])

            # Write initial raster to a temporary file with zeros (NoData value)
            temp_raster_path = os.path.join(setup['tempDir'], "temp_raster.tif")
            with rasterio.open(
                    temp_raster_path, 'w', driver='GTiff', height=height, width=width,
                    count=1, dtype=np.float32, crs=setup['UTM_crs'].toWkt(), transform=transform, nodata=0
            ) as dst:
                dst.write(raster_data, 1)

            # Rasterize the user value within the country bounds
            rasterize_result = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": setup['countryLayer'],
                    "FIELD": None,  # No field since we use a uniform value
                    "BURN": render_value,  # Use the scaled user-provided value
                    "USE_Z": False,
                    "UNITS": 1,
                    "WIDTH": setup['pixelSize'],
                    "HEIGHT": setup['pixelSize'],
                    "EXTENT": f"{xmin},{xmax},{ymin},{ymax}",
                    "NODATA": -9999,  # NoData is zero outside the country bounds
                    "OPTIONS": "",
                    "DATA_TYPE": 6,  # GDT_Float32 for real numbers
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": temp_raster_path  # Output to the temporary raster
                }
            )

            if not rasterize_result:
                raise ValueError("Rasterization failed. Please check the input data.")

            # Copy the temporary raster to the final output location
            raster_output = os.path.join(setup['workingDir'], setup['Dimension'], self.dlg.SAF_Output_Field.text())
            shutil.move(temp_raster_path, raster_output)

            # Set output field and apply style
            self.dlg.SAF_Aggregate_Field.setText(raster_output)
            styleTemplate = os.path.join(setup['current_script_path'], "Style", f"{setup['Dimension']}.qml")
            styleFile = f"{os.path.splitext(os.path.basename(raster_output))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(setup['workingDir'], setup['Dimension'], styleFile))

            self.dlg.SAF_status.setText("Processing has been completed!")
            self.dlg.SAF_status.repaint()

        except Exception as e:
            self.dlg.SAF_status.setText(f"Error: {str(e)}")
            self.dlg.SAF_status.repaint()

    def SAFPerceivedSafetyFromTextFieldRasterizer(self, layer):
        """
        This function rasterizes the Perceived Safety factor for the Urban Safety Factor.
        It converts vector data to raster, applying scores based on text attributes.
        """
        try:
            # Call the common setup function
            setup = self.CommonRasterizerSetup()

            # Get the field name
            rasField = self.dlg.SAF_rasField_CB.currentText().replace(" (text)", "")

            # Get scoring from SAF_typeScore_Field
            scoring_text = self.dlg.SAF_typeScore_Field.text()
            scoring_dict = {item[0]: item[1] for item in eval(scoring_text)}

            self.dlg.SAF_status.setText("Variables Set")
            self.dlg.SAF_status.repaint()
            time.sleep(0.5)
            self.dlg.SAF_status.setText("Processing...")
            self.dlg.SAF_status.repaint()

            # Ensure the layer is valid
            if not layer.isValid():
                raise ValueError("Invalid layer")

            # Convert CRS if necessary
            if layer.crs() != setup['UTM_crs']:
                layer = processing.run("native:reprojectlayer", {
                    'INPUT': layer,
                    'TARGET_CRS': setup['UTM_crs'],
                    'OUTPUT': 'memory:'
                }, feedback=QgsProcessingFeedback())['OUTPUT']

            # Clip the input layer by the country layer
            clipped_layer = processing.run("native:clip", {
                'INPUT': layer,
                'OVERLAY': setup['countryLayer'],
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

            if not any(clipped_layer.getFeatures()):
                raise ValueError("Clipping resulted in an empty layer")

            # Create a temporary memory layer to hold the scaled scores
            temp_layer = QgsVectorLayer("Polygon?crs=" + setup['UTM_crs'].authid(), "temp_layer", "memory")
            temp_layer.dataProvider().addAttributes(
                [QgsField("scaled_score", QVariant.Double)])  # Use Double for real numbers
            temp_layer.updateFields()

            # Calculate the scaled scores and add to temp layer
            temp_layer.startEditing()
            for feature in clipped_layer.getFeatures():
                value = feature[rasField]
                score = scoring_dict.get(value, 0.0)  # Default to 0.0 if value is not in scoring_dict
                new_feature = QgsFeature(temp_layer.fields())
                new_feature.setGeometry(feature.geometry())
                new_feature.setAttribute("scaled_score", float(score))
                temp_layer.addFeature(new_feature)
            temp_layer.commitChanges()

            # Get the extent for rasterization
            extent = setup['country_extent']
            xmin, ymin, xmax, ymax = extent.xMinimum(), extent.yMinimum(), extent.xMaximum(), extent.yMaximum()
            width = int(np.floor((xmax - xmin) / setup['pixelSize']))
            height = int(np.floor((ymax - ymin) / setup['pixelSize']))

            # Rasterize
            rasOutput = os.path.join(setup['workingDir'], setup['Dimension'], self.dlg.SAF_Output_Field.text())
            _ = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": temp_layer,
                    "FIELD": "scaled_score",
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": width,
                    "HEIGHT": height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 6,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput
                }
            )

            # Set output field and apply style
            self.dlg.SAF_Aggregate_Field.setText(rasOutput)
            styleTemplate = os.path.join(setup['current_script_path'], "Style", f"{setup['Dimension']}.qml")
            styleFileDestination = os.path.join(setup['workingDir'], setup['Dimension'])
            styleFile = f"{os.path.splitext(os.path.basename(rasOutput))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            # Update status
            self.dlg.SAF_status.setText("Processing has been completed!")
            self.dlg.SAF_status.repaint()

        except Exception as e:
            self.dlg.SAF_status.setText(f"Error: {str(e)}")
            self.dlg.SAF_status.repaint()

    def SAFPerceivedSafetyFromNumericFieldRasterizer(self, layer):
        """
        This function rasterizes the Perceived Safety factor for the Urban Safety Factor.
        It converts vector data to raster, applying necessary transformations and standardizations using a scaling approach.
        """
        try:
            # Call the common setup function
            setup = self.CommonRasterizerSetup()

            # Get the field name
            rasField = self.dlg.SAF_rasField_CB.currentText()

            self.dlg.SAF_status.setText("Variables Set")
            self.dlg.SAF_status.repaint()
            time.sleep(0.5)
            self.dlg.SAF_status.setText("Processing...")
            self.dlg.SAF_status.repaint()

            # Ensure the layer is valid
            if not layer.isValid():
                raise ValueError("Invalid layer")

            # Convert CRS if necessary
            if layer.crs() != setup['UTM_crs']:
                layer = processing.run("native:reprojectlayer", {
                    'INPUT': layer,
                    'TARGET_CRS': setup['UTM_crs'],
                    'OUTPUT': 'memory:'
                }, feedback=QgsProcessingFeedback())['OUTPUT']

            # Clip the input layer by the country layer
            clipped_layer = processing.run("native:clip", {
                'INPUT': layer,
                'OVERLAY': setup['countryLayer'],
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

            if not any(clipped_layer.getFeatures()):
                raise ValueError("Clipping resulted in an empty layer")

            # Get min and max values of the field
            values = [f[rasField] for f in clipped_layer.getFeatures() if f[rasField] is not None]
            if not values:
                raise ValueError("No valid values in the selected field")
            min_val, max_val = min(values), max(values)

            # Scale values to the 0-5 range
            def scale_value(val):
                return 0.0 if max_val == min_val else (val - min_val) / (max_val - min_val) * 5.0

            # Create a temporary memory layer to hold the scaled scores
            temp_layer = QgsVectorLayer("Polygon?crs=" + setup['UTM_crs'].authid(), "temp_layer", "memory")
            temp_layer.dataProvider().addAttributes(
                [QgsField("scaled_score", QVariant.Double)])  # Use Double for real numbers
            temp_layer.updateFields()

            # Calculate the scaled scores and add to temp layer
            temp_layer.startEditing()
            for feature in clipped_layer.getFeatures():
                value = feature[rasField]
                score = scale_value(value)
                new_feature = QgsFeature(temp_layer.fields())
                new_feature.setGeometry(feature.geometry())
                new_feature.setAttribute("scaled_score", score)
                temp_layer.addFeature(new_feature)
            temp_layer.commitChanges()

            # Get the extent for rasterization
            extent = setup['country_extent']
            xmin, ymin, xmax, ymax = extent.xMinimum(), extent.yMinimum(), extent.xMaximum(), extent.yMaximum()
            width = int(np.floor((xmax - xmin) / setup['pixelSize']))
            height = int(np.floor((ymax - ymin) / setup['pixelSize']))

            # Rasterize
            rasOutput = os.path.join(setup['workingDir'], setup['Dimension'], self.dlg.SAF_Output_Field.text())
            _ = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": temp_layer,
                    "FIELD": "scaled_score",
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 0,
                    "WIDTH": width,
                    "HEIGHT": height,
                    "EXTENT": None,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 6,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput
                }
            )

            # Set output field and apply style
            self.dlg.SAF_Aggregate_Field.setText(rasOutput)
            styleTemplate = os.path.join(setup['current_script_path'], "Style", f"{setup['Dimension']}.qml")
            styleFileDestination = os.path.join(setup['workingDir'], setup['Dimension'])
            styleFile = f"{os.path.splitext(os.path.basename(rasOutput))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            # Update status
            self.dlg.SAF_status.setText("Processing has been completed!")
            self.dlg.SAF_status.repaint()

        except Exception as e:
            self.dlg.SAF_status.setText(f"Error: {str(e)}")
            self.dlg.SAF_status.repaint()

    def EDURasterizerDelegator(self):
        input_file = self.dlg.EDU_Input_Field.filePath()

        # Check if the input file is empty or not provided
        if not input_file:
            # Get the user-provided value from the spinner
            user_value = self.dlg.EDU_User_Value_Input.value()
            self.EDULevelFromUserValueRasterizer(user_value)
            return
        else:
            self.EDUShapefileRasterizer()
            return

    def EDULevelFromUserValueRasterizer(self, user_value):
        """
        This function rasterizes the Education Level based on a user-provided value.
        It creates a raster with the user-provided value within the country bounds and fills pixels outside the country shape with zero.
        The value provided by the user is in the range 0-100, but the value to render the output at is 0-5,
        so it's user value divided by 20.0.
        """
        try:
            # Call the common setup function
            setup = self.CommonRasterizerSetup()

            # Convert the user-provided value to the 0-5 scale
            render_value = user_value / 20.0

            self.dlg.EDU_status.setText("Variables Set")
            self.dlg.EDU_status.repaint()
            time.sleep(0.5)
            self.dlg.EDU_status.setText("Processing...")
            self.dlg.EDU_status.repaint()

            # Get the extent of the buffered country layer
            xmin, ymin, xmax, ymax = setup['country_extent'].toRectF().getCoords()

            # Initialize raster data with zeros
            width = int(np.floor((xmax - xmin) / setup['pixelSize']))
            height = int(np.floor((ymax - ymin) / setup['pixelSize']))
            raster_data = np.zeros((height, width), dtype=np.float32)

            # Create the transform for the raster
            transform = rasterio.transform.from_origin(xmin, ymax, setup['pixelSize'], setup['pixelSize'])

            # Write initial raster to a temporary file with zeros (NoData value)
            temp_raster_path = os.path.join(setup['tempDir'], "temp_raster.tif")
            with rasterio.open(
                    temp_raster_path, 'w', driver='GTiff', height=height, width=width,
                    count=1, dtype=np.float32, crs=setup['UTM_crs'].toWkt(), transform=transform, nodata=0
            ) as dst:
                dst.write(raster_data, 1)

            # Rasterize the user value within the country bounds
            rasterize_result = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": setup['countryLayer'],
                    "FIELD": None,  # No field since we use a uniform value
                    "BURN": render_value,  # Use the scaled user-provided value
                    "USE_Z": False,
                    "UNITS": 1,
                    "WIDTH": setup['pixelSize'],
                    "HEIGHT": setup['pixelSize'],
                    "EXTENT": f"{xmin},{xmax},{ymin},{ymax}",
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 6,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": temp_raster_path  # Output to the temporary raster
                }
            )

            if not rasterize_result:
                raise ValueError("Rasterization failed. Please check the input data.")

            # Copy the temporary raster to the final output location
            raster_output = os.path.join(setup['workingDir'], setup['Dimension'], self.dlg.EDU_Output_Field.text())
            shutil.move(temp_raster_path, raster_output)

            # Set output field and apply style
            self.dlg.EDU_Aggregate_Field.setText(raster_output)
            styleTemplate = os.path.join(setup['current_script_path'], "Style", f"{setup['Dimension']}.qml")
            styleFile = f"{os.path.splitext(os.path.basename(raster_output))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(setup['workingDir'], setup['Dimension'], styleFile))

            self.dlg.EDU_status.setText("Processing has been completed!")
            self.dlg.EDU_status.repaint()

        except Exception as e:
            self.dlg.EDU_status.setText(f"Error: {str(e)}")
            self.dlg.EDU_status.repaint()

    def EDUShapefileRasterizer(self):
        """
        This function rasterizes the Education factor for the Urban Safety Factor.
        It converts vector data to raster, applying necessary transformations and standardizations using a scaling approach.
        """
        try:
            # Call the common setup function
            setup = self.CommonRasterizerSetup()

            # Update status
            self.dlg.EDU_status.setText("Variables Set")
            self.dlg.EDU_status.repaint()
            time.sleep(0.5)
            self.dlg.EDU_status.setText("Processing...")
            self.dlg.EDU_status.repaint()

            # Get the input layer and field
            rasField = self.dlg.EDU_rasField_CB.currentText()
            polygonLayerPath = os.path.normpath(self.dlg.EDU_Input_Field.filePath())
            polygonLayer = QgsVectorLayer(polygonLayerPath, "polygon_layer", "ogr")
            if not polygonLayer.isValid():
                raise ValueError("Invalid polygon layer")

            # Convert CRS if necessary
            if polygonLayer.crs() != setup['UTM_crs']:
                polygonLayer = processing.run("native:reprojectlayer", {
                    'INPUT': polygonLayer,
                    'TARGET_CRS': setup['UTM_crs'],
                    'OUTPUT': 'memory:'
                }, feedback=QgsProcessingFeedback())['OUTPUT']

            # Clip the input layer by the country layer
            clipped_layer = processing.run("native:clip", {
                'INPUT': polygonLayer,
                'OVERLAY': setup['countryLayer'],
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())['OUTPUT']

            if not any(clipped_layer.getFeatures()):
                raise ValueError("Clipping resulted in an empty layer")

            # Get min and max values of the field
            values = [f[rasField] for f in clipped_layer.getFeatures() if f[rasField] is not None]
            if not values:
                raise ValueError("No valid values in the selected field")
            min_val, max_val = min(values), max(values)

            # Scale values to the 0-5 range
            Rmax, Rmin = 100, 0

            def scale_value(val):
                return (val - Rmin) / (Rmax - Rmin) * 5.0

            # Create a temporary memory layer to hold the scaled scores
            temp_layer = QgsVectorLayer(f"Polygon?crs={setup['UTM_crs'].authid()}", "temp_layer", "memory")
            temp_layer.dataProvider().addAttributes([QgsField("scaled_score", QVariant.Double)])
            temp_layer.updateFields()

            # Calculate the scaled scores and add to temp layer
            temp_layer.startEditing()
            for feature in clipped_layer.getFeatures():
                value = feature[rasField]
                score = scale_value(value)
                new_feature = QgsFeature(temp_layer.fields())
                new_feature.setGeometry(feature.geometry())
                new_feature.setAttribute("scaled_score", score)
                temp_layer.addFeature(new_feature)
            temp_layer.commitChanges()

            # Get the extent for rasterization
            xmin, ymin, xmax, ymax = setup['country_extent'].toRectF().getCoords()
            print(f"Extent: xmin={xmin}, xmax={xmax}, ymin={ymin}, ymax={ymax}")

            # Rasterize
            rasOutput = os.path.join(setup['workingDir'], setup['Dimension'], self.dlg.EDU_Output_Field.text())
            rasterize_result = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": temp_layer,
                    "FIELD": "scaled_score",
                    "BURN": 0.0,
                    "USE_Z": False,
                    "UNITS": 1,
                    "WIDTH": setup['pixelSize'],
                    "HEIGHT": setup['pixelSize'],
                    "EXTENT": f"{xmin},{xmax},{ymin},{ymax}",
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,
                    "INIT": None,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": rasOutput
                }
            )

            if not rasterize_result:
                raise ValueError("Rasterization failed. Please check the input data.")

            # Set output field and apply style
            self.dlg.EDU_Aggregate_Field.setText(rasOutput)
            styleTemplate = os.path.join(setup['current_script_path'], "Style", f"{setup['Dimension']}.qml")
            styleFileDestination = os.path.join(setup['workingDir'], setup['Dimension'])
            styleFile = f"{os.path.splitext(os.path.basename(rasOutput))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            # Update status
            self.dlg.EDU_status.setText("Processing has been completed!")
            self.dlg.EDU_status.repaint()

        except Exception as e:
            self.dlg.EDU_status.setText(f"Error: {str(e)}")
            self.dlg.EDU_status.repaint()

    def ELCnightTimeLights(self):
        """
        This function use a linearly scales the night time lights raster dataset according to the standardized scoring system.
        How brightly lit an area is is used as a proxy ro electricty access.

        Factors it is applied:
            Place Characterization Dimension
                - Electrical Access
        """
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        tempDir = "temp"
        Dimension = "Place Characterization"

        if os.path.exists(Dimension):
            pass
        else:
            os.mkdir(Dimension)

        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        NTL_input = self.dlg.ELC_NTLInput_Field.filePath()
        rasOutput = self.dlg.ELC_NTLOutput_Field.text()

        # Temp files
        tempCalc = f"{tempDir}/tempCalc.tif"
        tempResample = f"{tempDir}/tempResample.tif"
        countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.ELCNTL_status.setText("Variables Set")
        self.dlg.ELCNTL_status.repaint()
        time.sleep(0.5)
        self.dlg.ELCNTL_status.setText("Processing...")
        self.dlg.ELCNTL_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": countryUTMLayerBuf,
            },
        )

        # countryUTMLayerBuf = buffer["OUTPUT"]

        CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
        country_extent = CountryBuf_df.total_bounds

        processing.run(
            "gdal:warpreproject",
            {
                "INPUT": NTL_input,
                "SOURCE_CRS": None,
                "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "RESAMPLING": 0,
                "NODATA": -9999,
                "TARGET_RESOLUTION": pixelSize,
                "OPTIONS": "",
                "DATA_TYPE": 0,
                "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "MULTITHREADING": False,
                "EXTRA": "",
                "OUTPUT": tempResample,
            },
        )

        processing.run(
            "gdal:rastercalculator",
            {
                "INPUT_A": tempResample,
                "BAND_A": 1,
                "INPUT_B": None,
                "BAND_B": None,
                "INPUT_C": None,
                "BAND_C": None,
                "INPUT_D": None,
                "BAND_D": None,
                "INPUT_E": None,
                "BAND_E": None,
                "INPUT_F": None,
                "BAND_F": None,
                "FORMULA": "A*1000",
                "NO_DATA": None,
                "EXTENT_OPT": 0,
                "PROJWIN": None,
                "RTYPE": 4,
                "OPTIONS": "",
                "EXTRA": "",
                "OUTPUT": tempCalc,
            },
        )

        with rasterio.open(tempCalc, "r+") as src:
            ELC_ras = src.read(1)
            meta1 = src.meta

            Rmax = ELC_ras.max()
            Rmin = ELC_ras.min()
            m_max = 5
            m_min = 0

        result = ((ELC_ras - Rmin) / (Rmax - Rmin)) * m_max
        meta1.update(dtype=rasterio.float32)

        if os.path.exists(Dimension):
            os.chdir(Dimension)
        else:
            os.mkdir(Dimension)
            os.chdir(Dimension)

        with rasterio.open(rasOutput, "w", **meta1) as dst:
            dst.write(result, 1)

        self.dlg.ELC_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        self.dlg.ELCNTL_status.setText("Processing Complete!")
        self.dlg.ELCNTL_status.repaint()

        os.chdir(workingDir)

    def WAS_rasterizer_v2(self):
        try:
            # Set up variables
            setup = self.CommonRasterizerSetup()
            workingDir = os.path.abspath(setup["workingDir"])
            Dimension = setup["Dimension"]
            tempDir = os.path.abspath(setup["tempDir"])
            countryLayer = setup["countryLayer"]
            country_extent = setup["country_extent"]
            pixelSize = setup["pixelSize"]
            UTM_crs = setup["UTM_crs"]
            current_script_path = setup["current_script_path"]

            print(f"Working directory: {workingDir}")
            print(f"Temp directory: {tempDir}")

            # Check if temp directory exists and is writable
            if not os.path.exists(tempDir):
                os.makedirs(tempDir)
            if not os.access(tempDir, os.W_OK):
                raise PermissionError(f"Temp directory is not writable: {tempDir}")

            # Update status
            self.dlg.WAS_status.setText("Processing...")
            self.dlg.WAS_status.repaint()

            # Load and validate the point layer
            pointlayer = self.dlg.WAS_Input_Field.filePath()
            pointUTMLayer = QgsVectorLayer(pointlayer, "pointUTMLayer", "ogr")
            if not pointUTMLayer.isValid():
                raise ValueError("Invalid point layer")

            # Convert CRS if necessary
            if pointUTMLayer.crs() != UTM_crs:
                pointUTMLayer = processing.run("native:reprojectlayer", {
                    'INPUT': pointUTMLayer,
                    'TARGET_CRS': UTM_crs,
                    'OUTPUT': 'memory:'
                }, feedback=QgsProcessingFeedback())['OUTPUT']

            # Buffer the points
            self.dlg.WAS_status.setText("Buffering points...")
            self.dlg.WAS_status.repaint()
            buffer_result = processing.run("native:buffer", {
                'INPUT': pointUTMLayer,
                'DISTANCE': 1000,
                'SEGMENTS': 50,
                'END_CAP_STYLE': 0,
                'JOIN_STYLE': 0,
                'MITER_LIMIT': 2,
                'DISSOLVE': False,
                'OUTPUT': 'memory:'
            }, feedback=QgsProcessingFeedback())
            buffer_layer = buffer_result['OUTPUT']

            # Add buffer value field
            rasField = "buffer_value"
            buffer_layer.dataProvider().addAttributes([QgsField(rasField, QVariant.Double)])
            buffer_layer.updateFields()

            buffer_layer.startEditing()
            for feature in buffer_layer.getFeatures():
                feature[rasField] = 5.0
                buffer_layer.updateFeature(feature)
            buffer_layer.commitChanges()

            # Rasterize
            temp_raster = os.path.join(tempDir, "temp_WAS.tif")
            print(f"Temporary raster path: {temp_raster}")
            self.dlg.WAS_status.setText("Rasterizing...")
            self.dlg.WAS_status.repaint()
            rasterize_result = processing.run(
                "gdal:rasterize",
                {
                    "INPUT": buffer_layer,
                    "FIELD": rasField,
                    "BURN": 0,
                    "USE_Z": False,
                    "UNITS": 1,
                    "WIDTH": pixelSize,
                    "HEIGHT": pixelSize,
                    "EXTENT": country_extent,
                    "NODATA": -9999,
                    "OPTIONS": "",
                    "DATA_TYPE": 5,  # Float32
                    "INIT": 0,
                    "INVERT": False,
                    "EXTRA": "",
                    "OUTPUT": temp_raster
                }
            )

            # Check if rasterization was successful
            if not os.path.exists(temp_raster):
                raise FileNotFoundError(f"Rasterization failed. Output file not created: {temp_raster}")

            print(f"Raster file created successfully: {temp_raster}")

            # Clip raster to country shape
            rasOutput = os.path.join(workingDir, Dimension, self.dlg.WAS_Output_Field.text())
            print(f"Final output path: {rasOutput}")
            self.dlg.WAS_status.setText("Clipping to country...")
            self.dlg.WAS_status.repaint()
            clip_result = processing.run("gdal:cliprasterbymasklayer", {
                'INPUT': temp_raster,
                'MASK': countryLayer,
                'SOURCE_CRS': None,
                'TARGET_CRS': QgsCoordinateReferenceSystem(UTM_crs),
                'NODATA': -9999,
                'ALPHA_BAND': False,
                'CROP_TO_CUTLINE': False,
                'KEEP_RESOLUTION': True,
                'SET_RESOLUTION': False,
                'DATA_TYPE': 5,
                'OUTPUT': rasOutput
            })

            # Check if clipping was successful
            if not os.path.exists(rasOutput):
                raise FileNotFoundError(f"Clipping failed. Output file not created: {rasOutput}")

            print(f"Clipped raster file created successfully: {rasOutput}")

            # Clean up temporary file
            if os.path.exists(temp_raster):
                os.remove(temp_raster)
                print(f"Temporary file removed: {temp_raster}")

            # Set output field and apply style
            self.dlg.WAS_Aggregate_Field.setText(rasOutput)
            styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
            styleFileDestination = os.path.join(workingDir, Dimension)
            styleFile = f"{os.path.splitext(os.path.basename(rasOutput))[0]}.qml"
            shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

            # Update status
            self.dlg.WAS_status.setText("Processing has been completed!")
            self.dlg.WAS_status.repaint()

        except Exception as e:
            self.dlg.WAS_status.setText(f"Error: {str(e)}")
            self.dlg.WAS_status.repaint()
            print(f"Error in WAS_rasterizer_v2: {str(e)}")
            raise

    def urbanization(self):
        """
        This algorithm characterizes areas based on their degree of urbanization. The algorithm reclassifies the eight
        classes in the input data into classes ranging from 0 to 5 as per the standardized scoring system.

        Factors it is applied:
            Place Characterization Dimension
                - Level of Urbanization
        """
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        tempDir = "temp"
        Dimension = "Place Characterization"

        if os.path.exists(Dimension):
            pass
        else:
            os.mkdir(Dimension)

        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]

        LOU_input = self.dlg.LOU_Input_Field.filePath()
        rasOutput = self.dlg.LOU_Output_Field.text()
        rasField = "Score"

        # Temp Files
        tempRas = f"{tempDir}/RasReproj.tif"
        tempVect = f"{tempDir}/tempVect.shp"
        Dissolve = f"{tempDir}/Dissolve.shp"
        DisReclass = f"{tempDir}/DisReclass.shp"

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.LOU_status.setText("Variables Set")
        self.dlg.LOU_status.repaint()
        time.sleep(0.5)
        self.dlg.LOU_status.setText("Processing...")
        self.dlg.LOU_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        shp_utm[rasField] = [0]
        countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": "memory:",
            },
        )

        countryUTMLayerBuf = buffer["OUTPUT"]

        Reproject = processing.run(
            "gdal:warpreproject",
            {
                "INPUT": LOU_input,
                "SOURCE_CRS": None,
                "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "RESAMPLING": 0,
                "NODATA": -9999,
                "TARGET_RESOLUTION": None,
                "OPTIONS": "",
                "DATA_TYPE": 0,
                "TARGET_EXTENT": None,
                "TARGET_EXTENT_CRS": None,
                "MULTITHREADING": False,
                "EXTRA": "",
                "OUTPUT": tempRas,
            },
        )

        vector = processing.run(
            "gdal:polygonize",
            {
                "INPUT": tempRas,
                "BAND": 1,
                "FIELD": "DN",
                "EIGHT_CONNECTEDNESS": False,
                "EXTRA": "",
                "OUTPUT": tempVect,
            },
        )

        time.sleep(0.5)

        dissolve = processing.run(
            "native:dissolve",
            {
                "INPUT": tempVect,
                "FIELD": ["DN"],
                "SEPARATE_DISJOINT": False,
                "OUTPUT": Dissolve,
            },
        )

        time.sleep(0.5)

        GHS_df = gpd.read_file(Dissolve)
        GHS_df["Score"] = 0
        GHS_df["Score"] = GHS_df["Score"].astype(int)

        conditions = [
            (GHS_df["DN"] == 30),
            (GHS_df["DN"] == 23),
            (GHS_df["DN"] == 22),
            (GHS_df["DN"] == 21),
            (GHS_df["DN"] == 13),
            (GHS_df["DN"] == 12),
            (GHS_df["DN"] == 11),
            (GHS_df["DN"] == 10),
        ]

        values = [5, 4, 3, 3, 2, 1, 1, 0]
        GHS_df["Score"] = np.select(conditions, values)

        GHS_vec = QgsVectorLayer(GHS_df.to_json(), "GHS_vec", "ogr")

        Clip = processing.run(
            "native:clip",
            {"INPUT": GHS_vec, "OVERLAY": countryUTMLayerBuf, "OUTPUT": "memory:"},
        )

        Clip_out = Clip["OUTPUT"]

        extent = Clip_out.extent()
        raster_width = int(extent.width() / pixelSize)
        raster_height = int(extent.height() / pixelSize)

        os.chdir(Dimension)
        rasOutput = self.dlg.LOU_Output_Field.text()

        rasterize = processing.run(
            "gdal:rasterize",
            {
                "INPUT": Clip_out,
                "FIELD": rasField,
                "BURN": 0,
                "USE_Z": False,
                "UNITS": 0,
                "WIDTH": raster_width,
                "HEIGHT": raster_height,
                "EXTENT": None,
                "NODATA": -9999,
                "OPTIONS": "",
                "DATA_TYPE": 5,
                "INIT": None,
                "INVERT": False,
                "EXTRA": "",
                "OUTPUT": rasOutput,
            },
        )

        self.dlg.LOU_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        self.dlg.LOU_status.setText("Processing Complete!")
        self.dlg.LOU_status.repaint()

    def housing(self):
        """
        This function characterizes areas based on the size of housing and assumes that buildings with a footprint of less than 60 m2 are more likely to represent informal housing typologies.
        algorithm calculates the area of each building footprint in the input layer. It then overlays the input layer onto a hexagonal grid and calculates the percentage
        of buildings within each hexagonal cell with a footprint greater than 60 m2.

        The output produced is a raster file containing values ranging from 0 to 5 is saved to the output directory. In this scale,
        5 signifies areas where 100% of buildings have a footprint larger than 60 m2 (and can be interpreted as entirely formal settlements),
        while 0 indicates areas where no buildings possess a footprint larger than 60 m2 (and can be interpreted as entirely informal settlements).

        Factors it is applied:
            Place Characterization Dimension
                - Size of Housing
        """
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        tempDir = "temp"
        Dimension = "Place Characterization"

        if os.path.exists(Dimension):
            pass
        else:
            os.mkdir(Dimension)

        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        hexSize = self.dlg.QUH_hexSize_SB.value()
        buildingFootprints = self.dlg.QUH_Input_Field.filePath()
        rasField = "Perc"

        # TempFiles
        scoredRoads = f"{workingDir}/{tempDir}/Scored_roads.shp"
        adminUTMLayer = f"{tempDir}/adminUTMLayer.shp"
        buildingOutput = f"{tempDir}/buildingOutput.shp"
        hexPercOutput = f"{tempDir}/hexPercOutput.shp"
        hexRasOutput = f"{tempDir}/hexRasOutput.tif"
        zonalOutput = f"{tempDir}/zonalOutput.shp"
        buildingFootprintsUTM = f"{tempDir}/buildingFootprintsUTM.shp"

        self.dlg.QUH_status.setText("Variables Set")
        self.dlg.QUH_status.repaint()
        time.sleep(0.5)
        self.dlg.QUH_status.setText("Processing...")
        self.dlg.QUH_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        shp_utm[rasField] = [0]
        countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": "memory:",
            },
        )

        countryUTMLayerBuf = buffer["OUTPUT"]

        country_extent = shp_utm.total_bounds

        Grid = processing.run(
            "native:creategrid",
            {
                "TYPE": 4,
                "EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                "HSPACING": hexSize,
                "VSPACING": hexSize,
                "HOVERLAY": 0,
                "VOVERLAY": 0,
                "CRS": QgsCoordinateReferenceSystem(f"{UTM_crs}"),
                "OUTPUT": "memory:",
            },
        )
        grid_out = Grid["OUTPUT"]

        Clip = processing.run(
            "native:clip",
            {"INPUT": grid_out, "OVERLAY": countryUTMLayer, "OUTPUT": "memory:"},
        )

        clip_out = Clip["OUTPUT"]

        # Rasterize hexegons
        extent = clip_out.extent()
        raster_width = int(extent.width() / (pixelSize / 10))
        raster_height = int(extent.height() / (pixelSize))

        rasterize = processing.run(
            "gdal:rasterize",
            {
                "INPUT": clip_out,
                "FIELD": "id",
                "BURN": 0,
                "USE_Z": False,
                "UNITS": 0,
                "WIDTH": raster_width,
                "HEIGHT": raster_height,
                "EXTENT": None,
                "NODATA": -9999,
                "OPTIONS": "",
                "DATA_TYPE": 5,
                "INIT": None,
                "INVERT": False,
                "EXTRA": "",
                "OUTPUT": hexRasOutput,
            },
        )

        self.convertCRS(buildingFootprints, UTM_crs)
        shp_utm.to_file(buildingFootprintsUTM)

        # Zonal Statistics using majority

        zonal = processing.run(
            "native:zonalstatisticsfb",
            {
                "INPUT": QgsProcessingFeatureSourceDefinition(
                    buildingFootprintsUTM,
                    selectedFeaturesOnly=False,
                    featureLimit=-1,
                    flags=QgsProcessingFeatureSourceDefinition.FlagOverrideDefaultGeometryCheck,
                    geometryCheck=QgsFeatureRequest.GeometrySkipInvalid,
                ),
                "INPUT_RASTER": hexRasOutput,
                "RASTER_BAND": 1,
                "COLUMN_PREFIX": "_",
                "STATISTICS": [9],
                "OUTPUT": zonalOutput,
            },
        )

        Clip = processing.run(
            "native:clip",
            {"INPUT": grid_out, "OVERLAY": countryUTMLayer, "OUTPUT": adminUTMLayer},
        )

        BF_gdf = gpd.read_file(zonalOutput)
        Admin_gdf = gpd.read_file(adminUTMLayer)
        BF_gdf = gpd.overlay(Admin_gdf, BF_gdf, how="intersection")

        building_geometries = BF_gdf["geometry"]
        BF_gdf["Area"] = building_geometries.area
        BF_gdf["more_60"] = 0
        BF_gdf.loc[BF_gdf["Area"] > 60, "more_60"] = 1
        BF_gdf["id"] = BF_gdf["_majority"].astype(int)
        BF_gdf.to_file(buildingOutput)

        grouped = BF_gdf.groupby("id").size().reset_index(name="Total_Count")

        filtered_df = BF_gdf[BF_gdf["more_60"] == 1]

        grouped2 = filtered_df.groupby("id").size().reset_index(name="More60_Count")

        merged = pd.merge(grouped, grouped2, on=["id"], how="outer")
        merged_length_gdf = pd.DataFrame(merged)
        merged_length_gdf[rasField] = (
                merged_length_gdf["More60_Count"] / merged_length_gdf["Total_Count"] * 100
        )

        hex_gdf = gpd.read_file(adminUTMLayer)
        merge_hex_gdf = hex_gdf.merge(merged_length_gdf, on="id", how="outer")
        # merge_hex_gdf.to_file(FinalHexOutput)

        # Rasterization

        Rmax = 100
        Rmin = 0
        m_max = 5
        m_min = 0

        merge_hex_gdf[rasField] = (
                (merge_hex_gdf[rasField] - Rmin) / (Rmax - Rmin) * m_max
        )
        merge_hex_gdf.to_file(hexPercOutput)

        Difference = processing.run(
            "native:difference",
            {
                "INPUT": countryUTMLayerBuf,
                "OVERLAY": hexPercOutput,
                "OUTPUT": "memory:",
                "GRID_SIZE": None,
            },
        )

        difference = Difference["OUTPUT"]

        diff = processing.run(
            "native:polygonstolines",
            {
                "INPUT": difference,
                "OUTPUT": "memory:"
            }
        )

        difference = diff["OUTPUT"]

        Merge = processing.run(
            "native:mergevectorlayers",
            {"LAYERS": [hexPercOutput, difference], "CRS": None, "OUTPUT": "memory:"},
        )

        mergeOutput = Merge["OUTPUT"]

        extent = mergeOutput.extent()
        raster_width = int(extent.width() / pixelSize)
        raster_height = int(extent.height() / pixelSize)

        os.chdir(Dimension)

        rasOutput = self.dlg.QUH_Output_Field.text()

        rasterize = processing.run(
            "gdal:rasterize",
            {
                "INPUT": mergeOutput,
                "FIELD": rasField,
                "BURN": 0,
                "USE_Z": False,
                "UNITS": 0,
                "WIDTH": raster_width,
                "HEIGHT": raster_height,
                "EXTENT": None,
                "NODATA": -9999,
                "OPTIONS": "",
                "DATA_TYPE": 5,
                "INIT": None,
                "INVERT": False,
                "EXTRA": "",
                "OUTPUT": rasOutput,
            },
        )

        self.dlg.QUH_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.QUH_status.setText("Processing Complete!")
        self.dlg.QUH_status.repaint()

    def natEnvironment(self):
        """
        This function is used in combination with the "TypeSet" and "uniqueValues" functions to execute the Natural Environment and Climatic factors algorithm.
        The input layers are rasterized according to the scoring assigned to the unique hazard values.

        Factors it is applied:
            Place Characterization Dimension
                - Environmental Hazards
        """
        try:
            # Set up variables
            current_script_path = os.path.dirname(os.path.abspath(__file__))
            workingDir = self.dlg.workingDir_Field.text()
            Dimension = "Place Characterization"
            tempDir = os.path.join(workingDir, "temp")

            if not os.path.exists(workingDir):
                os.mkdir(workingDir)

            dimension_dir = os.path.join(workingDir, Dimension)
            if not os.path.exists(dimension_dir):
                os.mkdir(dimension_dir)

            if os.path.exists(tempDir):
                shutil.rmtree(tempDir)
            time.sleep(0.5)
            os.mkdir(tempDir)

            # Temp files
            tempCalc = f"{tempDir}/tempEnvCalc.tif"
            tempResample = f"{tempDir}/tempEnvResample.tif"
            tempClipResample = f"{tempDir}/tempEnvClipResample.tif"
            countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"


            UTM_crs = self.dlg.mQgsProjectionSelectionWidget.crs()
            countryLayerPath = self.dlg.countryLayer_Field.filePath()
            pixelSize = self.dlg.pixelSize_SB.value()
            fireHazardLayer = self.dlg.ENV_Input_Field.filePath()
            floodLayer = self.dlg.ENV_Input_Field_2.filePath()
            landSlideLayer = self.dlg.ENV_Input_Field_3.filePath()
            cycloneLayer = self.dlg.ENV_Input_Field_4.filePath()
            droughtLayer = self.dlg.ENV_Input_Field_5.filePath()
            #riskLevelField = self.dlg.ENV_riskLevelField_CB.currentText()

            rasField = "Score"

            self.dlg.ENV_status.setText("Variables Set")
            self.dlg.ENV_status.repaint()
            time.sleep(0.5)
            self.dlg.ENV_status.setText("Processing...")
            self.dlg.ENV_status.repaint()

            # Load and reproject country layer if necessary
            countryLayer = QgsVectorLayer(countryLayerPath, "country_layer", "ogr")
            if not countryLayer.isValid():
                raise ValueError("Invalid country layer")
            if countryLayer.crs() != UTM_crs:
                countryLayer = processing.run("native:reprojectlayer", {
                    'INPUT': countryLayer,
                    'TARGET_CRS': UTM_crs,
                    'OUTPUT': 'memory:'
                })['OUTPUT']

            # Ensure spatial index exists
            _ = QgsSpatialIndex(countryLayer.getFeatures())
            #_ = QgsSpatialIndex(polygonLayer.getFeatures())

            # Buffer the country layer
            buffer = processing.run(
                "native:buffer",
                {
                    "INPUT": countryLayer,
                    "DISTANCE": self.BUFFER_DISTANCE,
                    "SEGMENTS": 5,
                    "END_CAP_STYLE": 0,
                    "JOIN_STYLE": 0,
                    "MITER_LIMIT": 2,
                    "DISSOLVE": True,
                    "SEPARATE_DISJOINT": False,
                    "OUTPUT": countryUTMLayerBuf,
                },
            )
            countryUTMLayerBuf = buffer["OUTPUT"]

            CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
            country_extent = CountryBuf_df.total_bounds

            if fireHazardLayer:
                processing.run(
                    "gdal:warpreproject",
                    {
                        "INPUT": fireHazardLayer,
                        "SOURCE_CRS": None,
                        "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "RESAMPLING": 0,
                        "NODATA": -9999,
                        "TARGET_RESOLUTION": pixelSize,
                        "OPTIONS": "",
                        "DATA_TYPE": 0,
                        "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                        "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "MULTITHREADING": False,
                        "EXTRA": "",
                        "OUTPUT": tempResample,
                    },
                )

                with rasterio.open(tempResample, "r+") as src:
                    ENV_ras = src.read(1)
                    meta1 = src.meta

                    #Rmax = ENV_ras.max()
                    #Rmin = ENV_ras.min()
                    #m_max = 5
                    #m_min = 0

                    #result = ((ENV_ras - Rmin) / (Rmax - Rmin)) * m_max
                    reclassified_ras = np.vectorize(self.reclassifyFireHazards)(ENV_ras)
                    meta1.update(dtype=rasterio.float32)

                if os.path.exists(f"{workingDir}/{Dimension}/ENV"):
                    os.chdir(f"{workingDir}/{Dimension}/ENV")
                else:
                    os.mkdir(f"{workingDir}/{Dimension}/ENV")
                    os.chdir(f"{workingDir}/{Dimension}/ENV")

                rasOutput = f"{self.dlg.ENV_Output_Field.text()[:-4]}Fire_Density.tif"

                with rasterio.open(tempClipResample, "w", **meta1) as dst:
                    dst.write(reclassified_ras, 1)

                processing.run("gdal:cliprasterbymasklayer", {
                    'INPUT': tempClipResample,
                    'MASK': countryLayer,
                    'SOURCE_CRS': None,
                    'TARGET_CRS': QgsCoordinateReferenceSystem(UTM_crs),
                    'NODATA': 0,
                    'ALPHA_BAND': False,
                    'CROP_TO_CUTLINE': False,
                    'KEEP_RESOLUTION': True,
                    'SET_RESOLUTION': False,
                    'X_RESOLUTION': None,
                    'Y_RESOLUTION': None,
                    'MULTITHREADING': False,
                    'OPTIONS': '',
                    'DATA_TYPE': 0,  # Use 0 for the same data type as the input
                    'EXTRA': '',
                    'OUTPUT': rasOutput
                })

                self.dlg.ENV_Aggregate_Field.setText(rasOutput)

                # Copy style file
                styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
                styleFileDestination = os.path.join(dimension_dir, "ENV")
                if not os.path.exists(styleFileDestination):
                    os.mkdir(styleFileDestination)
                styleFile = f"{os.path.splitext(rasOutput)[0]}.qml"
                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                self.dlg.ENV_status.setText("Processing Complete!")
                self.dlg.ENV_status.repaint()

            if floodLayer:
                processing.run(
                    "gdal:warpreproject",
                    {
                        "INPUT": floodLayer,
                        "SOURCE_CRS": None,
                        "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "RESAMPLING": 0,
                        "NODATA": -9999,
                        "TARGET_RESOLUTION": pixelSize,
                        "OPTIONS": "",
                        "DATA_TYPE": 0,
                        "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                        "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "MULTITHREADING": False,
                        "EXTRA": "",
                        "OUTPUT": tempResample,
                    },
                )

                with rasterio.open(tempResample, "r+") as src:
                    ENV_ras = src.read(1)
                    meta1 = src.meta

                    #Rmax = ENV_ras.max()
                    #Rmin = ENV_ras.min()
                    #m_max = 5
                    #m_min = 0
                    #nodata_value = src.nodata

                    #result = ((ENV_ras - Rmin) / (Rmax - Rmin)) * m_max
                    reclassified_ras = np.vectorize(self.reclassifyFloodHazard)(ENV_ras)
                    meta1.update(dtype=rasterio.float32)

                if os.path.exists(f"{workingDir}/{Dimension}/ENV"):
                    os.chdir(f"{workingDir}/{Dimension}/ENV")
                else:
                    os.mkdir(f"{workingDir}/{Dimension}/ENV")
                    os.chdir(f"{workingDir}/{Dimension}/ENV")

                rasOutput = f"{self.dlg.ENV_Output_Field.text()[:-4]}Flood.tif"

                with rasterio.open(tempClipResample, "w", **meta1) as dst:
                    dst.write(reclassified_ras, 1)

                processing.run("gdal:cliprasterbymasklayer", {
                    'INPUT': tempClipResample,
                    'MASK': countryLayer,
                    'SOURCE_CRS': None,
                    'TARGET_CRS': QgsCoordinateReferenceSystem(UTM_crs),
                    'NODATA': 0,
                    'ALPHA_BAND': False,
                    'CROP_TO_CUTLINE': False,
                    'KEEP_RESOLUTION': True,
                    'SET_RESOLUTION': False,
                    'X_RESOLUTION': None,
                    'Y_RESOLUTION': None,
                    'MULTITHREADING': False,
                    'OPTIONS': '',
                    'DATA_TYPE': 0,  # Use 0 for the same data type as the input
                    'EXTRA': '',
                    'OUTPUT': rasOutput
                })

                self.dlg.ENV_Aggregate_Field.setText(rasOutput)

                # Copy style file
                styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
                styleFileDestination = os.path.join(dimension_dir, "ENV")
                if not os.path.exists(styleFileDestination):
                    os.mkdir(styleFileDestination)
                styleFile = f"{os.path.splitext(rasOutput)[0]}.qml"
                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                self.dlg.ENV_status.setText("Processing Complete!")
                self.dlg.ENV_status.repaint()

            if landSlideLayer:
                processing.run(
                    "gdal:warpreproject",
                    {
                        "INPUT": landSlideLayer,
                        "SOURCE_CRS": None,
                        "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "RESAMPLING": 0,
                        "NODATA": -9999,
                        "TARGET_RESOLUTION": pixelSize,
                        "OPTIONS": "",
                        "DATA_TYPE": 0,
                        "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                        "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "MULTITHREADING": False,
                        "EXTRA": "",
                        "OUTPUT": tempResample,
                    },
                )

                with rasterio.open(tempResample, "r+") as src:
                    ENV_ras = src.read(1)
                    meta1 = src.meta

                    #Rmax = ENV_ras.max()
                    #Rmin = ENV_ras.min()
                    #m_max = 5
                    #m_min = 0

                    #result = ((ENV_ras - Rmin) / (Rmax - Rmin)) * m_max
                    reclassified_ras = np.vectorize(self.reclassifyLandslide)(ENV_ras)
                    meta1.update(dtype=rasterio.float32)

                if os.path.exists(f"{workingDir}/{Dimension}/ENV"):
                    os.chdir(f"{workingDir}/{Dimension}/ENV")
                else:
                    os.mkdir(f"{workingDir}/{Dimension}/ENV")
                    os.chdir(f"{workingDir}/{Dimension}/ENV")

                rasOutput = f"{self.dlg.ENV_Output_Field.text()[:-4]}Landslide_Susceptibility.tif"

                with rasterio.open(tempClipResample, "w", **meta1) as dst:
                    dst.write(reclassified_ras, 1)

                processing.run("gdal:cliprasterbymasklayer", {
                    'INPUT': tempClipResample,
                    'MASK': countryLayer,
                    'SOURCE_CRS': None,
                    'TARGET_CRS': QgsCoordinateReferenceSystem(UTM_crs),
                    'NODATA': None,
                    'ALPHA_BAND': False,
                    'CROP_TO_CUTLINE': False,
                    'KEEP_RESOLUTION': True,
                    'SET_RESOLUTION': False,
                    'X_RESOLUTION': None,
                    'Y_RESOLUTION': None,
                    'MULTITHREADING': False,
                    'OPTIONS': '',
                    'DATA_TYPE': 0,  # Use 0 for the same data type as the input
                    'EXTRA': '',
                    'OUTPUT': rasOutput
                })

                self.dlg.ENV_Aggregate_Field.setText(rasOutput)

                # Copy style file
                styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
                styleFileDestination = os.path.join(dimension_dir, "ENV")
                if not os.path.exists(styleFileDestination):
                    os.mkdir(styleFileDestination)
                styleFile = f"{os.path.splitext(rasOutput)[0]}.qml"
                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                self.dlg.ENV_status.setText("Processing Complete!")
                self.dlg.ENV_status.repaint()

            if cycloneLayer:
                processing.run(
                    "gdal:warpreproject",
                    {
                        "INPUT": cycloneLayer,
                        "SOURCE_CRS": None,
                        "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "RESAMPLING": 0,
                        "NODATA": -9999,
                        "TARGET_RESOLUTION": pixelSize,
                        "OPTIONS": "",
                        "DATA_TYPE": 0,
                        "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                        "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "MULTITHREADING": False,
                        "EXTRA": "",
                        "OUTPUT": tempResample,
                    },
                )

                with rasterio.open(tempResample, "r+") as src:
                    ENV_ras = src.read(1)
                    meta1 = src.meta

                    #Rmax = ENV_ras.max()
                    #Rmin = ENV_ras.min()
                    #m_max = 5
                    #m_min = 0

                    #result = ((ENV_ras - Rmin) / (Rmax - Rmin)) * m_max
                    reclassified_ras = np.vectorize(self.reclassifyTropicalCyclone)(ENV_ras)
                    meta1.update(dtype=rasterio.float32)

                if os.path.exists(f"{workingDir}/{Dimension}/ENV"):
                    os.chdir(f"{workingDir}/{Dimension}/ENV")
                else:
                    os.mkdir(f"{workingDir}/{Dimension}/ENV")
                    os.chdir(f"{workingDir}/{Dimension}/ENV")

                rasOutput = f"{self.dlg.ENV_Output_Field.text()[:-4]}Cyclones.tif"

                with rasterio.open(tempClipResample, "w", **meta1) as dst:
                    dst.write(reclassified_ras, 1)

                processing.run("gdal:cliprasterbymasklayer", {
                    'INPUT': tempClipResample,
                    'MASK': countryLayer,
                    'SOURCE_CRS': None,
                    'TARGET_CRS': QgsCoordinateReferenceSystem(UTM_crs),
                    'NODATA': 0,
                    'ALPHA_BAND': False,
                    'CROP_TO_CUTLINE': False,
                    'KEEP_RESOLUTION': True,
                    'SET_RESOLUTION': False,
                    'X_RESOLUTION': None,
                    'Y_RESOLUTION': None,
                    'MULTITHREADING': False,
                    'OPTIONS': '',
                    'DATA_TYPE': 0,  # Use 0 for the same data type as the input
                    'EXTRA': '',
                    'OUTPUT': rasOutput
                })

                self.dlg.ENV_Aggregate_Field.setText(rasOutput)

                # Copy style file
                styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
                styleFileDestination = os.path.join(dimension_dir, "ENV")
                if not os.path.exists(styleFileDestination):
                    os.mkdir(styleFileDestination)
                styleFile = f"{os.path.splitext(rasOutput)[0]}.qml"
                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                self.dlg.ENV_status.setText("Processing Complete!")
                self.dlg.ENV_status.repaint()

            if droughtLayer:
                processing.run(
                    "gdal:warpreproject",
                    {
                        "INPUT": droughtLayer,
                        "SOURCE_CRS": None,
                        "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "RESAMPLING": 0,
                        "NODATA": -9999,
                        "TARGET_RESOLUTION": pixelSize,
                        "OPTIONS": "",
                        "DATA_TYPE": 0,
                        "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                        "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                        "MULTITHREADING": False,
                        "EXTRA": "",
                        "OUTPUT": tempResample,
                    },
                )

                with rasterio.open(tempResample, "r+") as src:
                    ENV_ras = src.read(1)
                    meta1 = src.meta

                    #Rmax = ENV_ras.max()
                    #Rmin = ENV_ras.min()
                    #m_max = 5
                    #m_min = 0
                    # Retrieve the NoData value from the metadata
                    nodata_value = src.nodata

                    #result = ((ENV_ras - Rmin) / (Rmax - Rmin)) * m_max
                    reclassified_ras = np.vectorize(self.reclassifyDrought)(ENV_ras, nodata_value)
                    meta1.update(dtype=rasterio.float32)

                if os.path.exists(f"{workingDir}/{Dimension}/ENV"):
                    os.chdir(f"{workingDir}/{Dimension}/ENV")
                else:
                    os.mkdir(f"{workingDir}/{Dimension}/ENV")
                    os.chdir(f"{workingDir}/{Dimension}/ENV")

                rasOutput = f"{self.dlg.ENV_Output_Field.text()[:-4]}Drought.tif"

                with rasterio.open(tempClipResample, "w", **meta1) as dst:
                    dst.write(reclassified_ras, 1)

                processing.run("gdal:cliprasterbymasklayer", {
                    'INPUT': tempClipResample,
                    'MASK': countryLayer,
                    'SOURCE_CRS': None,
                    'TARGET_CRS': QgsCoordinateReferenceSystem(UTM_crs),
                    'NODATA': 0,
                    'ALPHA_BAND': False,
                    'CROP_TO_CUTLINE': False,
                    'KEEP_RESOLUTION': True,
                    'SET_RESOLUTION': False,
                    'X_RESOLUTION': None,
                    'Y_RESOLUTION': None,
                    'MULTITHREADING': False,
                    'OPTIONS': '',
                    'DATA_TYPE': 0,  # Use 0 for the same data type as the input
                    'EXTRA': '',
                    'OUTPUT': rasOutput
                })

                self.dlg.ENV_Aggregate_Field.setText(rasOutput)

                # Copy style file
                styleTemplate = os.path.join(current_script_path, "Style", f"{Dimension}.qml")
                styleFileDestination = os.path.join(dimension_dir, "ENV")
                if not os.path.exists(styleFileDestination):
                    os.mkdir(styleFileDestination)
                styleFile = f"{os.path.splitext(rasOutput)[0]}.qml"
                shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

                self.dlg.ENV_status.setText("Processing Complete!")
                self.dlg.ENV_status.repaint()

        except Exception as e:
            print(str(e))
            self.dlg.ENV_status.setText(f"Error: {str(e)}")
            self.dlg.ENV_status.repaint()

    # Define the reclassification function
    def reclassifyFireHazards(self, value):
        if value == 0:
            return 5
        elif 0 < value <= 1:
            return 4
        elif 1 < value <= 2:
            return 3
        elif 2 < value <= 5:
            return 2
        elif 5 < value <= 8:
            return 1
        elif value > 8:
            return 0
        else:
            return np.nan  # Handle NoData or unexpected values

    def reclassifyEarthQuakes(self, value):
        if 0.01 <= value < 0.02:
            return 5
        elif 0.02 < value <= 0.05:
            return 4
        elif 0.05 < value <= 0.013:
            return 3
        elif 0.013 < value <= 0.35:
            return 2
        elif 0.35 < value <= 0.90:
            return 1
        elif 0.90 < value <= 1.90:
            return 0
        else:
            return np.nan

    def reclassifyTsunami(self, value):
        if value == 0:
            return 5
        elif 0 < value <= 0.000001:
            return 4
        elif 0.000001 < value <= 0.00001:
            return 3
        elif 0.00001 < value <= 0.0001:
            return 2
        elif 0.0001 < value <= 0.001:
            return 1
        elif 0.001 < value <= 0.002:
            return 0
        else:
            return np.nan

    def reclassifyFloodHazard(self, value):
        if value == 0:
            return 5
        elif 0 < value <= 180:
            return 4
        elif 180 < value <= 360:
            return 3
        elif 360 < value <= 540:
            return 2
        elif 540 < value <= 720:
            return 1
        elif 720 < value <= 900:
            return 0
        else:
            return 5

    def reclassifyLandslide(self, value):
        if value == 0:
            return 5
        elif value == 1:
            return 4
        elif value == 2:
            return 3
        elif value == 3:
            return 2
        elif value == 4:
            return 1
        elif value == 5:
            return 0
        else:
            return 5

    def reclassifyTropicalCyclone(self, value):
        if value == 0:
            return 5
        elif 0 < value <= 25:
            return 4
        elif 25 < value <= 50:
            return 3
        elif 50 < value <= 75:
            return 2
        elif 75 < value <= 100:
            return 1
        elif value > 100:
            return 0
        else:
            return np.nan

    def reclassifyDrought(self, value, nodata):
        if value == 0:
            return 5
        elif 0 < value <= 1:
            return 4
        elif 1 < value <= 2:
            return 3
        elif 2 < value <= 3:
            return 2
        elif 3 < value <= 4:
            return 1
        elif 4 < value <= 5:
            return 0
        elif np.isnan(value) or value == nodata:
            return 5

    def reclassifyAirPollution(self, value):
        if 0 < value <= 10:
            return 5
        elif 10 < value <= 20:
            return 4
        elif 20 < value <= 30:
            return 3
        elif 30 < value <= 50:
            return 2
        elif 50 < value <= 80:
            return 1
        elif 80 < value <= 300:
            return 0
        else:
            return np.nan

    def env_aggregate(self):
        """
        This function is used in combination with the "natEnvironment" function. Due to there being numerous Natural Environment and Climatic factors that could
        influence place characterization the rasterization and standardization has to be conducted for each hazard. This function aggregates each of the hazards
        relating to Natural Environment and Climatic factors into a single standardized raster file.

        Factors it is applied:
            Accessibility Dimension
                - Natural Environment and Climatic factors
        """
        # OUTPUT
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        Dimension = "Place Characterization"
        ENV_Folder = f"{Dimension}/ENV"

        if os.path.exists(ENV_Folder):
            os.chdir(ENV_Folder)
        else:
            pass

        rasOutput = self.dlg.ENV_AGGOutput_Field.text()

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        self.dlg.ENVAGG_status.setText("Variables Set")
        self.dlg.ENVAGG_status.repaint()
        time.sleep(0.5)
        self.dlg.ENVAGG_status.setText("Processing...")
        self.dlg.ENVAGG_status.repaint()

        tif_list = [f for f in os.listdir(os.getcwd()) if f.endswith(".tif")]
        raster_list = []
        nodata_masks = []

        for ras in tif_list:
            with rasterio.open(ras) as src:
                raster_data = src.read(1)
                raster_list.append(raster_data)
                nodata_masks.append(raster_data == src.nodata)
                meta1 = src.meta

        len_raster_list = len(raster_list)
        cumulative_sum = np.zeros_like(raster_list[0], dtype=np.float32)
        valid_count = np.zeros_like(raster_list[0], dtype=np.float32)

        for i in range(len_raster_list):
            value = raster_list[i]
            mask = ~nodata_masks[i]  # Invert the nodata mask
            cumulative_sum += np.where(mask, value, 0)
            valid_count += mask.astype(np.float32)

        # Avoid division by zero
        aggregation = np.where(valid_count > 0, cumulative_sum / valid_count, -9999)

        os.chdir("..")

        meta1.update(dtype=rasterio.float32, nodata=-9999)

        with rasterio.open(rasOutput, "w", **meta1) as dst:
            dst.write(aggregation.astype(rasterio.float32), 1)

        self.dlg.ENV_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.ENVAGG_status.setText("Processing Complete!")
        self.dlg.ENVAGG_status.repaint()

    # *************************** Factor Aggregation Functions ************************************ #

    def contextual_aggregation(self):
        """
        This function performs a raster calculation aggregating all the contextual dimension factors according to their weightings
        """
        self.dlg.contextualAggregation_Check.setText("")
        self.dlg.contextualAggregation_Check.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)

        # INPUT
        WD_ras = self.dlg.WD_Aggregate_Field.text().strip(" ")
        RF_ras = self.dlg.RF_Aggregate_Field.text().strip(" ")
        FIN_ras = self.dlg.FIN_Aggregate_Field.text().strip(" ")

        WD_weight = self.dlg.WD_Aggregate_SB.value()
        RF_weight = self.dlg.RF_Aggregate_SB.value()
        FIN_weight = self.dlg.FIN_Aggregate_SB.value()

        # OUTPUT
        aggregation = self.dlg.Contextual_AggregateOutput_Field.text()

        rasLayers = [WD_ras, RF_ras, FIN_ras]
        factorWeighting = [WD_weight, RF_weight, FIN_weight]
        non_empty_count = sum(1 for item in rasLayers if item != "")

        weightingSum = round(sum(factorWeighting))

        if weightingSum == 100:
            if "" in rasLayers:
                missingLayers = [
                    index for index, item in enumerate(rasLayers) if item == ""
                ]
                presentLayers = [
                    index for index, item in enumerate(rasLayers) if item != ""
                ]

                for i in missingLayers:
                    rasLayers[i] = rasLayers[presentLayers[0]]
                    factorWeighting[i] = 0

            else:
                pass

            weightingSum = round(sum(factorWeighting))
            if weightingSum == 100:
                with rasterio.open(rasLayers[0]) as src:
                    WD_ras = src.read(1)
                    WD_weight = factorWeighting[0]
                    meta1 = src.meta
                    meta1.update(nodata=-9999)  # Set nodata to -9999

                with rasterio.open(rasLayers[1]) as src:
                    RF_ras = src.read(1)
                    RF_weight = factorWeighting[1]

                with rasterio.open(rasLayers[2]) as src:
                    FIN_ras = src.read(1)
                    FIN_weight = factorWeighting[2]

                # Raster Calculation
                result = (
                        (np.where(WD_ras != -9999, WD_ras, 0) * WD_weight / 100) +
                        (np.where(RF_ras != -9999, RF_ras, 0) * RF_weight / 100) +
                        (np.where(FIN_ras != -9999, FIN_ras, 0) * FIN_weight / 100)
                )
                result[np.logical_or(WD_ras == -9999, RF_ras == -9999, FIN_ras == -9999)] = -9999

                meta1.update(dtype=rasterio.float32, nodata=-9999)

                Dimension = "Contextual"
                if os.path.exists(Dimension):
                    os.chdir(Dimension)
                else:
                    os.mkdir(Dimension)
                    os.chdir(Dimension)

                with rasterio.open(aggregation, "w", **meta1) as dst:
                    dst.write(result.astype(rasterio.float32), 1)

                self.dlg.CD_Aggregate_Field.setText(
                    f"{workingDir}{Dimension}/{aggregation}"
                )

                loggerCD = logging.getLogger("loggerCD")
                loggerCD.setLevel(logging.INFO)
                handlerCD = logging.FileHandler("Contextual.log")
                formatterCD = logging.Formatter("%(asctime)s - %(message)s")
                handlerCD.setFormatter(formatterCD)
                loggerCD.addHandler(handlerCD)

                loggerCD.info(
                    f"Factors: {non_empty_count}/2 - {non_empty_count / 2 * 100} % - {non_empty_count}"
                )
                logging.shutdown()

                styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
                styleFileDestination = f"{workingDir}{Dimension}/"
                styleFile = f"{aggregation.split('.')[0]}.qml"

                shutil.copy(
                    styleTemplate, os.path.join(styleFileDestination, styleFile)
                )

                time.sleep(1)

                layer = QgsRasterLayer(aggregation, f"{aggregation}")

                if not layer.isValid():
                    print("Layer failed to load!")

                QgsProject.instance().addMapLayer(layer)

                self.dlg.contextualAggregation_Check.setText(
                    "Contextual dimension aggregation complete!"
                )
            else:
                self.dlg.contextualAggregation_Check.setText(
                    "Weighting % does not add up to 100 %"
                )

        else:
            self.dlg.contextualAggregation_Check.setText(
                "Weighting % does not add up to 100 %"
            )

        os.chdir(workingDir)

    def accessibilty_aggregation(self):
        """
        This function performs a raster calculation aggregating all the accessibilty dimension factors according to their weightings
        """
        self.dlg.accessibilityAggregation_Check.setText("")
        self.dlg.accessibilityAggregation_Check.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)

        # INPUT
        WTP_ras = self.dlg.WTP_Aggregate_Field.text().strip(" ")
        PBT_ras = self.dlg.PBT_Aggregate_Field.text().strip(" ")
        ETF_ras = self.dlg.ETF_Aggregate_Field.text().strip(" ")
        HEA_ras = self.dlg.HEA_Aggregate_Field.text().strip(" ")
        FIF_ras = self.dlg.FIF_Aggregate_Field.text().strip(" ")

        WTP_weight = self.dlg.WTP_Aggregate_SB.value()
        PBT_weight = self.dlg.PBT_Aggregate_SB.value()
        ETF_weight = self.dlg.ETF_Aggregate_SB.value()
        HEA_weight = self.dlg.HEA_Aggregate_SB.value()
        FIF_weight = self.dlg.FIF_Aggregate_SB.value()

        # OUTPUT
        aggregation = self.dlg.Accessibility_AggregateOutput_Field.text()

        rasLayers = [WTP_ras, PBT_ras, ETF_ras, HEA_ras, FIF_ras]
        factorWeighting = [
            WTP_weight,
            PBT_weight,
            ETF_weight,
            HEA_weight,
            FIF_weight,
        ]
        non_empty_count = sum(1 for item in rasLayers if item != "")

        weightingSum = round(sum(factorWeighting))

        if weightingSum == 100:
            if "" in rasLayers:
                missingLayers = [
                    index for index, item in enumerate(rasLayers) if item == ""
                ]
                presentLayers = [
                    index for index, item in enumerate(rasLayers) if item != ""
                ]

                for i in missingLayers:
                    rasLayers[i] = rasLayers[presentLayers[0]]
                    factorWeighting[i] = 0

            else:
                pass

            weightingSum = round(sum(factorWeighting))
            if weightingSum == 100:
                with rasterio.open(rasLayers[0]) as src:
                    WTP_ras = src.read(1)
                    WTP_weight = factorWeighting[0]
                    meta1 = src.meta
                    meta1.update(nodata=-9999)  # Set nodata to -9999

                with rasterio.open(rasLayers[1]) as src:
                    PBT_ras = src.read(1)
                    PBT_weight = factorWeighting[1]

                with rasterio.open(rasLayers[2]) as src:
                    ETF_ras = src.read(1)
                    ETF_weight = factorWeighting[2]

                with rasterio.open(rasLayers[3]) as src:
                    HEA_ras = src.read(1)
                    HEA_weight = factorWeighting[3]

                with rasterio.open(rasLayers[4]) as src:
                    FIF_ras = src.read(1)
                    FIF_weight = factorWeighting[4]

                # Raster Calculation
                result = (
                        (np.where(WTP_ras != -9999, WTP_ras, 0) * WTP_weight / 100) +
                        (np.where(PBT_ras != -9999, PBT_ras, 0) * PBT_weight / 100) +
                        (np.where(ETF_ras != -9999, ETF_ras, 0) * ETF_weight / 100) +
                        (np.where(HEA_ras != -9999, HEA_ras, 0) * HEA_weight / 100) +
                        (np.where(FIF_ras != -9999, FIF_ras, 0) * FIF_weight / 100)
                )
                result[np.logical_or(WTP_ras == -9999, PBT_ras == -9999, ETF_ras == -9999, HEA_ras == -9999,
                                     FIF_ras == -9999)] = -9999

                meta1.update(dtype=rasterio.float32, nodata=-9999)

                Dimension = "Accessibility"
                if os.path.exists(Dimension):
                    os.chdir(Dimension)
                else:
                    os.mkdir(Dimension)
                    os.chdir(Dimension)

                with rasterio.open(aggregation, "w", **meta1) as dst:
                    dst.write(result.astype(rasterio.float32), 1)

                self.dlg.AD_Aggregate_Field.setText(
                    f"{workingDir}{Dimension}/{aggregation}"
                )

                loggerAD = logging.getLogger("loggerAD")
                loggerAD.setLevel(logging.INFO)
                handlerAD = logging.FileHandler("Accessibility.log")
                formatterAD = logging.Formatter("%(asctime)s - %(message)s")
                handlerAD.setFormatter(formatterAD)
                loggerAD.addHandler(handlerAD)

                loggerAD.info(
                    f"Factors: {non_empty_count}/6 - {non_empty_count / 6 * 100} % - {non_empty_count}"
                )
                logging.shutdown()

                styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
                styleFileDestination = f"{workingDir}{Dimension}/"
                styleFile = f"{aggregation.split('.')[0]}.qml"

                shutil.copy(
                    styleTemplate, os.path.join(styleFileDestination, styleFile)
                )

                layer = QgsRasterLayer(aggregation, f"{aggregation}")

                if not layer.isValid():
                    print("Layer failed to load!")

                QgsProject.instance().addMapLayer(layer)

                self.dlg.accessibilityAggregation_Check.setText(
                    "Accessibility dimension aggregation complete!"
                )
            else:
                self.dlg.accessibilityAggregation_Check.setText(
                    "Weighting % does not add up to 100 %"
                )
        else:
            self.dlg.accessibilityAggregation_Check.setText(
                "Weighting % does not add up to 100 %"
            )

        os.chdir(workingDir)

    def place_characterization_aggregation(self):
        """
        This function performs a raster calculation aggregating all the place characterization dimension factors according to their weightings
        """
        self.dlg.placeCharacterizationAggregation_Check.setText("")
        self.dlg.placeCharacterizationAggregation_Check.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)

        # INPUT
        WLK_ras = self.dlg.AT_Aggregate_Field.text().strip(" ")
        SAF_ras = self.dlg.SAF_Aggregate_Field.text().strip(" ")
        DIG_ras = self.dlg.DIG_Aggregate_Field.text().strip(" ")
        ENV_ras = self.dlg.ENV_Aggregate_Field.text().strip(" ")
        EDU_ras = self.dlg.EDU_Aggregate_Field.text().strip(" ")
        FCV_ras = self.dlg.FCV_Aggregate_Field.text().strip(" ")
        WAS_ras = self.dlg.WAS_Aggregate_Field.text().strip(" ")

        WLK_weight = self.dlg.WLK_Aggregate_SB.value()
        SAF_weight = self.dlg.SAF_Aggregate_SB.value()
        DIG_weight = self.dlg.DIG_Aggregate_SB.value()
        ENV_weight = self.dlg.ENV_Aggregate_SB.value()
        EDU_weight = self.dlg.EDU_Aggregate_SB.value()
        FCV_weight = self.dlg.FCV_Aggregate_SB.value()
        WAS_weight = self.dlg.WAS_Aggregate_SB.value()

        # OUTPUT
        aggregation = self.dlg.PlaceCharacterization_AggregateOutput_Field.text()

        rasLayers = [
            WLK_ras,
            SAF_ras,
            DIG_ras,
            ENV_ras,
            EDU_ras,
            FCV_ras,
            WAS_ras,
        ]
        factorWeighting = [
            WLK_weight,
            SAF_weight,
            DIG_weight,
            ENV_weight,
            EDU_weight,
            FCV_weight,
            WAS_weight,
        ]
        non_empty_count = sum(1 for item in rasLayers if item != "")

        weightingSum = round(sum(factorWeighting))

        if weightingSum == 100:
            if "" in rasLayers:
                missingLayers = [
                    index for index, item in enumerate(rasLayers) if item == ""
                ]
                presentLayers = [
                    index for index, item in enumerate(rasLayers) if item != ""
                ]

                for i in missingLayers:
                    rasLayers[i] = rasLayers[presentLayers[0]]
                    factorWeighting[i] = 0

            else:
                pass

            weightingSum = round(sum(factorWeighting))
            if weightingSum == 100:
                with rasterio.open(rasLayers[0]) as src:
                    WLK_ras = src.read(1)
                    WLK_weight = factorWeighting[0]
                    meta1 = src.meta
                    meta1.update(nodata=-9999)  # Set nodata to -9999

                with rasterio.open(rasLayers[1]) as src:
                    SAF_ras = src.read(1)
                    SAF_weight = factorWeighting[1]

                with rasterio.open(rasLayers[2]) as src:
                    DIG_ras = src.read(1)
                    DIG_weight = factorWeighting[2]

                with rasterio.open(rasLayers[3]) as src:
                    ENV_ras = src.read(1)
                    ENV_weight = factorWeighting[3]

                with rasterio.open(rasLayers[4]) as src:
                    EDU_ras = src.read(1)
                    EDU_weight = factorWeighting[4]

                with rasterio.open(rasLayers[5]) as src:
                    FCV_ras = src.read(1)
                    FCV_weight = factorWeighting[5]

                with rasterio.open(rasLayers[6]) as src:
                    WAS_ras = src.read(1)
                    WAS_weight = factorWeighting[6]

                # Raster Calculation
                result = (
                        (np.where(WLK_ras != -9999, WLK_ras, 0) * WLK_weight / 100) +
                        (np.where(SAF_ras != -9999, SAF_ras, 0) * SAF_weight / 100) +
                        (np.where(DIG_ras != -9999, DIG_ras, 0) * DIG_weight / 100) +
                        (np.where(ENV_ras != -9999, ENV_ras, 0) * ENV_weight / 100) +
                        (np.where(EDU_ras != -9999, EDU_ras, 0) * EDU_weight / 100) +
                        (np.where(FCV_ras != -9999, FCV_ras, 0) * FCV_weight / 100) +
                        (np.where(WAS_ras != -9999, WAS_ras, 0) * WAS_weight / 100)
                )
                result[np.logical_or(WLK_ras == -9999, SAF_ras == -9999, DIG_ras == -9999, ENV_ras == -9999,
                                     EDU_ras == -9999, FCV_ras == -9999, WAS_ras == -9999)] = -9999

                meta1.update(dtype=rasterio.float32, nodata=-9999)

                Dimension = "Place Characterization"
                if os.path.exists(Dimension):
                    os.chdir(Dimension)
                else:
                    os.mkdir(Dimension)
                    os.chdir(Dimension)

                with rasterio.open(aggregation, "w", **meta1) as dst:
                    dst.write(result.astype(rasterio.float32), 1)

                self.dlg.PD_Aggregate_Field.setText(
                    f"{workingDir}{Dimension}/{aggregation}"
                )

                loggerPD = logging.getLogger("loggerPD")
                loggerPD.setLevel(logging.INFO)
                handlerPD = logging.FileHandler("Place Characterization.log")
                formatterPD = logging.Formatter("%(asctime)s - %(message)s")
                handlerPD.setFormatter(formatterPD)
                loggerPD.addHandler(handlerPD)

                loggerPD.info(
                    f"Factors: {non_empty_count}/10 - {non_empty_count / 10 * 100} % - {non_empty_count}"
                )
                logging.shutdown()

                styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
                styleFileDestination = f"{workingDir}{Dimension}/"
                styleFile = f"{aggregation.split('.')[0]}.qml"

                shutil.copy(
                    styleTemplate, os.path.join(styleFileDestination, styleFile)
                )

                layer = QgsRasterLayer(aggregation, f"{aggregation}")

                if not layer.isValid():
                    print("Layer failed to load!")

                QgsProject.instance().addMapLayer(layer)

                self.dlg.placeCharacterizationAggregation_Check.setText(
                    "Place Characterization dimension aggregation complete!"
                )
            else:
                self.dlg.placeCharacterizationAggregation_Check.setText(
                    "Weighting % does not add up to 100 %"
                )
        else:
            self.dlg.placeCharacterizationAggregation_Check.setText(
                "Weighting % does not add up to 100 %"
            )

        os.chdir(workingDir)

    def dimensions_aggregation(self):
        """
        This function performs a final raster calculation aggregating all the dimension aggregation output raster according to their weightings
        """
        self.dlg.dimensionAggregation_Check.setText("")
        self.dlg.dimensionAggregation_Check.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)

        # INPUT
        CD_ras = self.dlg.CD_Aggregate_Field.text().strip(" ")
        AD_ras = self.dlg.AD_Aggregate_Field.text().strip(" ")
        PD_ras = self.dlg.PD_Aggregate_Field.text().strip(" ")

        CD_weight = self.dlg.CD_Aggregate_SB.value()
        AD_weight = self.dlg.AD_Aggregate_SB.value()
        PD_weight = self.dlg.PD_Aggregate_SB.value()

        # OUTPUT
        aggregation = self.dlg.Dimensions_AggregateOutput_Field.text()

        rasLayers = [CD_ras, AD_ras, PD_ras]
        dimensionWeighting = [CD_weight, AD_weight, PD_weight]

        weightingSum = round(sum(dimensionWeighting))

        if weightingSum == 100:
            if "" in rasLayers:
                missingLayers = [
                    index for index, item in enumerate(rasLayers) if item == ""
                ]
                presentLayers = [
                    index for index, item in enumerate(rasLayers) if item != ""
                ]

                for i in missingLayers:
                    rasLayers[i] = rasLayers[presentLayers[0]]
                    dimensionWeighting[i] = 0

            else:
                pass

            weightingSum = round(sum(dimensionWeighting))
            if weightingSum == 100:
                with rasterio.open(rasLayers[0]) as src:
                    CD_ras = src.read(1)
                    CD_weight = dimensionWeighting[0]
                    meta1 = src.meta
                    meta1.update(nodata=-9999)  # Set nodata to -9999

                with rasterio.open(rasLayers[1]) as src:
                    AD_ras = src.read(1)
                    AD_weight = dimensionWeighting[1]

                with rasterio.open(rasLayers[2]) as src:
                    PD_ras = src.read(1)
                    PD_weight = dimensionWeighting[2]

                # Raster Calculation
                result = (
                        (np.where(CD_ras != -9999, CD_ras, 0) * CD_weight / 100) +
                        (np.where(AD_ras != -9999, AD_ras, 0) * AD_weight / 100) +
                        (np.where(PD_ras != -9999, PD_ras, 0) * PD_weight / 100)
                )
                result[np.logical_or(CD_ras == -9999, AD_ras == -9999, PD_ras == -9999)] = -9999

                meta1.update(dtype=rasterio.float32, nodata=-9999)

                Final_output = "Final_output"
                if os.path.exists(Final_output):
                    os.chdir(Final_output)
                else:
                    os.mkdir(Final_output)
                    os.chdir(Final_output)

                with rasterio.open(aggregation, "w", **meta1) as dst:
                    dst.write(result.astype(rasterio.float32), 1)

                styleTemplate = f"{current_script_path}/Style/Final.qml"
                styleFileDestination = f"{workingDir}{Final_output}/"
                styleFile = f"{aggregation.split('.')[0]}.qml"

                shutil.copy(
                    styleTemplate, os.path.join(styleFileDestination, styleFile)
                )

                log_list = [
                    "Contextual",
                    "Accessibility",
                    "Place Characterization",
                ]
                factor_num = []

                for dimension in log_list:
                    log_file = f"{workingDir}{dimension}/{dimension}.log"
                    if os.path.exists(log_file):
                        with open(log_file, "r") as file:
                            lines = file.readlines()

                            if lines:
                                last_line = lines[-1].split("-")[-1].strip()
                            else:
                                pass

                            factor_num.append(last_line)
                    else:
                        pass

                integer_list = [int(item) for item in factor_num]
                sum_list = sum(integer_list)
                Confidence = round(sum_list / 15 * 100, 2)

                layer = QgsRasterLayer(aggregation, f"{aggregation}")

                if not layer.isValid():
                    print("Layer failed to load!")

                QgsProject.instance().addMapLayer(layer)

                self.dlg.FinalAggregation_Check.setText(
                    f"Dimensional aggregation complete! - Confidence: {sum_list}/15 factors used. ({Confidence} %)"
                )
            else:
                self.dlg.dimensionAggregation_Check.setText(
                    "Weighting % does not add up to 100 %"
                )

        else:
            self.dlg.dimensionAggregation_Check.setText(
                "Weighting % does not add up to 100 %"
            )

        os.chdir(workingDir)

    # *************************** Insights Tab Functions *********************************** #
    def scoreReclassInsights(self):
        """
        This function takes the final aggregate score, a dimension aggregate score, or even a single factor output raster and classifies it into five discrete classes of enablement.
        """
        self.dlg.Enablement_status.setText("")
        self.dlg.Enablement_status.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()

        os.chdir(workingDir)
        Insights_folder = "Insights"
        if os.path.exists(Insights_folder):
            pass
        else:
            os.mkdir(Insights_folder)

        tempDir = f"temp"
        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        # INPUT
        score = self.dlg.Insights_Score_Input_Field.filePath()
        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()

        # Temp OUTPUT
        countryUTMLayer = f"{tempDir}/countryUTMLayer.shp"
        countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"
        ScoretempResample = f"{tempDir}/ScoretempResample.tif"

        self.dlg.Enablement_status.setText("Variables Set")
        self.dlg.Enablement_status.repaint()

        self.dlg.Enablement_status.setText("Processing...")
        self.dlg.Enablement_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        shp_utm.to_file(countryUTMLayer)

        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": countryUTMLayerBuf,
            },
        )

        CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
        country_extent = CountryBuf_df.total_bounds

        processing.run(
            "gdal:warpreproject",
            {
                "INPUT": score,
                "SOURCE_CRS": None,
                "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "RESAMPLING": 0,
                "NODATA": -9999,
                "TARGET_RESOLUTION": pixelSize,
                "OPTIONS": "",
                "DATA_TYPE": 0,
                "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "MULTITHREADING": False,
                "EXTRA": "",
                "OUTPUT": ScoretempResample,
            },
        )

        Insights_enablement = "1) Level of Enablement Classification"
        if os.path.exists(f"{Insights_folder}/{Insights_enablement}"):
            pass
        else:
            os.mkdir(f"{Insights_folder}/{Insights_enablement}")

        # Score Reclassify
        with rasterio.open(ScoretempResample) as src:
            score_ras = src.read(1)
            meta1 = src.meta

        # Raster Calculation

        result = (
                0 * (score_ras <= 0.5)
                + 1 * (score_ras > 0.5) * (score_ras <= 1.5)
                + 2 * (score_ras > 1.5) * (score_ras <= 2.5)
                + 3 * (score_ras > 2.5) * (score_ras <= 3.5)
                + 4 * (score_ras > 3.5) * (score_ras <= 4.5)
                + 5 * (score_ras > 4.5)
        )

        meta1.update(dtype=rasterio.float32)

        score_rec = f"{workingDir}{Insights_folder}/{Insights_enablement}/Level_of_Enablement.tif"
        with rasterio.open(score_rec, "w", **meta1) as dst:
            dst.write(result, 1)

        styleTemplate = f"{current_script_path}/Style/Insights Score.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_enablement}"
        styleFile = f"{score_rec.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.Insights_ScoreReclass_Input_Field.setFilePath(f"{score_rec}")

        self.dlg.Enablement_status.setText("Classification Complete!")
        self.dlg.Enablement_status.repaint()

    def populationReclassInsights(self):
        """
        This function takes a population count raster as input and classifies it into 3 discrete classes based on
        the lower quartile range, interquartile range, and upper quartile range of data to identify
        areas of relatively low, medium, and high population per region.
        """
        self.dlg.Population_status.setText("")
        self.dlg.Population_status.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()

        os.chdir(workingDir)
        Insights_folder = "Insights"
        if os.path.exists(Insights_folder):
            pass
        else:
            os.mkdir(Insights_folder)

        tempDir = f"temp"
        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        # INPUT
        population = self.dlg.Insights_Population_Input_Field.filePath()
        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()

        # Temp OUTPUT
        countryUTMLayer = f"{tempDir}/countryUTMLayer.shp"
        countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"
        PoptempResample = f"{tempDir}/PoptempResample.tif"

        self.dlg.Population_status.setText("Variables Set")
        self.dlg.Population_status.repaint()

        self.dlg.Population_status.setText("Processing...")
        self.dlg.Population_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        shp_utm.to_file(countryUTMLayer)

        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": countryUTMLayerBuf,
            },
        )

        CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
        country_extent = CountryBuf_df.total_bounds

        processing.run(
            "gdal:warpreproject",
            {
                "INPUT": population,
                "SOURCE_CRS": None,
                "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "RESAMPLING": 0,
                "NODATA": -9999,
                "TARGET_RESOLUTION": pixelSize,
                "OPTIONS": "",
                "DATA_TYPE": 0,
                "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "MULTITHREADING": False,
                "EXTRA": "",
                "OUTPUT": PoptempResample,
            },
        )

        Insights_population = "2) Relative Population Count Classification"
        if os.path.exists(f"{Insights_folder}/{Insights_population}"):
            pass
        else:
            os.mkdir(f"{Insights_folder}/{Insights_population}")

        # Population Reclassify
        with rasterio.open(PoptempResample) as src:
            pop_ras = src.read(1)
            meta1 = src.meta

            pop_ras[pop_ras == src.nodata] = -1
            masked_raster = np.ma.masked_where(pop_ras == -1, pop_ras)

            # out_image, out_transform = np.ma.mask(masked_raster, countryUTMLayer, invert=True)

        percentile_25 = np.percentile(masked_raster.compressed(), 25)
        percentile_75 = np.percentile(masked_raster.compressed(), 75)

        # # Raster Calculation
        #
        result = (
                0 * (pop_ras == -1)
                + 1 * (pop_ras > -1) * (pop_ras <= percentile_25)
                + 2 * (pop_ras > percentile_25) * (pop_ras <= percentile_75)
                + 3 * (pop_ras > percentile_75)
        )

        # result = pop_ras

        meta1.update(dtype=rasterio.float32)

        pop_rec = f"{workingDir}{Insights_folder}/{Insights_population}/Relative_Population_Count.tif"
        with rasterio.open(pop_rec, "w", **meta1) as dst:
            dst.write(result, 1)

        styleTemplate = f"{current_script_path}/Style/Insights Population.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_population}/"
        styleFile = f"{pop_rec.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.Insights_PopulationReclass_Input_Field.setFilePath(f"{pop_rec}")

        self.dlg.Population_status.setText("Classification Complete!")
        self.dlg.Population_status.repaint()

    def combineReclassInsights(self):
        """
        Through the use of raster calculation this function combines the discrete level of enablement raster produced by the "scoreReclassInsights"
        function and the relative population count raster produced by the "populationReclassInsights" function. A single raster layer is produced
        contains 15 classes.
        """
        self.dlg.Combine_status.setText("")
        self.dlg.Combine_status.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()

        os.chdir(workingDir)
        Insights_folder = "Insights"
        if os.path.exists(Insights_folder):
            pass
        else:
            os.mkdir(Insights_folder)

        tempDir = f"temp"
        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        # INPUT
        score_rec = self.dlg.Insights_ScoreReclass_Input_Field.filePath()
        pop_rec = self.dlg.Insights_PopulationReclass_Input_Field.filePath()

        Insights_combine = (
            "3) Combined Level of Enablement & Relative Population Count Classification"
        )
        if os.path.exists(f"{Insights_folder}/{Insights_combine}"):
            pass
        else:
            os.mkdir(f"{Insights_folder}/{Insights_combine}")

        self.dlg.Combine_status.setText("Variables Set")
        self.dlg.Combine_status.repaint()

        self.dlg.Combine_status.setText("Processing...")
        self.dlg.Combine_status.repaint()

        # Combine Population and Score Reclassify
        with rasterio.open(score_rec) as src:
            score_rec_ras = src.read(1)
            meta1 = src.meta

        with rasterio.open(pop_rec) as src:
            pop_rec_ras = src.read(1)

        # Raster Calculation

        result = (
                1 * (score_rec_ras == 1) * (pop_rec_ras == 1)
                + 2 * (score_rec_ras == 1) * (pop_rec_ras == 2)
                + 3 * (score_rec_ras == 1) * (pop_rec_ras == 3)
                + 4 * (score_rec_ras == 2) * (pop_rec_ras == 1)
                + 5 * (score_rec_ras == 2) * (pop_rec_ras == 2)
                + 6 * (score_rec_ras == 2) * (pop_rec_ras == 3)
                + 7 * (score_rec_ras == 3) * (pop_rec_ras == 1)
                + 8 * (score_rec_ras == 3) * (pop_rec_ras == 2)
                + 9 * (score_rec_ras == 3) * (pop_rec_ras == 3)
                + 10 * (score_rec_ras == 4) * (pop_rec_ras == 1)
                + 11 * (score_rec_ras == 4) * (pop_rec_ras == 2)
                + 12 * (score_rec_ras == 4) * (pop_rec_ras == 3)
                + 13 * (score_rec_ras == 5) * (pop_rec_ras == 1)
                + 14 * (score_rec_ras == 5) * (pop_rec_ras == 2)
                + 15 * (score_rec_ras == 5) * (pop_rec_ras == 3)
        )

        meta1.update(dtype=rasterio.float32)

        combined_rec = f"{workingDir}{Insights_folder}/{Insights_combine}/Enablement_&_Population_Combined_classification.tif"
        with rasterio.open(combined_rec, "w", **meta1) as dst:
            dst.write(result, 1)

        styleTemplate = f"{current_script_path}/Style/Insights Combined.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_combine}/"
        styleFile = f"{combined_rec.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.Insights_Reclass_Input_Field.setFilePath(f"{combined_rec}")
        self.dlg.Insights_Agg_Input_Field.setFilePath(f"{combined_rec}")
        self.dlg.Insights_Buf_Input_Field.setFilePath(f"{combined_rec}")

        layer0 = QgsRasterLayer(
            combined_rec, f"Enablement_&_Population_Combined_classification"
        )
        QgsProject.instance().addMapLayer(layer0)

        self.dlg.Combine_status.setText("Classification Complete!")
        self.dlg.Combine_status.repaint()

    def Aggregationinsights(self):
        """
        this function takes the combine raster output produced by the "combineReclassInsights" function and aggregates, by extracting
        the to the majority class to a polygon layer representing boundaries of interest for aggregation (e.g. municipal boundary layer).
        """
        self.dlg.Aggregate_status.setText("")
        self.dlg.Aggregate_status.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()

        os.chdir(workingDir)
        Insights_folder = "Insights"
        if os.path.exists(Insights_folder):
            pass
        else:
            os.mkdir(Insights_folder)

        tempDir = f"temp"
        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        # INPUT
        insights_raster = self.dlg.Insights_Agg_Input_Field.filePath()
        aggregation_polygon = self.dlg.Insights_Polygon_Input_Field.filePath()

        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]

        # TEMP OUTPUT
        aggregation_polygon_utm = f"{tempDir}/aggregation_polygon_utm.shp"

        self.dlg.Aggregate_status.setText("Variables Set")
        self.dlg.Aggregate_status.repaint()

        self.dlg.Aggregate_status.setText("Processing...")
        self.dlg.Aggregate_status.repaint()

        self.convertCRS(aggregation_polygon, UTM_crs)
        shp_utm.to_file(aggregation_polygon_utm)

        Insights_aggregation = "4) Aggregation"
        if os.path.exists(f"{Insights_folder}/{Insights_aggregation}"):
            pass
        else:
            os.mkdir(f"{Insights_folder}/{Insights_aggregation}")

        shpOutput = (
                f"{workingDir}{Insights_folder}/{Insights_aggregation}/"
                + self.dlg.AGG_Output_Field.text()
                + ".shp"
        )

        processing.run(
            "native:zonalstatisticsfb",
            {
                "INPUT": QgsProcessingFeatureSourceDefinition(
                    aggregation_polygon_utm,
                    selectedFeaturesOnly=False,
                    featureLimit=-1,
                    flags=QgsProcessingFeatureSourceDefinition.FlagOverrideDefaultGeometryCheck,
                    geometryCheck=QgsFeatureRequest.GeometrySkipInvalid,
                ),
                "INPUT_RASTER": insights_raster,
                "RASTER_BAND": 1,
                "COLUMN_PREFIX": "_",
                "STATISTICS": [9],
                "OUTPUT": shpOutput,
            },
        )

        styleTemplate = f"{current_script_path}/Style/Insights Aggregation.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_aggregation}/"
        styleFile = f"{self.dlg.AGG_Output_Field.text()}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.Insights_AGGReclass_Input_Field.setFilePath(f"{shpOutput}")
        self.dlg.Insights_AGGReclass_Input_Field_2.setFilePath(f"{shpOutput}")

        self.dlg.Aggregate_status.setText("Aggregation Complete!")
        self.dlg.Aggregate_status.repaint()

    def reZones(self):
        self.dlg.REzone_status.setText("")
        self.dlg.REzone_status.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()

        os.chdir(workingDir)
        Insights_folder = "Insights"
        if os.path.exists(Insights_folder):
            pass
        else:
            os.mkdir(Insights_folder)

        tempDir = f"temp"
        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        # INPUT
        reclassified_layer = self.dlg.Insights_Reclass_Input_Field.filePath()
        re_zones = self.dlg.Insights_RE_Input_Field.filePath()
        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]
        countryLayer = self.dlg.countryLayer_Field.filePath()
        pixelSize = self.dlg.pixelSize_SB.value()
        aggregate = self.dlg.Insights_AGGReclass_Input_Field.filePath()

        # Temp OUTPUT
        REtempResample = f"{tempDir}/REtempResample.tif"
        countryUTMLayerBuf = f"{tempDir}/countryUTMLayerBuf.shp"
        poly_temp = f"{tempDir}/poly_temp.shp"
        temp_dis = f"{tempDir}/temp_dis.shp"
        final_temp_dis = f"{tempDir}/final_temp_dis.shp"

        self.dlg.REzone_status.setText("Variables Set")
        self.dlg.REzone_status.repaint()

        self.dlg.REzone_status.setText("Processing...")
        self.dlg.REzone_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        countryUTMLayer = QgsVectorLayer(shp_utm.to_json(), "countryUTMLayer", "ogr")

        buffer = processing.run(
            "native:buffer",
            {
                "INPUT": countryUTMLayer,
                "DISTANCE": self.BUFFER_DISTANCE,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": True,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": countryUTMLayerBuf,
            },
        )

        CountryBuf_df = gpd.read_file(countryUTMLayerBuf)
        country_extent = CountryBuf_df.total_bounds

        processing.run(
            "gdal:warpreproject",
            {
                "INPUT": re_zones,
                "SOURCE_CRS": None,
                "TARGET_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "RESAMPLING": 0,
                "NODATA": -9999,
                "TARGET_RESOLUTION": pixelSize,
                "OPTIONS": "",
                "DATA_TYPE": 0,
                "TARGET_EXTENT": f"{country_extent[0]},{country_extent[2]},{country_extent[1]},{country_extent[3]} [{UTM_crs}]",
                "TARGET_EXTENT_CRS": QgsCoordinateReferenceSystem(UTM_crs),
                "MULTITHREADING": False,
                "EXTRA": "",
                "OUTPUT": REtempResample,
            },
        )

        Insights_re_raster = "5) RE Zone Raster Locations"
        if os.path.exists(f"{Insights_folder}/{Insights_re_raster}"):
            pass
        else:
            os.mkdir(f"{Insights_folder}/{Insights_re_raster}")

        # Reclassified rasters join to RE zones
        with rasterio.open(reclassified_layer) as src:
            reclassified_layer_ras = src.read(1)
            meta1 = src.meta

        with rasterio.open(REtempResample) as src:
            re_zones = src.read(1)
            re_zones[np.isinf(re_zones)] = src.nodata
            re_zones[re_zones != src.nodata] = 1

        # Raster Calculation
        result = reclassified_layer_ras * re_zones

        meta1.update(dtype=rasterio.float32)

        combined_RE = (
                f"{workingDir}{Insights_folder}/{Insights_re_raster}/"
                + self.dlg.RE_Output_Field.text()
                + "Enablement_&_Population_Combined.tif"
        )
        with rasterio.open(combined_RE, "w", **meta1) as dst:
            dst.write(result, 1)

        styleTemplate = f"{current_script_path}/Style/Insights Combined.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_re_raster}/"
        styleFile = f"{combined_RE.split('.')[0]}.qml"
        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        # Vectorize raster
        Polygon = processing.run(
            "gdal:polygonize",
            {
                "INPUT": combined_RE,
                "BAND": 1,
                "FIELD": "DN",
                "EIGHT_CONNECTEDNESS": False,
                "EXTRA": "",
                "OUTPUT": poly_temp,
            },
        )

        Dissolve = processing.run(
            "native:dissolve",
            {
                "INPUT": poly_temp,
                "FIELD": ["DN"],
                "SEPARATE_DISJOINT": False,
                "OUTPUT": temp_dis,
            },
        )

        gdf = gpd.read_file(temp_dis)
        gdf = gdf[(gdf["DN"] > 0) & (gdf["DN"] < 15)]
        gdf.to_file(final_temp_dis)

        # Load the main polygon layer
        main_layer = gpd.read_file(aggregate)

        # Load the layer you want to check for intersection
        intersect_layer = gpd.read_file(final_temp_dis)

        # Perform a spatial join
        intersecting_records = gpd.sjoin(
            main_layer, intersect_layer, how="inner", op="intersects"
        )

        # Extract the intersecting polygons
        intersecting_polygons = main_layer.loc[intersecting_records.index]

        # Save to a new shapefile
        admin_RE = (
                f"{workingDir}{Insights_folder}/{Insights_re_raster}/"
                + self.dlg.RE_Output_Field.text()
                + "admin_units_intersection.shp"
        )
        intersecting_polygons.to_file(admin_RE)

        styleTemplate = f"{current_script_path}/Style/Insights Aggregation.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_re_raster}/"
        styleFile = f"{admin_RE.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        layer4 = QgsVectorLayer(
            admin_RE, f"{self.dlg.RE_Output_Field.text()}admin_unit_intersection"
        )
        QgsProject.instance().addMapLayer(layer4)

        layer3 = QgsRasterLayer(
            combined_RE,
            f"{self.dlg.RE_Output_Field.text()}Enablement_&_Population_Combined",
        )
        QgsProject.instance().addMapLayer(layer3)

        self.dlg.REzone_status.setText("RE Zones extraction complete!")
        self.dlg.REzone_status.repaint()

    def Bufferinsights(self):
        self.dlg.REpoint_status.setText("")
        self.dlg.REpoint_status.repaint()
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()

        os.chdir(workingDir)
        Insights_folder = "Insights"
        if os.path.exists(Insights_folder):
            pass
        else:
            os.mkdir(Insights_folder)

        tempDir = f"temp"
        if os.path.exists(tempDir):
            shutil.rmtree(tempDir)
        else:
            pass

        time.sleep(0.5)
        os.mkdir(tempDir)

        # INPUT
        insights_raster = self.dlg.Insights_Buf_Input_Field.filePath()
        location_point = self.dlg.Insights_Points_Input_Field.filePath()
        countryLayer = self.dlg.countryLayer_Field.filePath()
        aggregate = self.dlg.Insights_AGGReclass_Input_Field_2.filePath()
        bufferDistance = self.dlg.bufferDistance_SB.value()

        UTM_crs = str(self.dlg.mQgsProjectionSelectionWidget.crs()).split(" ")[-1][:-1]

        # TEMP OUTPUT
        adminUTMLayer = f"{tempDir}/adminUTMLayer.shp"
        location_point_utm = f"{tempDir}/aggregation_polygon_utm.shp"
        location_buffer = f"{tempDir}/location_buffer.shp"
        location_buffer_clip = f"{tempDir}/location_buffer_clip.shp"

        self.dlg.REpoint_status.setText("Variables Set")
        self.dlg.REpoint_status.repaint()

        self.dlg.REpoint_status.setText("Processing...")
        self.dlg.REpoint_status.repaint()

        self.convertCRS(countryLayer, UTM_crs)
        shp_utm.to_file(adminUTMLayer)

        self.convertCRS(location_point, UTM_crs)
        location_point_utm = QgsVectorLayer(
            shp_utm.to_json(), "location_point_utm", "ogr"
        )

        processing.run(
            "native:buffer",
            {
                "INPUT": location_point_utm,
                "DISTANCE": bufferDistance,
                "SEGMENTS": 5,
                "END_CAP_STYLE": 0,
                "JOIN_STYLE": 0,
                "MITER_LIMIT": 2,
                "DISSOLVE": False,
                "SEPARATE_DISJOINT": False,
                "OUTPUT": location_buffer,
            },
        )

        processing.run(
            "native:clip",
            {
                "INPUT": location_buffer,
                "OVERLAY": QgsProcessingFeatureSourceDefinition(
                    adminUTMLayer,
                    selectedFeaturesOnly=False,
                    featureLimit=-1,
                    flags=QgsProcessingFeatureSourceDefinition.FlagOverrideDefaultGeometryCheck,
                    geometryCheck=QgsFeatureRequest.GeometrySkipInvalid,
                ),
                "OUTPUT": location_buffer_clip,
            },
        )

        Insights_re_point = "6) RE Point Locations"
        if os.path.exists(f"{Insights_folder}/{Insights_re_point}"):
            pass
        else:
            os.mkdir(f"{Insights_folder}/{Insights_re_point}")

        shpOutput = (
                f"{workingDir}{Insights_folder}/{Insights_re_point}/"
                + self.dlg.Buffer_Output_Field.text()
                + f"{str(bufferDistance)}m_buffer.shp"
        )

        processing.run(
            "native:zonalstatisticsfb",
            {
                "INPUT": QgsProcessingFeatureSourceDefinition(
                    location_buffer_clip,
                    selectedFeaturesOnly=False,
                    featureLimit=-1,
                    flags=QgsProcessingFeatureSourceDefinition.FlagOverrideDefaultGeometryCheck,
                    geometryCheck=QgsFeatureRequest.GeometrySkipInvalid,
                ),
                "INPUT_RASTER": insights_raster,
                "RASTER_BAND": 1,
                "COLUMN_PREFIX": "_",
                "STATISTICS": [9],
                "OUTPUT": shpOutput,
            },
        )

        styleTemplate = f"{current_script_path}/Style/Insights Buffer Aggregation.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_re_point}/"
        styleFile = (
            f"{self.dlg.Buffer_Output_Field.text()}{str(bufferDistance)}m_buffer.qml"
        )

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        # Load the main polygon layer
        main_layer = gpd.read_file(aggregate)

        # Load the layer you want to check for intersection
        intersect_layer = gpd.read_file(shpOutput)

        # Perform a spatial join
        intersecting_records = gpd.sjoin(
            main_layer, intersect_layer, how="inner", op="intersects"
        )

        # Extract the intersecting polygons
        intersecting_polygons = main_layer.loc[intersecting_records.index]

        # Save to a new shapefile
        admin_RE = (
                f"{workingDir}{Insights_folder}/{Insights_re_point}/"
                + self.dlg.Buffer_Output_Field.text()
                + f"admin_unit_{str(bufferDistance)}m_buffer_intersection.shp"
        )
        intersecting_polygons.to_file(admin_RE)

        styleTemplate = f"{current_script_path}/Style/Insights Aggregation.qml"
        styleFileDestination = f"{workingDir}{Insights_folder}/{Insights_re_point}/"
        styleFile = f"{admin_RE.split('.')[0]}.qml"

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        layer2 = QgsVectorLayer(
            admin_RE,
            f"{self.dlg.Buffer_Output_Field.text()}admin_unit_{str(bufferDistance)}m_buffer_intersection",
        )
        QgsProject.instance().addMapLayer(layer2)

        layer = QgsVectorLayer(
            shpOutput,
            f"{self.dlg.Buffer_Output_Field.text()}{str(bufferDistance)}m_buffer",
        )
        QgsProject.instance().addMapLayer(layer)

        self.dlg.REpoint_status.setText("RE point proximity complete!")
        self.dlg.REpoint_status.repaint()


    def walkabilityAggregate(self):
        """
        This function is used in combination with the "walkability" function.
        This function now performs a UNION (maximum value) of the active transport
        rasters instead of averaging them.

        Factors it is applied:
            Accessibility Dimension
                - Active transport
        """
        self.dlg.ATAGG_status.setText("")
        self.dlg.ATAGG_status.repaint()
        # OUTPUT
        current_script_path = os.path.dirname(os.path.abspath(__file__))
        workingDir = self.dlg.workingDir_Field.text()
        os.chdir(workingDir)
        Dimension = "Place Characterization"
        AT_Folder = f"{Dimension}/AT"

        if os.path.exists(AT_Folder):
            os.chdir(AT_Folder)
        else:
            pass

        rasOutput = self.dlg.AT_AGGOutput_Field.text()

        styleTemplate = f"{current_script_path}/Style/{Dimension}.qml"
        styleFileDestination = f"{workingDir}{Dimension}/"
        styleFile = f"{rasOutput.split('.')[0]}.qml"

        tif_list = [f for f in os.listdir(os.getcwd()) if f.endswith(".tif")]
        raster_list = []

        for ras in tif_list:
            with rasterio.open(ras) as src:
                raster_data = src.read(1)
                raster_list.append(raster_data)
                meta1 = src.meta

        # Initialize the union result with the first raster
        union_result = raster_list[0].copy()

        # Perform UNION operation (taking the maximum value for each pixel)
        for raster in raster_list[1:]:
            union_result = np.maximum(union_result, raster)

        # Set nodata values to -9999
        union_result = np.where(union_result == meta1['nodata'], -9999, union_result)

        # Commented out average calculation
        """
        len_raster_list = len(raster_list)
        cumulative_sum = np.zeros_like(raster_list[0], dtype=np.float32)

        for i in range(len_raster_list):
            value = raster_list[i]
            cumulative_sum += np.where(value != meta1['nodata'], value, 0)

        valid_count = np.sum([np.where(raster != meta1['nodata'], 1, 0) for raster in raster_list], axis=0)
        aggregation = np.where(valid_count > 0, cumulative_sum / valid_count, -9999)
        """

        os.chdir("..")

        # Update metadata for the new nodata value
        meta1.update(nodata=-9999, dtype=rasterio.float32)

        with rasterio.open(rasOutput, "w", **meta1) as dst:
            dst.write(union_result.astype(rasterio.float32), 1)

        self.dlg.AT_Aggregate_Field.setText(f"{workingDir}{Dimension}/{rasOutput}")

        shutil.copy(styleTemplate, os.path.join(styleFileDestination, styleFile))

        self.dlg.ATAGG_status.setText("Processing Complete!")
        self.dlg.ATAGG_status.repaint()

        os.chdir(workingDir)
        
        
    
